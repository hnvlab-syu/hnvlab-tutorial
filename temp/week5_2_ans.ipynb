{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기\n",
    "\n",
    "메인 교재와 서브 강의만을 활용하여 MNIST 데이터셋을 불러오시오. (구글링 금지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785) (10000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/mnist_train.csv')\n",
    "test_data = pd.read_csv('data/mnist_test.csv')\n",
    "\n",
    "print(train_data.shape, test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785) (10000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40629</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24227</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40340</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "6355       6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "40629      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "24227      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "40340      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "6680       5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "6355       0      0      0      0      0      0      0      0  \n",
       "40629      0      0      0      0      0      0      0      0  \n",
       "24227      0      0      0      0      0      0      0      0  \n",
       "40340      0      0      0      0      0      0      0      0  \n",
       "6680       0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle\n",
    "train_data = train_data.sample(frac=1)\n",
    "\n",
    "print(train_data.shape, test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 나누기(split)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 data를 feature와 정답(label)로 나누는 코드를 구현하시오. (구글링 금지)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def split_data(train_data: pd.DataFrame, test_data: pd.DataFrame) -> Tuple[np.ndarray]:\n",
    "    test_x_data = np.array(test_data.iloc[:, 1:])\n",
    "    test_t_data = np.array(test_data.iloc[:, 0])\n",
    "    train_x_data = np.array(train_data.iloc[:, 1:])\n",
    "    train_t_data = np.array(train_data.iloc[:, 0])\n",
    "    \n",
    "    return train_x_data, train_t_data, test_x_data, test_t_data\n",
    "\n",
    "\n",
    "train_x_data, train_t_data, test_x_data, test_t_data = split_data(train_data, test_data)\n",
    "print(train_x_data.shape, train_t_data.shape, test_x_data.shape, test_t_data.shape,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리(preprocessing)\n",
    "\n",
    "a. 메인 교재와 서브 강의를 활용하여 train data를 normalize하시오. (구글링 가능)\n",
    "\n",
    "$$normalize(X) = \\frac {X - min} {max - min} \\space (max - min \\neq 0)$$\n",
    "\n",
    "b. 메인 교재와 서브 강의를 활용하여 test data를 one-hot encoding하시오. (구글링 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01]\n",
      " [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01]\n",
      " [0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      " [0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      " [0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]]\n",
      "(60000, 784) (60000, 10) (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(train_x_data: np.ndarray, train_t_data: np.ndarray, test_x_data: np.ndarray, test_t_data: np.ndarray) -> Tuple[np.ndarray]:\n",
    "    train_x_data = np.array(train_x_data) / 255.0  # 0~1 min-max scaling (normalization)\n",
    "    train_x_data = train_x_data * 0.99 + 0.01  # smoothing\n",
    "    \n",
    "    test_x_data = np.array(test_x_data) / 255.0  # 0~1 min-max scaling (normalization)\n",
    "    test_x_data = test_x_data * 0.99 + 0.01  # smoothing\n",
    "\n",
    "    num_classes = 10  # 0~9\n",
    "    train_t_data_onehot = np.zeros((train_t_data.shape[0], num_classes), dtype=np.float32) + 0.01  # one-hot encoding (vectorization) + smoothing\n",
    "    for i in range(len(train_t_data_onehot)):\n",
    "        train_t_data_onehot[i, train_t_data[i]] = 0.99  # smoothing\n",
    "\n",
    "    test_t_data_onehot = np.zeros((test_t_data.shape[0], num_classes), dtype=np.float32) + 0.01  # one-hot encoding (vectorization) + smoothing\n",
    "    for i in range(len(test_t_data_onehot)):\n",
    "        test_t_data_onehot[i, test_t_data[i]] = 0.99  # smoothing\n",
    "    \n",
    "    return train_x_data, train_t_data_onehot, test_x_data, test_t_data_onehot\n",
    "\n",
    "    \n",
    "train_x_data, train_t_data_onehot, test_x_data, test_t_data_onehot = preprocess(train_x_data, train_t_data, test_x_data, test_t_data)\n",
    "print(train_t_data_onehot[:5])\n",
    "print(train_x_data.shape, train_t_data_onehot.shape, test_x_data.shape, test_t_data_onehot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 활성 함수(activation function)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 활성 함수 중 하나인 softmax 함수를 구현하시오. (구글링 금지)\n",
    "\n",
    "$$\\sigma(\\boldsymbol{z})_{i} = \\frac {e^{z_{i}}} {\\sum_{i=1} ^K e_{z_{i}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    e_x = np.exp(z)\n",
    "    return e_x / e_x.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 신경망(neural network) 모델\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 신경망(neural network) 모델을 구현하시오. (구글링 금지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, n_input: int, n_output: int, n_hidden: int = 128) -> None:\n",
    "        self.W2 = np.random.randn(n_input, n_hidden)  # he initialization\n",
    "        self.b2 = np.random.randn(n_hidden)\n",
    "        self.W3 = np.random.randn(n_hidden, n_output)\n",
    "        self.b3 = np.random.randn(n_output)\n",
    "        \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        self.a1 = x\n",
    "        z2 = self.a1 @ self.W2 + self.b2\n",
    "        self.a2 = sigmoid(z2)\n",
    "        z3 = self.a2 @ self.W3 + self.b3\n",
    "        y = self.a3 = softmax(z3)\n",
    "        return y\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self.forward(x)\n",
    "    \n",
    "    \n",
    "model = NeuralNetwork(n_input=784, n_output=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 오차 함수 (error function, loss function)\n",
    "\n",
    "주어진 수식만을 이용하여 CE(cross entropy) 오차 함수를 구현하시오. (구글링, 메인 교재 참고, 서브 강의 참고 금지)\n",
    "- delta는 log의 진수 조건을 만족하기 위해 필요하므로 반드시 사용\n",
    "- N은 데이터 개수 (행 개수)\n",
    "- $y$는 정답(label) $\\hat{y}$은 예측값(prediction)\n",
    "\n",
    "$$CE = -\\sum_{i=1} ^N (\\boldsymbol{y_{i}} \\cdot \\log \\boldsymbol{\\hat{y_{i}}} + (1 - \\boldsymbol{y_{i}}) \\cdot \\log (1 - \\boldsymbol{\\hat{y_{i}}}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_data: np.ndarray, t_data: np.ndarray) -> np.ndarray:\n",
    "    delta = 1e-4\n",
    "    return -np.mean(t_data * np.log(y_data + delta) + (1 - t_data) * np.log((1 - y_data) + delta))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 오차역전파 (backpropagation)\n",
    "\n",
    "메인 교재와 서브 강의 및 다음 수식을 참고하여 5번과 6번에 대한 오차역전파(backpropagation) 공식을 구하시오. (구글링 금지)\n",
    "- n은 input node 개수, m은 hidden node 개수, o는 output node 개수\n",
    "\n",
    "$$J(W^{(2)}) = \\frac{dE} {dW^{(2)}} = \\begin{pmatrix} \n",
    "\\frac{\\partial E} {\\partial W^{(2)}_{11}} & \\cdots & \\frac {\\partial E} {\\partial W^{(2)}_{m1}} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "\\frac {\\partial E} {\\partial W^{(2)}_{1n}} & \\cdots & \\frac {\\partial E} {\\partial W^{(2)}_{mn}} \\end{pmatrix}$$\n",
    "\n",
    "$$J(W^{(3)}) = \\frac{dE} {dW^{(3)}} = \\begin{pmatrix} \n",
    "\\frac{\\partial E} {\\partial W^{(3)}_{11}} & \\cdots & \\frac {\\partial E} {\\partial W^{(3)}_{o1}} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "\\frac {\\partial E} {\\partial W^{(3)}_{1m}} & \\cdots & \\frac {\\partial E} {\\partial W^{(3)}_{om}} \\end{pmatrix}$$\n",
    "\n",
    "$$J(\\boldsymbol{b^{(2)}}) = \\frac{dE} {d\\boldsymbol{b^{(2)}}} = \\begin{pmatrix} \\frac{\\partial E} {\\partial b^{(2)}_{1}} \\frac{\\partial E} {\\partial b^{(2)}_{2}} \\end{pmatrix}$$\n",
    "\n",
    "$$J(\\boldsymbol{b^{(3)}}) = \\frac{dE} {d\\boldsymbol{b^{(3)}}} = \\begin{pmatrix} \\frac{\\partial E} {\\partial b^{(3)}_{1}} \\frac{\\partial E} {\\partial b^{(3)}_{2}} \\end{pmatrix}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 모델 학습 (train)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 다음 순서를 가지는 학습 코드를 구현하시오. (구글링 금지)\n",
    "- 한꺼번에 다 학습 -> batch(뭉텅이) gradient descent\n",
    "\n",
    "1. 모델 순전파 (forward)\n",
    "2. 오차 계산 (loss)\n",
    "3. 모델 파라미터(가중치 + 편향) 별 오차 함수의 오차역전파 계산 (backpropagation)\n",
    "4. 가중치(weight), 편향(bias) 갱신 (경사 하강법, gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss 1.0459180038739544\n",
      "Epoch: 10, loss 1.7191932726640307\n",
      "Epoch: 20, loss 1.7191932726640307\n",
      "Epoch: 30, loss 1.7191932726640307\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     20\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, loss \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m train_batch()\n",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m, in \u001b[0;36mtrain_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m loss_2 \u001b[39m=\u001b[39m loss_3 \u001b[39m@\u001b[39m model\u001b[39m.\u001b[39mW3\u001b[39m.\u001b[39mT \u001b[39m*\u001b[39m model\u001b[39m.\u001b[39ma2 \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m model\u001b[39m.\u001b[39ma2)\n\u001b[1;32m     16\u001b[0m model\u001b[39m.\u001b[39mW2 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mW2 \u001b[39m-\u001b[39m lr \u001b[39m*\u001b[39m model\u001b[39m.\u001b[39ma1\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m loss_2\n\u001b[0;32m---> 17\u001b[0m model\u001b[39m.\u001b[39mb2 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mb2 \u001b[39m-\u001b[39;49m lr \u001b[39m*\u001b[39;49m loss_2\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, loss \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_batch() -> None:\n",
    "    lr = 1e-1\n",
    "    \n",
    "    for epoch in range(10000):\n",
    "        y_data = model(train_x_data)\n",
    "        # print(y_data[0], np.sum(y_data[0]), y_data.shape, train_t_data_onehot[0])\n",
    "        loss = cross_entropy_loss(y_data, train_t_data_onehot)\n",
    "        \n",
    "        # backpropagation\n",
    "        loss_3 = (model.a3 - train_t_data_onehot) * model.a3 * (1 - model.a3)\n",
    "        # print(loss_3.shape)\n",
    "        model.W3 = model.W3 - lr * model.a2.T @ loss_3\n",
    "        # print(model.a2.T.shape)\n",
    "        model.b3 = model.b3 - lr * loss_3\n",
    "        loss_2 = loss_3 @ model.W3.T * model.a2 * (1 - model.a2)\n",
    "        model.W2 = model.W2 - lr * model.a1.T @ loss_2\n",
    "        model.b2 = model.b2 - lr * loss_2\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, loss {loss}')\n",
    "\n",
    "\n",
    "train_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2185028b62590b62afdaea33c23835374a0efabc80ef4ce750ba82ee2e8657e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
