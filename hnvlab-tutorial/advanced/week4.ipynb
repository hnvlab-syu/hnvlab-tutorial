{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented and written by Yeoreum Lee in AI HnV Lab @ Sahmyook University in 2023\n",
    "__author__ = 'leeyeoreum02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기\n",
    "\n",
    "메인 교재와 서브 강의만을 활용하여 pandas로 MNIST 데이터셋을 불러오시오. [mnist_train.csv, mnist_test.csv] (구글링 금지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785) (10000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "...\n",
    "\n",
    "print(train_data.shape, test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785) (10000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44937</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21314</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45397</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "44937      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "21314      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "45397      7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "9497       6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "6093       8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "44937      0      0      0      0      0      0      0      0  \n",
       "21314      0      0      0      0      0      0      0      0  \n",
       "45397      0      0      0      0      0      0      0      0  \n",
       "9497       0      0      0      0      0      0      0      0  \n",
       "6093       0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle\n",
    "train_data = ...\n",
    "\n",
    "print(train_data.shape, test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 나누기(split)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 data를 feature와 정답(label)로 나누는 코드를 구현하시오. (구글링 금지)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def split_data(train_data: pd.DataFrame, test_data: pd.DataFrame) -> Tuple[np.ndarray]:\n",
    "    ...\n",
    "    return train_x_data, train_t_data, test_x_data, test_t_data\n",
    "\n",
    "\n",
    "train_x_data, train_t_data, test_x_data, test_t_data = split_data(train_data, test_data)\n",
    "print(train_x_data.shape, train_t_data.shape, test_x_data.shape, test_t_data.shape,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리(preprocessing)\n",
    "\n",
    "a. 메인 교재와 서브 강의를 활용하여 train data를 normalize하시오. (구글링 가능)\n",
    "\n",
    "$$normalize(X) = \\frac {X - min} {max - min} \\space (max - min \\neq 0)$$\n",
    "\n",
    "b. 메인 교재와 서브 강의를 활용하여 test data를 one-hot encoding하시오. (구글링 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01]\n",
      " [0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      " [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01]\n",
      " [0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01]\n",
      " [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01]]\n",
      "(60000, 784) (60000, 10) (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(train_x_data: np.ndarray, train_t_data: np.ndarray, test_x_data: np.ndarray, test_t_data: np.ndarray) -> Tuple[np.ndarray]:\n",
    "    ...\n",
    "    return train_x_data, train_t_data_onehot, test_x_data, test_t_data_onehot\n",
    "\n",
    "    \n",
    "train_x_data, train_t_data_onehot, test_x_data, test_t_data_onehot = preprocess(train_x_data, train_t_data, test_x_data, test_t_data)\n",
    "print(train_t_data_onehot[:5])\n",
    "print(train_x_data.shape, train_t_data_onehot.shape, test_x_data.shape, test_t_data_onehot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 활성 함수(activation function)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 활성 함수 중 하나인 softmax 함수를 구현하시오. (구글링 금지)\n",
    "\n",
    "$$\\sigma(\\boldsymbol{z})_{i} = \\frac {e^{z_{i}}} {\\sum_{i=1} ^K e^{z_{i}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    return ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 신경망(neural network) 모델\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 신경망(neural network) 모델을 구현하시오. (구글링 금지)\n",
    "\n",
    "$$f(W^{(2)}, b^{(2)})(\\boldsymbol{x}) = sigmoid(W^{(2)}\\boldsymbol{x} + b^{(2)})$$\n",
    "$$g(W^{(3)}, b^{(3)})(\\boldsymbol{x}) = \\sigma(W^{(3)}\\boldsymbol{x} + b^{(3)})$$\n",
    "$$\n",
    "\\begin{matrix}\n",
    "y &=& h(W^{(2)}, b^{(2)}, W^{(3)}, b^{(3)})(\\boldsymbol{x}) \\\\\n",
    "  &=& (g(W^{(3)}, b^{(3)}) \\circ f(W^{(2)}, b^{(2)}))(\\boldsymbol{x}) \\\\\n",
    "  &=& g(W^{(3)}, b^{(3)})(f(W^{(2)}, b^{(2)})(\\boldsymbol{x})) \\\\\n",
    "  &=& \\sigma(W^{(3)}sigmoid(W^{(2)}\\boldsymbol{x} + b^{(2)}) + b^{(3)})\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, n_input: int, n_output: int, n_hidden: int = 128) -> None:\n",
    "        ...\n",
    "        \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        ...\n",
    "        return y\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self.forward(x)\n",
    "    \n",
    "    \n",
    "model = NeuralNetwork(n_input=..., n_output=...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 오차 함수 (error function, loss function)\n",
    "\n",
    "주어진 수식만을 이용하여 CE(cross entropy) 오차 함수를 구현하시오. (구글링, 메인 교재 참고, 서브 강의 참고 금지)\n",
    "- delta는 log의 진수 조건을 만족하기 위해 필요하므로 반드시 사용\n",
    "- N은 데이터 개수 (행 개수)\n",
    "- $y$는 정답(label) $\\hat{y}$은 예측값(prediction)\n",
    "\n",
    "$$CE = -\\sum_{i=1} ^N (\\boldsymbol{y_{i}} \\cdot \\log \\boldsymbol{\\hat{y_{i}}} + (1 - \\boldsymbol{y_{i}}) \\cdot \\log (1 - \\boldsymbol{\\hat{y_{i}}}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_data: np.ndarray, t_data: np.ndarray) -> np.ndarray:\n",
    "    delta = 1e-4\n",
    "    return ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 편미분 함수 (partial numerical derivative)\n",
    "\n",
    "- n은 input node 개수, m은 hidden node 개수, o는 output node 개수\n",
    "\n",
    "$$J(W^{(2)}) = \\frac{dE} {dW^{(2)}} = \\begin{pmatrix} \n",
    "\\frac{\\partial E} {\\partial W^{(2)}_{11}} & \\cdots & \\frac {\\partial E} {\\partial W^{(2)}_{m1}} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "\\frac {\\partial E} {\\partial W^{(2)}_{1n}} & \\cdots & \\frac {\\partial E} {\\partial W^{(2)}_{mn}} \\end{pmatrix}$$\n",
    "\n",
    "$$J(W^{(3)}) = \\frac{dE} {dW^{(3)}} = \\begin{pmatrix} \n",
    "\\frac{\\partial E} {\\partial W^{(3)}_{11}} & \\cdots & \\frac {\\partial E} {\\partial W^{(3)}_{o1}} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "\\frac {\\partial E} {\\partial W^{(3)}_{1m}} & \\cdots & \\frac {\\partial E} {\\partial W^{(3)}_{om}} \\end{pmatrix}$$\n",
    "\n",
    "$$J(\\boldsymbol{b^{(2)}}) = \\frac{dE} {d\\boldsymbol{b^{(2)}}} = \\begin{pmatrix} \\frac{\\partial E} {\\partial b^{(2)}_{1}} \\frac{\\partial E} {\\partial b^{(2)}_{2}} \\end{pmatrix}$$\n",
    "\n",
    "$$J(\\boldsymbol{b^{(3)}}) = \\frac{dE} {d\\boldsymbol{b^{(3)}}} = \\begin{pmatrix} \\frac{\\partial E} {\\partial b^{(3)}_{1}} \\frac{\\partial E} {\\partial b^{(3)}_{2}} \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f: Callable, x: np.ndarray) -> np.ndarray:\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        temp = x[idx]\n",
    "        x[idx] = float(temp) + h\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = temp - h\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2 * h)\n",
    "        \n",
    "        x[idx] = temp\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-1. 모델 학습 (train)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 다음 순서를 가지는 학습 코드를 구현하시오. (구글링 금지)\n",
    "- 한꺼번에 다 학습 -> batch(뭉텅이) gradient descent\n",
    "\n",
    "1. 모델 순전파 (forward)\n",
    "2. 오차 계산 (loss)\n",
    "3. 모델 파라미터(가중치 + 편향) 별 오차 함수의 편미분값 계산 (numerical derivative)\n",
    "4. 가중치(weight), 편향(bias) 갱신 (경사 하강법, gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m         model\u001b[39m.\u001b[39mb3 \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m lr \u001b[39m*\u001b[39m numerical_derivative(f_b3, model\u001b[39m.\u001b[39mb3)\n\u001b[1;32m     18\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, loss \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m train()\n",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m f_W3 \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W3: categorical_cross_entropy_loss(softmax(sigmoid(train_x_data \u001b[39m@\u001b[39m model\u001b[39m.\u001b[39mW2 \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mb2) \u001b[39m@\u001b[39m W3 \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mb3), train_t_data_onehot)\n\u001b[1;32m     11\u001b[0m f_b3 \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m b3: categorical_cross_entropy_loss(softmax(sigmoid(train_x_data \u001b[39m@\u001b[39m model\u001b[39m.\u001b[39mW2 \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mb2) \u001b[39m@\u001b[39m model\u001b[39m.\u001b[39mW3 \u001b[39m+\u001b[39m b3), train_t_data_onehot)\n\u001b[0;32m---> 13\u001b[0m model\u001b[39m.\u001b[39mW2 \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m lr \u001b[39m*\u001b[39m numerical_derivative(f_W2, model\u001b[39m.\u001b[39;49mW2)\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39mb2 \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m lr \u001b[39m*\u001b[39m numerical_derivative(f_b2, model\u001b[39m.\u001b[39mb2)\n\u001b[1;32m     15\u001b[0m model\u001b[39m.\u001b[39mW3 \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m lr \u001b[39m*\u001b[39m numerical_derivative(f_W3, model\u001b[39m.\u001b[39mW3)\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mnumerical_derivative\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m fx1 \u001b[39m=\u001b[39m f(x)\n\u001b[1;32m     14\u001b[0m x[idx] \u001b[39m=\u001b[39m temp \u001b[39m-\u001b[39m h\n\u001b[0;32m---> 15\u001b[0m fx2 \u001b[39m=\u001b[39m f(x)\n\u001b[1;32m     16\u001b[0m grad[idx] \u001b[39m=\u001b[39m (fx1 \u001b[39m-\u001b[39m fx2) \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m h)\n\u001b[1;32m     18\u001b[0m x[idx] \u001b[39m=\u001b[39m temp\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mtrain.<locals>.<lambda>\u001b[0;34m(W2)\u001b[0m\n\u001b[1;32m      5\u001b[0m y_data \u001b[39m=\u001b[39m model(train_x_data)\n\u001b[1;32m      6\u001b[0m loss \u001b[39m=\u001b[39m categorical_cross_entropy_loss(y_data, train_t_data_onehot)\n\u001b[0;32m----> 8\u001b[0m f_W2 \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W2: categorical_cross_entropy_loss(softmax(sigmoid(train_x_data \u001b[39m@\u001b[39;49m W2 \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mb2) \u001b[39m@\u001b[39m model\u001b[39m.\u001b[39mW3 \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mb3), train_t_data_onehot)\n\u001b[1;32m      9\u001b[0m f_b2 \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m b2: categorical_cross_entropy_loss(softmax(sigmoid(train_x_data \u001b[39m@\u001b[39m model\u001b[39m.\u001b[39mW2 \u001b[39m+\u001b[39m b2) \u001b[39m@\u001b[39m model\u001b[39m.\u001b[39mW3 \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mb3), train_t_data_onehot)\n\u001b[1;32m     10\u001b[0m f_W3 \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W3: categorical_cross_entropy_loss(softmax(sigmoid(train_x_data \u001b[39m@\u001b[39m model\u001b[39m.\u001b[39mW2 \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mb2) \u001b[39m@\u001b[39m W3 \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39mb3), train_t_data_onehot)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_batch() -> None:\n",
    "    ...\n",
    "\n",
    "\n",
    "train_batch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-2. 모델 학습 (train)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 다음 순서를 가지는 학습 코드를 구현하시오. (구글링 금지)\n",
    "- mini-batch 단위로 학습 -> mini-batch gradient descent\n",
    "- 만약 batch size가 1인 경우 -> stocastic gradient descent\n",
    "- 메모리가 부족해 한꺼번에 다 안들어갈 경우 위의 방식들을 사용\n",
    "- 여기선 메모리가 부족하진 않지만 loss 변화가 너무 늦게 출력되니까 사용\n",
    "\n",
    "1. 모델 순전파 (forward)\n",
    "2. 오차 계산 (loss)\n",
    "3. 모델 파라미터(가중치 + 편향) 별 오차 함수의 편미분값 계산 (numerical derivative)\n",
    "4. 가중치(weight), 편향(bias) 갱신 (경사 하강법, gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 0, loss 9.542098089816562\n",
      "Epoch: 0, step: 1, loss 1.6276390972015258\n",
      "Epoch: 0, step: 2, loss 9.616006131579352\n",
      "Epoch: 0, step: 3, loss 9.033076191087133\n",
      "Epoch: 0, step: 4, loss 9.424084911879163\n",
      "Epoch: 0, step: 5, loss 6.9276291235833725\n",
      "Epoch: 0, step: 6, loss 6.592219003785746\n",
      "Epoch: 0, step: 7, loss 2.203215612282584\n",
      "Epoch: 0, step: 8, loss 9.779394345529438\n",
      "Epoch: 0, step: 9, loss 6.306510581809841\n",
      "Epoch: 0, step: 10, loss 2.5358057511827763\n",
      "Epoch: 0, step: 11, loss 9.691672894323363\n",
      "Epoch: 0, step: 12, loss 6.7438864728623455\n",
      "Epoch: 0, step: 13, loss 9.582851387735955\n",
      "Epoch: 0, step: 14, loss 2.4749930989396103\n",
      "Epoch: 0, step: 15, loss 4.995239615196154\n",
      "Epoch: 0, step: 16, loss 9.810783816020272\n",
      "Epoch: 0, step: 17, loss 9.686294035542304\n",
      "Epoch: 0, step: 18, loss 7.5193177098430874\n",
      "Epoch: 0, step: 19, loss 9.768022746390415\n",
      "Epoch: 0, step: 20, loss 9.12719436307242\n",
      "Epoch: 0, step: 21, loss 9.854966302923193\n",
      "Epoch: 0, step: 22, loss 9.642742929994151\n",
      "Epoch: 0, step: 23, loss 1.0098864962854426\n",
      "Epoch: 0, step: 24, loss 0.8030834420924072\n",
      "Epoch: 0, step: 25, loss 8.436818847601371\n",
      "Epoch: 0, step: 26, loss 9.739426649055282\n",
      "Epoch: 0, step: 27, loss 9.646445632853222\n",
      "Epoch: 0, step: 28, loss 9.6819840198379\n",
      "Epoch: 0, step: 29, loss 7.266730990372153\n",
      "Epoch: 0, step: 30, loss 8.718945363166199\n",
      "Epoch: 0, step: 31, loss 7.339421085895685\n",
      "Epoch: 0, step: 32, loss 0.7214820842896895\n",
      "Epoch: 0, step: 33, loss 9.750896336768456\n",
      "Epoch: 0, step: 34, loss 7.956200660230921\n",
      "Epoch: 0, step: 35, loss 9.317718765666111\n",
      "Epoch: 0, step: 36, loss 9.835203761137768\n",
      "Epoch: 0, step: 37, loss 9.83346607968741\n",
      "Epoch: 0, step: 38, loss 9.68367714090484\n",
      "Epoch: 0, step: 39, loss 9.645569820293732\n",
      "Epoch: 0, step: 40, loss 4.605578033326287\n",
      "Epoch: 0, step: 41, loss 9.640967988859776\n",
      "Epoch: 0, step: 42, loss 8.055632271241084\n",
      "Epoch: 0, step: 43, loss 8.012152035772178\n",
      "Epoch: 0, step: 44, loss 0.7549364693025401\n",
      "Epoch: 0, step: 45, loss 2.47602549545818\n",
      "Epoch: 0, step: 46, loss 2.101062527524362\n",
      "Epoch: 0, step: 47, loss 4.566085665335881\n",
      "Epoch: 0, step: 48, loss 2.363619100580858\n",
      "Epoch: 0, step: 49, loss 9.690770722222954\n",
      "Epoch: 0, step: 50, loss 3.144126223389312\n",
      "Epoch: 0, step: 51, loss 9.632311524457617\n",
      "Epoch: 0, step: 52, loss 1.5972556656865549\n",
      "Epoch: 0, step: 53, loss 8.874680754401055\n",
      "Epoch: 0, step: 54, loss 1.1900909242767348\n",
      "Epoch: 0, step: 55, loss 1.7008433872859168\n",
      "Epoch: 0, step: 56, loss 4.7436950135077245\n",
      "Epoch: 0, step: 57, loss 4.185847355434815\n",
      "Epoch: 0, step: 58, loss 6.527194455609707\n",
      "Epoch: 0, step: 59, loss 7.167384982181803\n",
      "Epoch: 0, step: 60, loss 9.503211173430751\n",
      "Epoch: 0, step: 61, loss 1.0186147061973472\n",
      "Epoch: 0, step: 62, loss 2.7683387460892153\n",
      "Epoch: 0, step: 63, loss 3.2597146433374546\n",
      "Epoch: 0, step: 64, loss 9.761596632920764\n",
      "Epoch: 0, step: 65, loss 9.729923544688926\n",
      "Epoch: 0, step: 66, loss 9.633767256959127\n",
      "Epoch: 0, step: 67, loss 0.7413468481593182\n",
      "Epoch: 0, step: 68, loss 6.275364850274521\n",
      "Epoch: 0, step: 69, loss 8.352351003755906\n"
     ]
    }
   ],
   "source": [
    "def train_mini_batch() -> None:\n",
    "    ...\n",
    "                \n",
    "                \n",
    "train_mini_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2185028b62590b62afdaea33c23835374a0efabc80ef4ce750ba82ee2e8657e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
