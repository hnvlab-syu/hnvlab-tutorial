{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented and written by Yeoreum Lee in AI HnV Lab @ Sahmyook University in 2023\n",
    "__author__ = 'leeyeoreum02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2) (9, 1)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[2, 4], [4, 11], [6, 6], [8, 5], [10, 7], [12, 16], [14, 8], [16, 3], [18, 7]])\n",
    "t_data = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1]).reshape(9, 1)\n",
    "\n",
    "print(x_data.shape, t_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 나누기(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2) (8, 1) (1, 2) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "def split_data(x_data: np.ndarray, t_data: np.ndarray, split_rate: float) -> Tuple[np.ndarray]:\n",
    "    test_x_data = x_data[:int(split_rate * len(x_data))]\n",
    "    test_t_data = t_data[:int(split_rate * len(t_data))]\n",
    "    train_x_data = x_data[int(split_rate * len(x_data)):]\n",
    "    train_t_data = t_data[int(split_rate * len(t_data)):]\n",
    "    \n",
    "    return train_x_data, train_t_data, test_x_data, test_t_data\n",
    "\n",
    "\n",
    "train_x_data, train_t_data, test_x_data, test_t_data = split_data(x_data, t_data, split_rate=0.2)\n",
    "print(train_x_data.shape, train_t_data.shape, test_x_data.shape, test_t_data.shape,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 활성 함수(activation function)\n",
    "\n",
    "$$sigmoid(\\boldsymbol{x}) = \\frac {1} {1 + e^{-\\boldsymbol{x}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 원핫 인코딩(One-hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99 0.01]\n",
      " [0.99 0.01]\n",
      " [0.99 0.01]]\n",
      "(8, 2) (1, 2)\n"
     ]
    }
   ],
   "source": [
    "def onehot_encoding(train_t_data: np.ndarray, test_t_data: np.ndarray, num_classes: int = 2) -> Tuple[np.ndarray]:\n",
    "    train_t_data_onehot = np.zeros((train_t_data.shape[0], num_classes), dtype=np.float32) + 0.01  # one-hot encoding (vectorization) + smoothing\n",
    "    for i in range(len(train_t_data_onehot)):\n",
    "        train_t_data_onehot[i, train_t_data[i]] = 0.99  # smoothing\n",
    "\n",
    "    test_t_data_onehot = np.zeros((test_t_data.shape[0], num_classes), dtype=np.float32) + 0.01  # one-hot encoding (vectorization) + smoothing\n",
    "    for i in range(len(test_t_data_onehot)):\n",
    "        test_t_data_onehot[i, test_t_data[i]] = 0.99  # smoothing\n",
    "    \n",
    "    return train_t_data_onehot, test_t_data_onehot\n",
    "\n",
    "\n",
    "train_t_data_onehot, test_t_data_onehot = onehot_encoding(train_t_data, test_t_data)\n",
    "print(train_t_data_onehot[:3])\n",
    "print(train_t_data_onehot.shape, test_t_data_onehot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 신경망(neural network) 모델\n",
    "\n",
    "$$f(W^{(2)}, b^{(2)})(\\boldsymbol{x}) = sigmoid(W^{(2)}\\boldsymbol{x} + b^{(2)})$$\n",
    "$$g(W^{(3)}, b^{(3)})(\\boldsymbol{x}) = \\sigma(W^{(3)}\\boldsymbol{x} + b^{(3)})$$\n",
    "$$\n",
    "\\begin{matrix}\n",
    "y &=& h(W^{(2)}, b^{(2)}, W^{(3)}, b^{(3)})(\\boldsymbol{x}) \\\\\n",
    "  &=& (g(W^{(3)}, b^{(3)}) \\circ f(W^{(2)}, b^{(2)}))(\\boldsymbol{x}) \\\\\n",
    "  &=& g(W^{(3)}, b^{(3)})(f(W^{(2)}, b^{(2)})(\\boldsymbol{x})) \\\\\n",
    "  &=& \\sigma(W^{(3)}sigmoid(W^{(2)}\\boldsymbol{x} + b^{(2)}) + b^{(3)})\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self) -> None:\n",
    "        self.W2 = np.random.randn(2, 2)\n",
    "        self.b2 = np.random.randn(2)\n",
    "        self.W3 = np.random.randn(2, 2)\n",
    "        self.b3 = np.random.randn(2)\n",
    "        \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        a1 = x\n",
    "        z2 = a1 @ self.W2 + self.b2\n",
    "        self.a2 = sigmoid(z2)\n",
    "        z3 = self.a2 @ self.W3 + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "        return y\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self.forward(x)\n",
    "    \n",
    "    \n",
    "model_back = NeuralNetwork()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 오차 함수 (error function, loss function)\n",
    "\n",
    "- N은 데이터 개수 (행 개수)\n",
    "- $y$는 정답(label) $\\hat{y}$은 예측값(prediction)\n",
    "\n",
    "$$MSE = \\frac{1} {N}\\sum_{i=1} ^N (\\boldsymbol{y_{i}} - \\boldsymbol{\\hat{y_{i}}})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y_data: np.ndarray, t_data: np.ndarray) -> np.ndarray:\n",
    "    return np.sum((t_data - y_data) ** 2) / len(y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 학습 (train)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 오차역전파를 계산하고 학습 코드를 구현하시오. (구글링 금지)\n",
    "\n",
    "0. 배치 사이즈는 1임\n",
    "1. 모델 순전파 (forward)\n",
    "2. 오차 계산 (loss)\n",
    "3. 모델 파라미터(가중치 + 편향) 별 오차 함수의 오차역전파 계산 (backpropagation)\n",
    "4. 가중치(weight), 편향(bias) 갱신 (경사 하강법, gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss 0.11319923179622736\n",
      "Epoch: 0, loss 0.14155131209121938\n",
      "Epoch: 0, loss 0.14879140598903834\n",
      "Epoch: 0, loss 0.39372061920028345\n",
      "Epoch: 0, loss 0.3996936566256902\n",
      "Epoch: 0, loss 0.3970173653640901\n",
      "Epoch: 0, loss 0.3335363151926713\n",
      "Epoch: 0, loss 0.39492746825568825\n",
      "Epoch: 10, loss 0.11371131907888737\n",
      "Epoch: 10, loss 0.14199742766884244\n",
      "Epoch: 10, loss 0.14932905189964743\n",
      "Epoch: 10, loss 0.39238601860159894\n",
      "Epoch: 10, loss 0.3984288041358447\n",
      "Epoch: 10, loss 0.39571338033261505\n",
      "Epoch: 10, loss 0.33160561235205277\n",
      "Epoch: 10, loss 0.39358534299477876\n",
      "Epoch: 20, loss 0.11423521494412651\n",
      "Epoch: 20, loss 0.1424543816155216\n",
      "Epoch: 20, loss 0.14987972427291052\n",
      "Epoch: 20, loss 0.39104817168559347\n",
      "Epoch: 20, loss 0.39716259952396726\n",
      "Epoch: 20, loss 0.3944068083064324\n",
      "Epoch: 20, loss 0.32965847178665425\n",
      "Epoch: 20, loss 0.392239262587663\n",
      "Epoch: 30, loss 0.1147708543445799\n",
      "Epoch: 30, loss 0.14292221178622336\n",
      "Epoch: 30, loss 0.1504435375419785\n",
      "Epoch: 30, loss 0.38970725287320407\n",
      "Epoch: 30, loss 0.3958952947048312\n",
      "Epoch: 30, loss 0.3930978455285908\n",
      "Epoch: 30, loss 0.3276946584890721\n",
      "Epoch: 30, loss 0.39088935645810907\n",
      "Epoch: 40, loss 0.1153181640583191\n",
      "Epoch: 40, loss 0.14340095343227416\n",
      "Epoch: 40, loss 0.15102060687552557\n",
      "Epoch: 40, loss 0.3883634339853005\n",
      "Epoch: 40, loss 0.39462714266444765\n",
      "Epoch: 40, loss 0.39178668634150565\n",
      "Epoch: 40, loss 0.32571392401456695\n",
      "Epoch: 40, loss 0.3895357482764051\n",
      "Epoch: 50, loss 0.11587706265947381\n",
      "Epoch: 50, loss 0.14389063932707136\n",
      "Epoch: 50, loss 0.15161104845996257\n",
      "Epoch: 50, loss 0.3870168838287845\n",
      "Epoch: 50, loss 0.39335839723508753\n",
      "Epoch: 50, loss 0.39047352278409975\n",
      "Epoch: 50, loss 0.32371600614289286\n",
      "Epoch: 50, loss 0.3881785553080499\n",
      "Epoch: 60, loss 0.11644746049929007\n",
      "Epoch: 60, loss 0.14439129990712232\n",
      "Epoch: 60, loss 0.1522149798040151\n",
      "Epoch: 60, loss 0.3856677677732433\n",
      "Epoch: 60, loss 0.3920893128714418\n",
      "Epoch: 60, loss 0.389158544178284\n",
      "Epoch: 60, loss 0.3217006285797539\n",
      "Epoch: 60, loss 0.386817887734305\n",
      "Epoch: 70, loss 0.11702925969753657\n",
      "Epoch: 70, loss 0.14490296342873682\n",
      "Epoch: 70, loss 0.15283252006627693\n",
      "Epoch: 70, loss 0.38431624731820435\n",
      "Epoch: 70, loss 0.39082014442860935\n",
      "Epoch: 70, loss 0.38784193670461004\n",
      "Epoch: 70, loss 0.3196675007038281\n",
      "Epoch: 70, loss 0.38545384794313275\n",
      "Epoch: 80, loss 0.11762235414413726\n",
      "Epoch: 80, loss 0.14542565614069056\n",
      "Epoch: 80, loss 0.15346379040634023\n",
      "Epoch: 80, loss 0.38296247965100005\n",
      "Epoch: 80, loss 0.38955114694259885\n",
      "Epoch: 80, loss 0.3865238829668639\n",
      "Epoch: 80, loss 0.31761631736576956\n",
      "Epoch: 80, loss 0.3840865297888796\n",
      "Epoch: 90, loss 0.11822662951088383\n",
      "Epoch: 90, loss 0.14595940247315972\n",
      "Epoch: 90, loss 0.1541089143601067\n",
      "Epoch: 90, loss 0.3816066171951942\n",
      "Epoch: 90, loss 0.38828257541402117\n",
      "Epoch: 90, loss 0.3852045615452762\n",
      "Epoch: 90, loss 0.31554675874607324\n",
      "Epoch: 90, loss 0.3827160178188672\n",
      "Epoch: 100, loss 0.11884196327306568\n",
      "Epoch: 100, loss 0.14650422524322926\n",
      "Epoch: 100, loss 0.154768018239893\n",
      "Epoch: 100, loss 0.3802488071494554\n",
      "Epoch: 100, loss 0.3870146845956368\n",
      "Epoch: 100, loss 0.3838841465379397\n",
      "Epoch: 100, loss 0.31345849027918676\n",
      "Epoch: 100, loss 0.3813423864648442\n",
      "Epoch: 110, loss 0.11946822474083355\n",
      "Epoch: 110, loss 0.14706014587726515\n",
      "Epoch: 110, loss 0.1554412315599487\n",
      "Epoch: 110, loss 0.3788891910167016\n",
      "Epoch: 110, loss 0.38574772878440894\n",
      "Epoch: 110, loss 0.3825628070899227\n",
      "Epoch: 110, loss 0.31135116265175494\n",
      "Epoch: 110, loss 0.37996569919702206\n",
      "Epoch: 120, loss 0.12010527510010785\n",
      "Epoch: 120, loss 0.14762718465044974\n",
      "Epoch: 120, loss 0.15612868748802866\n",
      "Epoch: 120, loss 0.37752790412325354\n",
      "Epoch: 120, loss 0.38448196161869697\n",
      "Epoch: 120, loss 0.3812407069094458\n",
      "Epoch: 120, loss 0.30922441188339106\n",
      "Epoch: 120, loss 0.378586007638164\n",
      "Epoch: 130, loss 0.12075296746284556\n",
      "Epoch: 130, loss 0.14820536094378736\n",
      "Epoch: 130, loss 0.1568305233236908\n",
      "Epoch: 130, loss 0.3761650751276474\n",
      "Epoch: 130, loss 0.3832176358811966\n",
      "Epoch: 130, loss 0.37991800377036644\n",
      "Epoch: 130, loss 0.30707785949886346\n",
      "Epoch: 130, loss 0.3772033506349115\n",
      "Epoch: 140, loss 0.12141114692648353\n",
      "Epoch: 140, loss 0.1487946935189016\n",
      "Epoch: 140, loss 0.1575468810040272\n",
      "Epoch: 140, loss 0.37480082551865745\n",
      "Epoch: 140, loss 0.38195500330821874\n",
      "Epoch: 140, loss 0.3785948490000678\n",
      "Epoch: 140, loss 0.30491111280107774\n",
      "Epoch: 140, loss 0.37581775328322703\n",
      "Epoch: 150, loss 0.12207965064239551\n",
      "Epoch: 150, loss 0.14939520081097776\n",
      "Epoch: 150, loss 0.15827790763760047\n",
      "Epoch: 150, loss 0.37343526910195535\n",
      "Epoch: 150, loss 0.3806943144058567\n",
      "Epoch: 150, loss 0.3772713869516886\n",
      "Epoch: 150, loss 0.30272376525468525\n",
      "Epoch: 150, loss 0.3744292259044889\n",
      "Epoch: 160, loss 0.12275830789322756\n",
      "Epoch: 160, loss 0.15000690124023494\n",
      "Epoch: 160, loss 0.15902375606742092\n",
      "Epoch: 160, loss 0.3720685114747179\n",
      "Epoch: 160, loss 0.37943581827357625\n",
      "Epoch: 160, loss 0.37594775445945505\n",
      "Epoch: 160, loss 0.30051539699057733\n",
      "Epoch: 160, loss 0.37303776296839775\n",
      "Epoch: 170, loss 0.12344694017901697\n",
      "Epoch: 170, loss 0.15062981354237212\n",
      "Epoch: 170, loss 0.15978458546390578\n",
      "Epoch: 170, loss 0.3707006494873311\n",
      "Epoch: 170, loss 0.37817976243571655\n",
      "Epoch: 170, loss 0.374624080275673\n",
      "Epoch: 170, loss 0.2982855754418722\n",
      "Epoch: 170, loss 0.3716433419584366\n",
      "Epoch: 180, loss 0.1241453613120451\n",
      "Epoch: 180, loss 0.1512639571184929\n",
      "Epoch: 180, loss 0.1605605619488783\n",
      "Epoch: 180, loss 0.3693317706911854\n",
      "Epoch: 180, loss 0.37692639268136047\n",
      "Epoch: 180, loss 0.3733004844877182\n",
      "Epoch: 180, loss 0.29603385612229416\n",
      "Epoch: 180, loss 0.37024592217516367\n",
      "Epoch: 190, loss 0.12485337752044069\n",
      "Epoch: 190, loss 0.15190935240510725\n",
      "Epoch: 190, loss 0.1613518592518225\n",
      "Epoch: 190, loss 0.367961952771358\n",
      "Epoch: 190, loss 0.37567595291299205\n",
      "Epoch: 190, loss 0.37197707791311396\n",
      "Epoch: 190, loss 0.29375978355802246\n",
      "Epoch: 190, loss 0.3688454434720995\n",
      "Epoch: 200, loss 0.1255707875606238\n",
      "Epoch: 200, loss 0.15256602126491642\n",
      "Epoch: 200, loss 0.16215865939980553\n",
      "Epoch: 200, loss 0.366591262962767\n",
      "Epoch: 200, loss 0.3744286850043166\n",
      "Epoch: 200, loss 0.37065396147050295\n",
      "Epoch: 200, loss 0.2914628923841447\n",
      "Epoch: 200, loss 0.36744182491839583\n",
      "Epoch: 210, loss 0.12629738283876482\n",
      "Epoch: 210, loss 0.1532339873992255\n",
      "Epoch: 210, loss 0.16298115344271424\n",
      "Epoch: 210, loss 0.36521975744813273\n",
      "Epoch: 210, loss 0.37318482866758024\n",
      "Epoch: 210, loss 0.3693312255240123\n",
      "Epoch: 210, loss 0.28914270861675195\n",
      "Epoch: 210, loss 0.3660349633818266\n",
      "Epoch: 220, loss 0.12703294754153924\n",
      "Epoch: 220, loss 0.15391327678299854\n",
      "Epoch: 220, loss 0.1638195422157591\n",
      "Epoch: 220, loss 0.3638474807357954\n",
      "Epoch: 220, loss 0.3719446213306755\n",
      "Epoch: 220, loss 0.3680089491981445\n",
      "Epoch: 220, loss 0.2867987511114201\n",
      "Epoch: 220, loss 0.3646247320249128\n",
      "Epoch: 230, loss 0.12777725877656304\n",
      "Epoch: 230, loss 0.15460391812378\n",
      "Epoch: 230, loss 0.1646740371415523\n",
      "Epoch: 230, loss 0.362474465015118\n",
      "Epoch: 230, loss 0.370708298024281\n",
      "Epoch: 230, loss 0.3666871996599418\n",
      "Epoch: 230, loss 0.28443053321831346\n",
      "Epoch: 230, loss 0.3632109787061719\n",
      "Epoch: 240, loss 0.12853008672302813\n",
      "Epoch: 240, loss 0.15530594334595538\n",
      "Epoch: 240, loss 0.16554486107451796\n",
      "Epoch: 240, loss 0.36110072948681693\n",
      "Epoch: 240, loss 0.36947609127923065\n",
      "Epoch: 240, loss 0.36536603136469664\n",
      "Epoch: 240, loss 0.2820375646433602\n",
      "Epoch: 240, loss 0.3617935242775505\n",
      "Epoch: 250, loss 0.12929119479318765\n",
      "Epoch: 250, loss 0.15601938810213448\n",
      "Epoch: 250, loss 0.1664322491909235\n",
      "Epoch: 250, loss 0.3597262796651356\n",
      "Epoch: 250, loss 0.36824823103426785\n",
      "Epoch: 250, loss 0.364045485260974\n",
      "Epoch: 250, loss 0.27961935352386597\n",
      "Epoch: 250, loss 0.36037216076803075\n",
      "Epoch: 260, loss 0.13006033980549167\n",
      "Epoch: 260, loss 0.15674429231380077\n",
      "Epoch: 260, loss 0.16733644992847013\n",
      "Epoch: 260, loss 0.3583511066482591\n",
      "Epoch: 260, loss 0.36702494455428725\n",
      "Epoch: 260, loss 0.3627255879501028\n",
      "Epoch: 260, loss 0.27717540872548374\n",
      "Epoch: 260, loss 0.3589466494421847\n",
      "Epoch: 270, loss 0.13083727217033225\n",
      "Epoch: 270, loss 0.15748070074381024\n",
      "Epoch: 270, loss 0.16825772598015765\n",
      "Epoch: 270, loss 0.35697518635279\n",
      "Epoch: 270, loss 0.3658064563591297\n",
      "Epoch: 270, loss 0.36140635079461825\n",
      "Epoch: 270, loss 0.27470524236562704\n",
      "Epoch: 270, loss 0.35751671872105767\n",
      "Epoch: 280, loss 0.13162173608951747\n",
      "Epoch: 280, loss 0.15822866360384413\n",
      "Epoch: 280, loss 0.16919635534806948\n",
      "Epoch: 280, loss 0.3555984787074068\n",
      "Epoch: 280, loss 0.36459298816294444\n",
      "Epoch: 280, loss 0.3600877689693347\n",
      "Epoch: 280, loss 0.2722083725661145\n",
      "Epoch: 280, loss 0.3560820619511322\n",
      "Epoch: 290, loss 0.13241346977076895\n",
      "Epoch: 290, loss 0.15898823720053595\n",
      "Epoch: 290, loss 0.17015263246382845\n",
      "Epoch: 290, loss 0.3542209268000325\n",
      "Epoch: 290, loss 0.36338475882409926\n",
      "Epoch: 290, loss 0.3587698204478178\n",
      "Epoch: 290, loss 0.26968432643507123\n",
      "Epoch: 290, loss 0.35464233500526876\n",
      "Epoch: 300, loss 0.13321220565870584\n",
      "Epoch: 300, loss 0.159759484624722\n",
      "Epoch: 300, loss 0.1711268693837936\n",
      "Epoch: 300, loss 0.35284245597190134\n",
      "Epoch: 300, loss 0.36218198430557297\n",
      "Epoch: 300, loss 0.357452464915962\n",
      "Epoch: 300, loss 0.2671326432748016\n",
      "Epoch: 300, loss 0.35319715369733873\n",
      "Epoch: 310, loss 0.13401767068394982\n",
      "Epoch: 310, loss 0.16054247648912562\n",
      "Epoch: 310, loss 0.17211939706862106\n",
      "Epoch: 310, loss 0.3514629728508198\n",
      "Epoch: 310, loss 0.36098487764574216\n",
      "Epoch: 310, loss 0.35613564260313635\n",
      "Epoch: 310, loss 0.26455287800849436\n",
      "Epoch: 310, loss 0.3517460909897381\n",
      "Epoch: 320, loss 0.1348295865321574\n",
      "Epoch: 320, loss 0.1613372917207943\n",
      "Epoch: 320, loss 0.1731305667586518\n",
      "Epoch: 320, loss 0.3500823643146302\n",
      "Epoch: 320, loss 0.3597936489394338\n",
      "Epoch: 320, loss 0.3548192730199209\n",
      "Epoch: 320, loss 0.26194460481416826\n",
      "Epoch: 320, loss 0.3502886739700135\n",
      "Epoch: 330, loss 0.13564766993493377\n",
      "Epoch: 330, loss 0.16214401841579235\n",
      "Epoch: 330, loss 0.17416075145874388\n",
      "Epoch: 330, loss 0.3487004963743968\n",
      "Epoch: 330, loss 0.3586085053291022\n",
      "Epoch: 330, loss 0.35350325358976153\n",
      "Epoch: 330, loss 0.2593074209492406\n",
      "Epoch: 330, loss 0.3488243805693756\n",
      "Epoch: 340, loss 0.13647163298473342\n",
      "Epoch: 340, loss 0.16296275476503408\n",
      "Epoch: 340, loss 0.1752103475486959\n",
      "Epoch: 340, loss 0.347317212965073\n",
      "Epoch: 340, loss 0.3574296510059718\n",
      "Epoch: 340, loss 0.35218745815989316\n",
      "Epoch: 340, loss 0.2566409507434876\n",
      "Epoch: 340, loss 0.3473526359918151\n",
      "Epoch: 350, loss 0.13730118347597298\n",
      "Epoch: 350, loss 0.16379361006175389\n",
      "Epoch: 350, loss 0.17627977653836163\n",
      "Epoch: 350, loss 0.34593233462936546\n",
      "Epoch: 350, loss 0.35625728722098093\n",
      "Epoch: 350, loss 0.3508717353745563\n",
      "Epoch: 350, loss 0.2539448497320119\n",
      "Epoch: 350, loss 0.34587280881778537\n",
      "Epoch: 360, loss 0.1381360252746809\n",
      "Epoch: 360, loss 0.164636705802989\n",
      "Epoch: 360, loss 0.17736948698999555\n",
      "Epoch: 360, loss 0.3445456570781102\n",
      "Epoch: 360, loss 0.3550916123053679\n",
      "Epoch: 360, loss 0.3495559068907892\n",
      "Epoch: 360, loss 0.25121880889319753\n",
      "Epoch: 360, loss 0.3443842067408047\n",
      "Epoch: 370, loss 0.1389758587190773\n",
      "Epoch: 370, loss 0.1654921768996194\n",
      "Epoch: 370, loss 0.1784799566343569\n",
      "Epoch: 370, loss 0.34315694960767756\n",
      "Epoch: 370, loss 0.353932821700761\n",
      "Epoch: 370, loss 0.3482397654138729\n",
      "Epoch: 370, loss 0.24846255894962616\n",
      "Epoch: 370, loss 0.34288607188876546\n",
      "Epoch: 380, loss 0.13982038105350764\n",
      "Epoch: 380, loss 0.16636017301204273\n",
      "Epoch: 380, loss 0.179611694711732\n",
      "Epoch: 380, loss 0.34176595335165416\n",
      "Epoch: 380, loss 0.35278110799865947\n",
      "Epoch: 380, loss 0.34692307252569693\n",
      "Epoch: 380, loss 0.24567587468266255\n",
      "Epoch: 380, loss 0.34137757567398147\n",
      "Epoch: 390, loss 0.14066928689814626\n",
      "Epoch: 390, loss 0.1672408600314707\n",
      "Epoch: 390, loss 0.18076524457436252\n",
      "Epoch: 390, loss 0.34037237934023234\n",
      "Epoch: 390, loss 0.3516366609892433\n",
      "Epoch: 390, loss 0.34560555627484835\n",
      "Epoch: 390, loss 0.24285857920411713\n",
      "Epoch: 390, loss 0.3398578131068962\n",
      "Epoch: 400, loss 0.14152226875682994\n",
      "Epoch: 400, loss 0.16813442173020926\n",
      "Epoch: 400, loss 0.18194118659293063\n",
      "Epoch: 400, loss 0.33897590633628677\n",
      "Epoch: 400, loss 0.35049966771951\n",
      "Epoch: 400, loss 0.34428690849193533\n",
      "Epoch: 400, loss 0.24001054812124709\n",
      "Epoch: 400, loss 0.33832579649765127\n",
      "Epoch: 410, loss 0.1423790175652739\n",
      "Epoch: 410, loss 0.16904106160817486\n",
      "Epoch: 410, loss 0.18314014141681523\n",
      "Epoch: 410, loss 0.33757617841192566\n",
      "Epoch: 410, loss 0.34937031256081713\n",
      "Epoch: 410, loss 0.34296678178741213\n",
      "Epoch: 410, loss 0.23713171352469503\n",
      "Epoch: 410, loss 0.3367804484570909\n",
      "Epoch: 420, loss 0.14323922328176447\n",
      "Epoch: 420, loss 0.16996100496737726\n",
      "Epoch: 420, loss 0.18436277364595222\n",
      "Epoch: 420, loss 0.33617280222326107\n",
      "Epoch: 420, loss 0.3482487772860071\n",
      "Epoch: 420, loss 0.3416447861817813\n",
      "Epoch: 420, loss 0.2342220677231078\n",
      "Epoch: 420, loss 0.3352205940939546\n",
      "Epoch: 430, loss 0.14410257552221561\n",
      "Epoch: 430, loss 0.17089450125127423\n",
      "Epoch: 430, loss 0.18560979598142183\n",
      "Epoch: 430, loss 0.33476534393408364\n",
      "Epoch: 430, loss 0.34713524115641314\n",
      "Epoch: 430, loss 0.34032048530930653\n",
      "Epoch: 430, loss 0.2312816666435345\n",
      "Epoch: 430, loss 0.33364495228757085\n",
      "Epoch: 440, loss 0.14496876424120808\n",
      "Epoch: 440, loss 0.17184182669184672\n",
      "Epoch: 440, loss 0.18688197393251682\n",
      "Epoch: 440, loss 0.3333533257309249\n",
      "Epoch: 440, loss 0.3460298810191752\n",
      "Epoch: 440, loss 0.3389933921260031\n",
      "Epoch: 440, loss 0.22831063281374636\n",
      "Epoch: 440, loss 0.3320521258948975\n",
      "Epoch: 450, loss 0.14583748046032471\n",
      "Epoch: 450, loss 0.17280328731410494\n",
      "Epoch: 450, loss 0.1881801311701834\n",
      "Epoch: 450, loss 0.3319362218624131\n",
      "Epoch: 450, loss 0.3449328714154605\n",
      "Epoch: 450, loss 0.33766296404038487\n",
      "Epoch: 450, loss 0.2253091578418507\n",
      "Epoch: 450, loss 0.3304405907267529\n",
      "Epoch: 460, loss 0.14670841704474064\n",
      "Epoch: 460, loss 0.17377922235563906\n",
      "Epoch: 460, loss 0.18950515563058706\n",
      "Epoch: 460, loss 0.33051345412467925\n",
      "Epoch: 460, loss 0.3438443847003485\n",
      "Epoch: 460, loss 0.3363285973708624\n",
      "Epoch: 460, loss 0.22227750431057033\n",
      "Epoch: 460, loss 0.32880868309994626\n",
      "Epoch: 470, loss 0.1475812695286527\n",
      "Epoch: 470, loss 0.1747700081679453\n",
      "Epoch: 470, loss 0.1908580064883582\n",
      "Epoch: 470, loss 0.32908438670155715\n",
      "Epoch: 470, loss 0.3427645911753333\n",
      "Epoch: 470, loss 0.33498962101634905\n",
      "Epoch: 470, loss 0.21921600700892185\n",
      "Epoch: 470, loss 0.32715458573909495\n",
      "Epoch: 480, loss 0.14845573698972606\n",
      "Epoch: 480, loss 0.17577606267678797\n",
      "Epoch: 480, loss 0.19223972213709237\n",
      "Epoch: 480, loss 0.3276483202531508\n",
      "Epoch: 480, loss 0.3416936592345912\n",
      "Epoch: 480, loss 0.33364528920601255\n",
      "Epoch: 480, loss 0.21612507343341336\n",
      "Epoch: 480, loss 0.3254763117634571\n",
      "Epoch: 490, loss 0.1493315229723483\n",
      "Epoch: 490, loss 0.17679785049103652\n",
      "Epoch: 490, loss 0.1936514293352169\n",
      "Epoch: 490, loss 0.3262044851286152\n",
      "Epoch: 490, loss 0.34063175552636105\n",
      "Epoch: 490, loss 0.33229477316954337\n",
      "Epoch: 490, loss 0.21300518350495612\n",
      "Epoch: 490, loss 0.3237716864492409\n",
      "Epoch: 500, loss 0.15020833645909548\n",
      "Epoch: 500, loss 0.1778358887635052\n",
      "Epoch: 500, loss 0.19509435369871864\n",
      "Epoch: 500, loss 0.32475203355830073\n",
      "Epoch: 500, loss 0.33957904513098225\n",
      "Epoch: 500, loss 0.330937151540029\n",
      "Epoch: 500, loss 0.209856888467174\n",
      "Epoch: 500, loss 0.3220383264056632\n",
      "Epoch: 510, loss 0.1510858928894786\n",
      "Epoch: 510, loss 0.17889075392366238\n",
      "Epoch: 510, loss 0.196569831748853\n",
      "Epoch: 510, loss 0.32329003065620254\n",
      "Epoch: 510, loss 0.33853569175730625\n",
      "Epoch: 510, loss 0.3295713992665473\n",
      "Epoch: 510, loss 0.20668080895739627\n",
      "Epoch: 510, loss 0.32027361574246194\n",
      "Epoch: 520, loss 0.15196391522476635\n",
      "Epoch: 520, loss 0.17996308942102568\n",
      "Epoch: 520, loss 0.1980793247532024\n",
      "Epoch: 520, loss 0.3218174440353677\n",
      "Epoch: 520, loss 0.3375018579593383\n",
      "Epoch: 520, loss 0.32819637477181035\n",
      "Epoch: 520, loss 0.20347763227413446\n",
      "Epoch: 520, loss 0.3184746787365945\n",
      "Epoch: 530, loss 0.15284213505747818\n",
      "Epoch: 530, loss 0.18105361464003772\n",
      "Epoch: 530, loss 0.19962443463274715\n",
      "Epoch: 530, loss 0.3203331318058331\n",
      "Epoch: 530, loss 0.3364777053750506\n",
      "Epoch: 530, loss 0.32681080504021787\n",
      "Epoch: 530, loss 0.20024810890508438\n",
      "Epoch: 530, loss 0.31663834842538907\n",
      "Epoch: 540, loss 0.15372029376406376\n",
      "Epoch: 540, loss 0.18216313517272273\n",
      "Epoch: 540, loss 0.20120692224634718\n",
      "Epoch: 540, loss 0.3188358286860352\n",
      "Epoch: 540, loss 0.3354633949892894\n",
      "Epoch: 540, loss 0.325413268261878\n",
      "Epoch: 540, loss 0.1969930484285498\n",
      "Epoch: 540, loss 0.3147611304615606\n",
      "Epoch: 550, loss 0.15459814369928743\n",
      "Epoch: 550, loss 0.183292554664922\n",
      "Epoch: 550, loss 0.20282872840747712\n",
      "Epoch: 550, loss 0.3173241299136317\n",
      "Epoch: 550, loss 0.3344590874225735\n",
      "Epoch: 550, loss 0.32400217358664124\n",
      "Epoch: 550, loss 0.19371331495975663\n",
      "Epoch: 550, loss 0.31283916146167173\n",
      "Epoch: 560, loss 0.1554754494309752\n",
      "Epoch: 560, loss 0.1844428884859471\n",
      "Epoch: 560, loss 0.20449199803634438\n",
      "Epoch: 560, loss 0.315796472589391\n",
      "Epoch: 560, loss 0.33346494324724807\n",
      "Epoch: 560, loss 0.3225757374567009\n",
      "Epoch: 560, loss 0.19040982238301624\n",
      "Epoch: 560, loss 0.3108681609638293\n",
      "Epoch: 570, loss 0.1563519890139886\n",
      "Epoch: 570, loss 0.18561527951049617\n",
      "Epoch: 570, loss 0.2061991079033606\n",
      "Epoch: 570, loss 0.31425111402746797\n",
      "Epoch: 570, loss 0.33248112333189106\n",
      "Epoch: 570, loss 0.3211319558843627\n",
      "Epoch: 570, loss 0.18708352969273356\n",
      "Epoch: 570, loss 0.3088433759839272\n",
      "Epoch: 580, loss 0.15722755530254479\n",
      "Epoch: 580, loss 0.18681101634598046\n",
      "Epoch: 580, loss 0.2079526984764446\n",
      "Epoch: 580, loss 0.3126861066163152\n",
      "Epoch: 580, loss 0.33150778921394086\n",
      "Epoch: 580, loss 0.3196685719204053\n",
      "Epoch: 580, loss 0.1837354368627706\n",
      "Epoch: 580, loss 0.30675951702571413\n",
      "Epoch: 590, loss 0.15810195730019797\n",
      "Epoch: 590, loss 0.18803155438796584\n",
      "Epoch: 590, loss 0.20975571044283792\n",
      "Epoch: 590, loss 0.31109926861649323\n",
      "Epoch: 590, loss 0.33054510349911337\n",
      "Epoch: 590, loss 0.3181830374152277\n",
      "Epoch: 590, loss 0.18036658177724446\n",
      "Epoch: 590, loss 0.3046106842648729\n",
      "Epoch: 600, loss 0.15897502154680887\n",
      "Epoch: 600, loss 0.18927854014068074\n",
      "Epoch: 600, loss 0.2116114265323884\n",
      "Epoch: 600, loss 0.3094881502352957\n",
      "Epoch: 600, loss 0.32959323028412124\n",
      "Epoch: 600, loss 0.31667246800712473\n",
      "Epoch: 600, loss 0.17697803888959385\n",
      "Epoch: 600, loss 0.3023902825027718\n",
      "Epoch: 610, loss 0.1598465935413898\n",
      "Epoch: 610, loss 0.19055383929682868\n",
      "Epoch: 610, loss 0.21352351931722396\n",
      "Epoch: 610, loss 0.30784999422548487\n",
      "Epoch: 610, loss 0.3286523355962879\n",
      "Epoch: 610, loss 0.3151335900778379\n",
      "Epoch: 610, loss 0.17357092043466482\n",
      "Epoch: 610, loss 0.30009092339154\n",
      "Epoch: 620, loss 0.1607165391985293\n",
      "Epoch: 620, loss 0.19185956912800203\n",
      "Epoch: 620, loss 0.21549610569198335\n",
      "Epoch: 620, loss 0.30618169016097335\n",
      "Epoch: 620, loss 0.3277225878395106\n",
      "Epoch: 620, loss 0.3135626781951097\n",
      "Epoch: 620, loss 0.17014638120526981\n",
      "Epoch: 620, loss 0.29770431340126896\n",
      "Epoch: 630, loss 0.16158474633360043\n",
      "Epoch: 630, loss 0.1931981357877656\n",
      "Epoch: 630, loss 0.21753380873239772\n",
      "Epoch: 630, loss 0.3044797214545736\n",
      "Epoch: 630, loss 0.3268041582303299\n",
      "Epoch: 630, loss 0.31195548131921713\n",
      "Epoch: 630, loss 0.16670562812541015\n",
      "Epoch: 630, loss 0.2952211260848503\n",
      "Epoch: 640, loss 0.16245112616746438\n",
      "Epoch: 640, loss 0.1945722771636521\n",
      "Epoch: 640, loss 0.21964182756176726\n",
      "Epoch: 640, loss 0.302740104116904\n",
      "Epoch: 640, loss 0.3258972211999589\n",
      "Epoch: 640, loss 0.3103071357957653\n",
      "Epoch: 640, loss 0.16324993611232536\n",
      "Epoch: 640, loss 0.29263085747824535\n",
      "Epoch: 650, loss 0.16331561483375892\n",
      "Epoch: 650, loss 0.19598511191478113\n",
      "Epoch: 650, loss 0.22182601568405352\n",
      "Epoch: 650, loss 0.3009583162364805\n",
      "Epoch: 650, loss 0.32500195472740134\n",
      "Epoch: 650, loss 0.308612062912342\n",
      "Epoch: 650, loss 0.15978067202294838\n",
      "Epoch: 650, loss 0.28992166408048947\n",
      "Epoch: 660, loss 0.16417817485963854\n",
      "Epoch: 660, loss 0.19744019527126191\n",
      "Epoch: 660, loss 0.22409296790754124\n",
      "Epoch: 660, loss 0.2991292172298885\n",
      "Epoch: 660, loss 0.3241185405542073\n",
      "Epoch: 660, loss 0.3068638486029279\n",
      "Epoch: 660, loss 0.1562993288281605\n",
      "Epoch: 660, loss 0.28708018398044\n",
      "Epoch: 670, loss 0.16503879657182086\n",
      "Epoch: 670, loss 0.19894158200709583\n",
      "Epoch: 670, loss 0.22645011539266735\n",
      "Epoch: 670, loss 0.2972469561329208\n",
      "Epoch: 670, loss 0.3232471642118753\n",
      "Epoch: 670, loss 0.30505510281340287\n",
      "Epoch: 670, loss 0.15280757254468927\n",
      "Epoch: 670, loss 0.2840913436227956\n",
      "Epoch: 680, loss 0.1658974993509768\n",
      "Epoch: 680, loss 0.20049389666426878\n",
      "Epoch: 680, loss 0.22890582737763027\n",
      "Epoch: 680, loss 0.2953048686797249\n",
      "Epoch: 680, loss 0.32238801476693313\n",
      "Epoch: 680, loss 0.3031772962157798\n",
      "Epoch: 680, loss 0.14930730486077215\n",
      "Epoch: 680, loss 0.28093815585332743\n",
      "Epoch: 690, loss 0.1667543326147714\n",
      "Epoch: 690, loss 0.2021024105034849\n",
      "Epoch: 690, loss 0.2314695165736701\n",
      "Epoch: 690, loss 0.29329536380081833\n",
      "Epoch: 690, loss 0.32154128415471656\n",
      "Epoch: 690, loss 0.30122057257674084\n",
      "Epoch: 690, loss 0.14580074477624552\n",
      "Epoch: 690, loss 0.2776015198506185\n",
      "Epoch: 700, loss 0.16760937634762624\n",
      "Epoch: 700, loss 0.20377312364211508\n",
      "Epoch: 700, loss 0.23415174281080103\n",
      "Epoch: 700, loss 0.2912098016895517\n",
      "Epoch: 700, loss 0.32070716592918036\n",
      "Epoch: 700, loss 0.2991735364629228\n",
      "Epoch: 700, loss 0.14229053286073826\n",
      "Epoch: 700, loss 0.2740600411631645\n",
      "Epoch: 710, loss 0.1684627409064292\n",
      "Epoch: 710, loss 0.20551284920748739\n",
      "Epoch: 710, loss 0.23696430589582948\n",
      "Epoch: 710, loss 0.28903836806638217\n",
      "Epoch: 710, loss 0.31988585320154217\n",
      "Epoch: 710, loss 0.2970230185863234\n",
      "Epoch: 710, loss 0.13877986177469834\n",
      "Epoch: 710, loss 0.2702899014060456\n",
      "Epoch: 720, loss 0.16931456570721598\n",
      "Epoch: 720, loss 0.20732929380513906\n",
      "Epoch: 720, loss 0.23992031336578906\n",
      "Epoch: 720, loss 0.2867699531596782\n",
      "Epoch: 720, loss 0.31907753547537165\n",
      "Epoch: 720, loss 0.29475382567826186\n",
      "Epoch: 720, loss 0.13527263626477695\n",
      "Epoch: 720, loss 0.2662648235304639\n",
      "Epoch: 730, loss 0.17016501622884128\n",
      "Epoch: 730, loss 0.20923112482291933\n",
      "Epoch: 730, loss 0.24303420136796677\n",
      "Epoch: 730, loss 0.2843920497991139\n",
      "Epoch: 730, loss 0.3182823940131691\n",
      "Epoch: 730, loss 0.29234848934866836\n",
      "Epoch: 730, loss 0.1317736645749424\n",
      "Epoch: 730, loss 0.2619562012914229\n",
      "Epoch: 740, loss 0.1710142785478141\n",
      "Epoch: 740, loss 0.211228009660976\n",
      "Epoch: 740, loss 0.24632167680531436\n",
      "Epoch: 740, loss 0.2818906935514192\n",
      "Epoch: 740, loss 0.31750059529882146\n",
      "Epoch: 740, loss 0.28978704028324276\n",
      "Epoch: 740, loss 0.12828888057587176\n",
      "Epoch: 740, loss 0.2573334914454465\n",
      "Epoch: 750, loss 0.17186255034219053\n",
      "Epoch: 750, loss 0.2133306045395408\n",
      "Epoch: 750, loss 0.24979953598617788\n",
      "Epoch: 750, loss 0.27925047962951755\n",
      "Epoch: 750, loss 0.3167322821115175\n",
      "Epoch: 750, loss 0.28704685192686086\n",
      "Epoch: 750, loss 0.12482559118948475\n",
      "Epoch: 750, loss 0.2523650035514255\n",
      "Epoch: 760, loss 0.17271002698612453\n",
      "Epoch: 760, loss 0.21555046100362127\n",
      "Epoch: 760, loss 0.25348529994498314\n",
      "Epoch: 760, loss 0.2764547065725833\n",
      "Epoch: 760, loss 0.3159775617369332\n",
      "Epoch: 760, loss 0.28410262291454536\n",
      "Epoch: 760, loss 0.12139273601850786\n",
      "Epoch: 760, loss 0.24701926058622004\n",
      "Epoch: 770, loss 0.17355688104714823\n",
      "Epoch: 770, loss 0.21789980722519758\n",
      "Epoch: 770, loss 0.25739659165335893\n",
      "Epoch: 770, loss 0.2734857145039236\n",
      "Epoch: 770, loss 0.31523649097268563\n",
      "Epoch: 770, loss 0.2809266002557572\n",
      "Epoch: 770, loss 0.11800113469536534\n",
      "Epoch: 770, loss 0.24126713247872805\n",
      "Epoch: 780, loss 0.174403233298571\n",
      "Epoch: 780, loss 0.22039115071165782\n",
      "Epoch: 780, loss 0.2615501707263693\n",
      "Epoch: 780, loss 0.2703255028956624\n",
      "Epoch: 780, loss 0.3145090579289691\n",
      "Epoch: 780, loss 0.27748918299272884\n",
      "Epoch: 780, loss 0.11466368210407633\n",
      "Epoch: 780, loss 0.2350849413482289\n",
      "Epoch: 790, loss 0.17524911345603433\n",
      "Epoch: 790, loss 0.22303664342228863\n",
      "Epoch: 790, loss 0.2659605464167057\n",
      "Epoch: 790, loss 0.266956722047069\n",
      "Epoch: 790, loss 0.31379516129764184\n",
      "Epoch: 790, loss 0.27376008005263486\n",
      "Epoch: 790, loss 0.11139543351197516\n",
      "Epoch: 790, loss 0.22845866424709016\n",
      "Epoch: 800, loss 0.1760944095239383\n",
      "Epoch: 800, loss 0.22584715708592829\n",
      "Epoch: 800, loss 0.2706381238956756\n",
      "Epoch: 800, loss 0.26336412138382537\n",
      "Epoch: 800, loss 0.31309458887100017\n",
      "Epoch: 800, loss 0.2697102077925432\n",
      "Epoch: 800, loss 0.10821350472480498\n",
      "Epoch: 800, loss 0.22138916716206475\n",
      "Epoch: 810, loss 0.1769388062382553\n",
      "Epoch: 810, loss 0.22883104605025256\n",
      "Epoch: 810, loss 0.2755869185353779\n",
      "Epoch: 810, loss 0.2595364887061827\n",
      "Epoch: 810, loss 0.31240699865588356\n",
      "Epoch: 810, loss 0.26531447166186356\n",
      "Epoch: 810, loss 0.10513670458984196\n",
      "Epoch: 810, loss 0.2138980498380852\n",
      "Epoch: 820, loss 0.17778171587889352\n",
      "Epoch: 820, loss 0.2319926372954147\n",
      "Epoch: 820, loss 0.2808020086100912\n",
      "Epoch: 820, loss 0.2554690104416203\n",
      "Epoch: 820, loss 0.3117319077534553\n",
      "Epoch: 820, loss 0.2605554440565863\n",
      "Epoch: 820, loss 0.1021848303838785\n",
      "Epoch: 820, loss 0.20603317128834187\n",
      "Epoch: 830, loss 0.17862220859135214\n",
      "Epoch: 830, loss 0.23533058439331095\n",
      "Epoch: 830, loss 0.28626707752149627\n",
      "Epoch: 830, loss 0.25116581991558884\n",
      "Epoch: 830, loss 0.31106869570407225\n",
      "Epoch: 830, loss 0.2554276989296202\n",
      "Epoch: 830, loss 0.09937760315792021\n",
      "Epoch: 830, loss 0.19787238124008633\n",
      "Epoch: 840, loss 0.17945895347735058\n",
      "Epoch: 840, loss 0.23883633736872395\n",
      "Epoch: 840, loss 0.29195257248573003\n",
      "Epoch: 840, loss 0.24664230734066345\n",
      "Epoch: 840, loss 0.31041662928436264\n",
      "Epoch: 840, loss 0.24994221109886672\n",
      "Epoch: 840, loss 0.0967333042949888\n",
      "Epoch: 840, loss 0.18952368069787284\n",
      "Epoch: 850, loss 0.18029018440654843\n",
      "Epoch: 850, loss 0.24249307080579366\n",
      "Epoch: 850, loss 0.29781508630062914\n",
      "Epoch: 850, loss 0.24192661592380943\n",
      "Epoch: 850, loss 0.3097749137217674\n",
      "Epoch: 850, loss 0.24412987650068257\n",
      "Epoch: 850, loss 0.09426728146361543\n",
      "Epoch: 850, loss 0.1811203449307499\n",
      "Epoch: 860, loss 0.18111370373945346\n",
      "Epoch: 860, loss 0.24627541886165344\n",
      "Epoch: 860, loss 0.30379845329941796\n",
      "Epoch: 860, loss 0.23705974712254302\n",
      "Epoch: 860, loss 0.3091427704111299\n",
      "Epoch: 860, loss 0.23804304533287618\n",
      "Epoch: 860, loss 0.09199058250777158\n",
      "Epoch: 860, loss 0.17281068888932866\n",
      "Epoch: 870, loss 0.18192693182356162\n",
      "Epoch: 870, loss 0.25015024554564097\n",
      "Epoch: 870, loss 0.3098367043289064\n",
      "Epoch: 870, loss 0.23209391968023768\n",
      "Epoch: 870, loss 0.30851953418257455\n",
      "Epoch: 870, loss 0.23175417331916265\n",
      "Epoch: 870, loss 0.08990899864789033\n",
      "Epoch: 870, loss 0.16474390399661668\n",
      "Epoch: 880, loss 0.18272700130030928\n",
      "Epoch: 880, loss 0.2540784467779696\n",
      "Epoch: 880, loss 0.31585853922929735\n",
      "Epoch: 880, loss 0.22708924378209785\n",
      "Epoch: 880, loss 0.30790475612498563\n",
      "Epoch: 880, loss 0.22535133459190476\n",
      "Epoch: 880, loss 0.08802272285310322\n",
      "Epoch: 880, loss 0.15705497384078249\n",
      "Epoch: 890, loss 0.18351088611949323\n",
      "Epoch: 890, loss 0.25801752075820805\n",
      "Epoch: 890, loss 0.32179254811650304\n",
      "Epoch: 890, loss 0.22210923141609085\n",
      "Epoch: 890, loss 0.30729829368844785\n",
      "Epoch: 890, loss 0.2189312063810941\n",
      "Epoch: 890, loss 0.08632667424793111\n",
      "Epoch: 890, loss 0.14985218348996243\n",
      "Epoch: 900, loss 0.18427554912603608\n",
      "Epoch: 900, loss 0.26192446388375457\n",
      "Epoch: 900, loss 0.32757223753084264\n",
      "Epoch: 900, loss 0.21721596686073574\n",
      "Epoch: 900, loss 0.30670037024433233\n",
      "Epoch: 900, loss 0.21259086041337757\n",
      "Epoch: 900, loss 0.08481137046148611\n",
      "Epoch: 900, loss 0.14320982149812853\n",
      "Epoch: 910, loss 0.1850180906481284\n",
      "Epoch: 910, loss 0.26575851689650754\n",
      "Epoch: 910, loss 0.33314005391077606\n",
      "Epoch: 910, loss 0.212465785639075\n",
      "Epoch: 910, loss 0.306111591622929\n",
      "Epoch: 910, loss 0.20641995917688233\n",
      "Epoch: 910, loss 0.08346411864424526\n",
      "Epoch: 910, loss 0.13716684466572276\n",
      "Epoch: 920, loss 0.1857358827552593\n",
      "Epoch: 920, loss 0.2694833884166643\n",
      "Epoch: 920, loss 0.3384499453492035\n",
      "Epoch: 920, loss 0.2079060817975184\n",
      "Epoch: 920, loss 0.30553291573605834\n",
      "Epoch: 920, loss 0.20049468610546323\n",
      "Epoch: 920, loss 0.0822702758241067\n",
      "Epoch: 920, loss 0.13173050729539876\n",
      "Epoch: 930, loss 0.18642667785602768\n",
      "Epoch: 930, loss 0.27306875430128635\n",
      "Epoch: 930, loss 0.34346839136603713\n",
      "Epoch: 930, loss 0.20357351440362476\n",
      "Epoch: 930, loss 0.304965580625149\n",
      "Epoch: 930, loss 0.1948741246117598\n",
      "Epoch: 930, loss 0.08121438376179928\n",
      "Epoch: 930, loss 0.12688298218098393\n",
      "Epoch: 940, loss 0.18708868470540907\n",
      "Epoch: 940, loss 0.2764910003198184\n",
      "Epoch: 940, loss 0.34817412447810836\n",
      "Epoch: 940, loss 0.19949355826531878\n",
      "Epoch: 940, loss 0.3044110035985753\n",
      "Epoch: 940, loss 0.18959913298581182\n",
      "Epoch: 940, loss 0.08028106941473681\n",
      "Epoch: 940, loss 0.12258894530453404\n",
      "Epoch: 950, loss 0.1877206091917737\n",
      "Epoch: 950, loss 0.27973329951978454\n",
      "Epoch: 950, loss 0.3525569167605963\n",
      "Epoch: 950, loss 0.19568112716158645\n",
      "Epoch: 950, loss 0.30387066783794064\n",
      "Epoch: 950, loss 0.18469326695044708\n",
      "Epoch: 950, loss 0.07945568086940322\n",
      "Epoch: 950, loss 0.11880262929101697\n",
      "Epoch: 960, loss 0.18832166126928074\n",
      "Epoch: 960, loss 0.2827851828460259\n",
      "Epoch: 960, loss 0.3566158275582534\n",
      "Epoch: 960, loss 0.1921419079199908\n",
      "Epoch: 960, loss 0.30334601256341664\n",
      "Epoch: 960, loss 0.1801650663070367\n",
      "Epoch: 960, loss 0.0787246812208898\n",
      "Epoch: 960, loss 0.11547354502864693\n",
      "Epoch: 970, loss 0.1888915327289439\n",
      "Epoch: 970, loss 0.2856417799802067\n",
      "Epoch: 970, loss 0.3603572515325832\n",
      "Epoch: 970, loss 0.18887405388525946\n",
      "Epoch: 970, loss 0.3028383393927059\n",
      "Epoch: 970, loss 0.17601101551966278\n",
      "Epoch: 970, loss 0.07807584814977218\n",
      "Epoch: 970, loss 0.11255064357174008\n",
      "Epoch: 980, loss 0.18943035271525338\n",
      "Epoch: 980, loss 0.28830289220785604\n",
      "Epoch: 980, loss 0.363793014714066\n",
      "Epoch: 980, loss 0.18586995499174946\n",
      "Epoch: 980, loss 0.30234874245939236\n",
      "Epoch: 980, loss 0.17221862260242848\n",
      "Epoch: 980, loss 0.07749833239041158\n",
      "Epoch: 980, loss 0.10998504464146833\n",
      "Epoch: 990, loss 0.18993862875628734\n",
      "Epoch: 990, loss 0.29077202585112916\n",
      "Epoch: 990, loss 0.36693867225553606\n",
      "Epoch: 990, loss 0.18311789104196935\n",
      "Epoch: 990, loss 0.30187806475063084\n",
      "Epoch: 990, loss 0.16876924670022567\n",
      "Epoch: 990, loss 0.07698262271561448\n",
      "Epoch: 990, loss 0.10773161670588242\n"
     ]
    }
   ],
   "source": [
    "def train(lr: float) -> None:\n",
    "    for epoch in range(1000):\n",
    "        for x_batch, t_batch in zip(train_x_data, train_t_data_onehot):\n",
    "            y_data = model_back(x_batch)\n",
    "            loss = mean_square_error(y_data, t_batch)\n",
    "            \n",
    "            # backpropagation\n",
    "            round_E_round_b3 = np.array([..., ...])\n",
    "            round_E_round_W3 = ...\n",
    "            model_back.W3 -= lr * round_E_round_W3\n",
    "            model_back.b3 -= lr * round_E_round_b3\n",
    "            \n",
    "            round_E_round_b2 = ...\n",
    "            round_E_round_W2 = ...\n",
    "            model_back.W2 -= lr * round_E_round_W2\n",
    "            model_back.b2 -= - lr * round_E_round_b2\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch: {epoch}, loss {loss}')\n",
    "\n",
    "\n",
    "train(lr=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 학습 속도 비교\n",
    "\n",
    "오차역전파를 가중치 갱신에 사용한 문제 6과 수치미분을 가중치 갱신에 사용한 문제7 간의 속도를 비교해보시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss 0.3249954391495161\n",
      "Epoch: 0, loss 0.3208688095209839\n",
      "Epoch: 0, loss 0.31797531572201915\n",
      "Epoch: 0, loss 0.20321007933273952\n",
      "Epoch: 0, loss 0.20003363999285848\n",
      "Epoch: 0, loss 0.2021358207198346\n",
      "Epoch: 0, loss 0.21911266216756606\n",
      "Epoch: 0, loss 0.20373353819646461\n",
      "Epoch: 10, loss 0.3256108778297751\n",
      "Epoch: 10, loss 0.3215180902193899\n",
      "Epoch: 10, loss 0.31867004807073546\n",
      "Epoch: 10, loss 0.20182796591046936\n",
      "Epoch: 10, loss 0.1987203804711819\n",
      "Epoch: 10, loss 0.20075185867363332\n",
      "Epoch: 10, loss 0.21734963907762572\n",
      "Epoch: 10, loss 0.20226293793226569\n",
      "Epoch: 20, loss 0.32622719737129924\n",
      "Epoch: 20, loss 0.32216671576965983\n",
      "Epoch: 20, loss 0.3193624531305483\n",
      "Epoch: 20, loss 0.20046963596265716\n",
      "Epoch: 20, loss 0.19742817566107906\n",
      "Epoch: 20, loss 0.19939257410219693\n",
      "Epoch: 20, loss 0.2156192007150933\n",
      "Epoch: 20, loss 0.20082236440899173\n",
      "Epoch: 30, loss 0.3268439758023222\n",
      "Epoch: 30, loss 0.3228143333765377\n",
      "Epoch: 30, loss 0.3200522426322927\n",
      "Epoch: 30, loss 0.1991350205519084\n",
      "Epoch: 30, loss 0.19615707502218352\n",
      "Epoch: 30, loss 0.19805780829054073\n",
      "Epoch: 30, loss 0.2139215479172244\n",
      "Epoch: 30, loss 0.19941131745113033\n",
      "Epoch: 40, loss 0.32746080503948566\n",
      "Epoch: 40, loss 0.32346060191805137\n",
      "Epoch: 40, loss 0.32073913885365457\n",
      "Epoch: 40, loss 0.19782402720146947\n",
      "Epoch: 40, loss 0.19490710072003226\n",
      "Epoch: 40, loss 0.19674738642403639\n",
      "Epoch: 40, loss 0.21225678164951212\n",
      "Epoch: 40, loss 0.19802929882612713\n",
      "Epoch: 50, loss 0.32807729126742485\n",
      "Epoch: 50, loss 0.3241051922785587\n",
      "Epoch: 50, loss 0.321422874761252\n",
      "Epoch: 50, loss 0.1965365413015376\n",
      "Epoch: 50, loss 0.19367824888043023\n",
      "Epoch: 50, loss 0.1954611185102244\n",
      "Epoch: 50, loss 0.2106249123814026\n",
      "Epoch: 50, loss 0.19667581314236232\n",
      "Epoch: 60, loss 0.3286930552337491\n",
      "Epoch: 60, loss 0.3247477876115253\n",
      "Epoch: 60, loss 0.32210319411207367\n",
      "Epoch: 60, loss 0.19527242749883753\n",
      "Epoch: 60, loss 0.19247049087420331\n",
      "Epoch: 60, loss 0.19419880029178466\n",
      "Epoch: 60, loss 0.20902586916767515\n",
      "Epoch: 60, loss 0.19535036851955087\n",
      "Epoch: 70, loss 0.32930773246479633\n",
      "Epoch: 70, loss 0.32538808353680865\n",
      "Epoch: 70, loss 0.3227798515175062\n",
      "Epoch: 70, loss 0.19403153106319418\n",
      "Epoch: 70, loss 0.1912837746211634\n",
      "Epoch: 70, loss 0.1929602141493378\n",
      "Epoch: 70, loss 0.20745950833473245\n",
      "Epoch: 70, loss 0.19405247707780915\n",
      "Epoch: 80, loss 0.3299209734077326\n",
      "Epoch: 80, loss 0.3260257882772374\n",
      "Epoch: 80, loss 0.3234526124729281\n",
      "Epoch: 80, loss 0.19281367922573497\n",
      "Epoch: 80, loss 0.1901180259030644\n",
      "Epoch: 80, loss 0.19174512999253684\n",
      "Epoch: 80, loss 0.20592562169886403\n",
      "Epoch: 80, loss 0.19278165528459032\n",
      "Epoch: 90, loss 0.33053244350459376\n",
      "Epoch: 90, loss 0.3266606227391734\n",
      "Epoch: 90, loss 0.3241212533555702\n",
      "Epoch: 90, loss 0.1916186824842033\n",
      "Epoch: 90, loss 0.18897314967630885\n",
      "Epoch: 90, loss 0.1905533061377614\n",
      "Epoch: 90, loss 0.2044239442677468\n",
      "Epoch: 90, loss 0.1915374241923128\n",
      "Epoch: 100, loss 0.3311418232038736\n",
      "Epoch: 100, loss 0.32729232054163465\n",
      "Epoch: 100, loss 0.3247855613931054\n",
      "Epoch: 100, loss 0.19044633587165963\n",
      "Epoch: 100, loss 0.18784903137616446\n",
      "Epoch: 100, loss 0.18938449017067352\n",
      "Epoch: 100, loss 0.202954161397023\n",
      "Epoch: 100, loss 0.1903193095938277\n",
      "Epoch: 110, loss 0.33174880791513917\n",
      "Epoch: 110, loss 0.3279206279983674\n",
      "Epoch: 110, loss 0.3254453346051937\n",
      "Epoch: 110, loss 0.18929642018556858\n",
      "Epoch: 110, loss 0.18674553820522916\n",
      "Epoch: 110, loss 0.18823841979188694\n",
      "Epoch: 110, loss 0.2015159153907708\n",
      "Epoch: 110, loss 0.18912684211787523\n",
      "Epoch: 120, loss 0.3323531079120221\n",
      "Epoch: 120, loss 0.32854530405709303\n",
      "Epoch: 120, loss 0.32610038172003525\n",
      "Epoch: 120, loss 0.18816870317490708\n",
      "Epoch: 120, loss 0.18566252039981648\n",
      "Epoch: 120, loss 0.18711482364403495\n",
      "Epoch: 120, loss 0.20010881154827104\n",
      "Epoch: 120, loss 0.1879595572823251\n",
      "Epoch: 130, loss 0.33295444818871356\n",
      "Epoch: 130, loss 0.3291661201999156\n",
      "Epoch: 130, loss 0.32675052206780164\n",
      "Epoch: 130, loss 0.18706294068352813\n",
      "Epoch: 130, loss 0.18459981246886706\n",
      "Epoch: 130, loss 0.18601342211863\n",
      "Epoch: 130, loss 0.19873242367007984\n",
      "Epoch: 130, loss 0.1868169955192952\n",
      "Epoch: 140, loss 0.33355256827489127\n",
      "Epoch: 140, loss 0.3297828603087152\n",
      "Epoch: 140, loss 0.32739558545273106\n",
      "Epoch: 140, loss 0.18597887774848737\n",
      "Epoch: 140, loss 0.18355723440080074\n",
      "Epoch: 140, loss 0.18493392814117796\n",
      "Epoch: 140, loss 0.19738629904427277\n",
      "Epoch: 140, loss 0.18569870218304815\n",
      "Epoch: 150, loss 0.33414722201373254\n",
      "Epoch: 150, loss 0.33039532049910475\n",
      "Epoch: 150, loss 0.3280354120055342\n",
      "Epoch: 150, loss 0.18491624965251113\n",
      "Epoch: 150, loss 0.18253459283454188\n",
      "Epoch: 150, loss 0.18387604793317608\n",
      "Epoch: 150, loss 0.19606996293936627\n",
      "Epoch: 150, loss 0.1846042275489453\n",
      "Epoch: 160, loss 0.3347381773074374\n",
      "Epoch: 160, loss 0.33100330892636026\n",
      "Epoch: 160, loss 0.3286698520177304\n",
      "Epoch: 160, loss 0.18387478293013804\n",
      "Epoch: 160, loss 0.18153168219164798\n",
      "Epoch: 160, loss 0.1828394817497431\n",
      "Epoch: 160, loss 0.19478292263407504\n",
      "Epoch: 160, loss 0.183533126809533\n",
      "Epoch: 170, loss 0.335325215834371\n",
      "Epoch: 170, loss 0.33160664556649505\n",
      "Epoch: 170, loss 0.3292987657594254\n",
      "Epoch: 170, loss 0.18285419632742891\n",
      "Epoch: 170, loss 0.1805482857671547\n",
      "Epoch: 170, loss 0.1818239245918175\n",
      "Epoch: 170, loss 0.19352467101624332\n",
      "Epoch: 170, loss 0.18248496007206264\n",
      "Epoch: 180, loss 0.33590813274171266\n",
      "Epoch: 180, loss 0.3322051619754946\n",
      "Epoch: 180, loss 0.3299220232820463\n",
      "Epoch: 180, loss 0.18185420171539224\n",
      "Epoch: 180, loss 0.17958417677731814\n",
      "Epoch: 180, loss 0.18082906689200234\n",
      "Epoch: 180, loss 0.19229468978413233\n",
      "Epoch: 180, loss 0.18145929236030206\n",
      "Epoch: 190, loss 0.33648673631719705\n",
      "Epoch: 190, loss 0.3327987010295168\n",
      "Epoch: 190, loss 0.3305395042074803\n",
      "Epoch: 190, loss 0.18087450495753013\n",
      "Epoch: 190, loss 0.1786391193629739\n",
      "Epoch: 190, loss 0.17985459517331318\n",
      "Epoch: 190, loss 0.19109245228319766\n",
      "Epoch: 190, loss 0.1804556936223573\n",
      "Epoch: 200, loss 0.33706084764329025\n",
      "Epoch: 200, loss 0.3333871166486915\n",
      "Epoch: 200, loss 0.3311510975050466\n",
      "Epoch: 200, loss 0.17991480673211258\n",
      "Epoch: 200, loss 0.17771286954770307\n",
      "Epoch: 200, loss 0.1789001926802581\n",
      "Epoch: 200, loss 0.1899174260106931\n",
      "Epoch: 200, loss 0.1794737387453546\n",
      "Epoch: 210, loss 0.33763030023686724\n",
      "Epoch: 210, loss 0.33397027350697167\n",
      "Epoch: 210, loss 0.33175670125768936\n",
      "Epoch: 210, loss 0.17897480330995547\n",
      "Epoch: 210, loss 0.1768051761503979\n",
      "Epoch: 210, loss 0.177965539981833\n",
      "Epoch: 210, loss 0.1887690748191101\n",
      "Epoch: 210, loss 0.1785130075771474\n",
      "Epoch: 220, loss 0.33819493967722813\n",
      "Epoch: 220, loss 0.33454804673032607\n",
      "Epoch: 220, loss 0.3323562224187444\n",
      "Epoch: 220, loss 0.1780541872886374\n",
      "Epoch: 220, loss 0.17591578165219143\n",
      "Epoch: 220, loss 0.1770503155461955\n",
      "Epoch: 220, loss 0.18764686084782412\n",
      "Epoch: 220, loss 0.17757308495474275\n",
      "Epoch: 230, loss 0.3387546232250493\n",
      "Epoch: 230, loss 0.3351203215854022\n",
      "Epoch: 230, loss 0.3329495765606128\n",
      "Epoch: 230, loss 0.17715264828418986\n",
      "Epoch: 230, loss 0.17504442301800857\n",
      "Epoch: 230, loss 0.1761541962869047\n",
      "Epoch: 230, loss 0.18655024621037308\n",
      "Epoch: 230, loss 0.17665356073876656\n",
      "Epoch: 240, loss 0.3393092194346435\n",
      "Epoch: 240, loss 0.33568699316063405\n",
      "Epoch: 240, loss 0.33353668761661276\n",
      "Epoch: 240, loss 0.17626987358140742\n",
      "Epoch: 240, loss 0.17419083247326467\n",
      "Epoch: 240, loss 0.17527685808077353\n",
      "Epoch: 240, loss 0.18547869446283638\n",
      "Epoch: 240, loss 0.17575402985307303\n",
      "Epoch: 250, loss 0.33985860776166993\n",
      "Epoch: 250, loss 0.33624796604160495\n",
      "Epoch: 250, loss 0.3341174876172431\n",
      "Epoch: 250, loss 0.17540554874401\n",
      "Epoch: 250, loss 0.1733547382364747\n",
      "Epoch: 250, loss 0.17441797625751723\n",
      "Epoch: 250, loss 0.18443167187669685\n",
      "Epoch: 250, loss 0.17487409232845802\n",
      "Epoch: 260, loss 0.34040267816827596\n",
      "Epoch: 260, loss 0.33680315398236194\n",
      "Epoch: 260, loss 0.33469191642205487\n",
      "Epoch: 260, loss 0.17455935818593538\n",
      "Epoch: 260, loss 0.17253586520869932\n",
      "Epoch: 260, loss 0.17357722606148437\n",
      "Epoch: 260, loss 0.18340864853756247\n",
      "Epoch: 260, loss 0.17401335334936646\n",
      "Epoch: 270, loss 0.34094133072740535\n",
      "Epoch: 270, loss 0.3373524795742027\n",
      "Epoch: 270, loss 0.3352599214482488\n",
      "Epoch: 270, loss 0.17373098570510753\n",
      "Epoch: 270, loss 0.17173393562093092\n",
      "Epoch: 270, loss 0.17275428308588625\n",
      "Epoch: 270, loss 0.18240909928914337\n",
      "Epoch: 270, loss 0.17317142330247554\n",
      "Epoch: 280, loss 0.34147447522789026\n",
      "Epoch: 280, loss 0.3378958739133658\n",
      "Epoch: 280, loss 0.33582145739709246\n",
      "Epoch: 280, loss 0.17292011498104612\n",
      "Epoch: 280, loss 0.17094866964062838\n",
      "Epoch: 280, loss 0.17194882368001924\n",
      "Epoch: 280, loss 0.18143250454002094\n",
      "Epoch: 280, loss 0.17234791782605158\n",
      "Epoch: 290, loss 0.3420020307817229\n",
      "Epoch: 290, loss 0.3384332762688908\n",
      "Epoch: 290, loss 0.3363764859791568\n",
      "Epoch: 290, loss 0.17212643003772038\n",
      "Epoch: 290, loss 0.17017978593871919\n",
      "Epoch: 290, loss 0.17116052533007964\n",
      "Epoch: 290, loss 0.1804783509489978\n",
      "Epoch: 290, loss 0.17154245785905559\n",
      "Epoch: 300, loss 0.342523925434793\n",
      "Epoch: 300, loss 0.33896463375183095\n",
      "Epoch: 300, loss 0.3369249756393405\n",
      "Epoch: 300, loss 0.17134961567304813\n",
      "Epoch: 300, loss 0.16942700221845633\n",
      "Epoch: 300, loss 0.17038906701422385\n",
      "Epoch: 300, loss 0.1795461320031594\n",
      "Epoch: 300, loss 0.17075466968902717\n",
      "Epoch: 310, loss 0.3430400957821919\n",
      "Epoch: 310, loss 0.3394899009868541\n",
      "Epoch: 310, loss 0.33746690128256007\n",
      "Epoch: 310, loss 0.17058935785647134\n",
      "Epoch: 310, loss 0.16869003570758206\n",
      "Epoch: 310, loss 0.1696341295326188\n",
      "Epoch: 310, loss 0.17863534850131932\n",
      "Epoch: 310, loss 0.16998418499789913\n",
      "Epoch: 320, loss 0.34355048658908255\n",
      "Epoch: 320, loss 0.34000903978718433\n",
      "Epoch: 320, loss 0.3380022440009356\n",
      "Epoch: 320, loss 0.16984534409600727\n",
      "Epoch: 320, loss 0.16796860361527322\n",
      "Epoch: 320, loss 0.1688953958132485\n",
      "Epoch: 320, loss 0.17774550895410798\n",
      "Epoch: 320, loss 0.16923064090496037\n",
      "Epoch: 330, loss 0.344055050417991\n",
      "Epoch: 330, loss 0.34052201883373434\n",
      "Epoch: 330, loss 0.33853099080324\n",
      "Epoch: 330, loss 0.16911726377618197\n",
      "Epoch: 330, loss 0.16726242355537405\n",
      "Epoch: 330, loss 0.16817255119430938\n",
      "Epoch: 330, loss 0.17687612991073726\n",
      "Epoch: 330, loss 0.16849368000631015\n",
      "Epoch: 340, loss 0.34455374726326565\n",
      "Epoch: 340, loss 0.3410288133591591\n",
      "Epoch: 340, loss 0.3390531343472896\n",
      "Epoch: 340, loss 0.16840480846824057\n",
      "Epoch: 340, loss 0.1665712139374375\n",
      "Epoch: 340, loss 0.16746528368405414\n",
      "Epoch: 340, loss 0.17602673622136028\n",
      "Epoch: 340, loss 0.16777295041024604\n",
      "Epoch: 350, loss 0.3450465441933394\n",
      "Epoch: 350, loss 0.34152940483750216\n",
      "Epoch: 350, loss 0.33956867267592017\n",
      "Epoch: 350, loss 0.16770767221399407\n",
      "Epoch: 350, loss 0.16589469432707857\n",
      "Epoch: 350, loss 0.16677328419896625\n",
      "Epoch: 350, loss 0.17519686124290412\n",
      "Epoch: 350, loss 0.16706810576811448\n",
      "Epoch: 360, loss 0.3455334150013428\n",
      "Epoch: 360, loss 0.34202378068000144\n",
      "Epoch: 360, loss 0.34007760895711314\n",
      "Epoch: 360, loss 0.1670255517846473\n",
      "Epoch: 360, loss 0.16523258577714425\n",
      "Epoch: 360, loss 0.1660962467811688\n",
      "Epoch: 360, loss 0.17438604699537924\n",
      "Epoch: 360, loss 0.16637880530026183\n",
      "Epoch: 370, loss 0.3460143398645136\n",
      "Epoch: 370, loss 0.3425119339375493\n",
      "Epoch: 370, loss 0.3405799512287755\n",
      "Epoch: 370, loss 0.16635814691591722\n",
      "Epoch: 370, loss 0.16458461113117506\n",
      "Epoch: 370, loss 0.16543386879597713\n",
      "Epoch: 370, loss 0.173593844274832\n",
      "Epoch: 370, loss 0.16570471381679638\n",
      "Epoch: 380, loss 0.3464893050127752\n",
      "Epoch: 380, loss 0.34299386301022916\n",
      "Epoch: 380, loss 0.34107571214862403\n",
      "Epoch: 380, loss 0.16570516052072712\n",
      "Epoch: 380, loss 0.16395049530061725\n",
      "Epoch: 380, loss 0.16478585111051938\n",
      "Epoch: 380, loss 0.17281981272841526\n",
      "Epoch: 380, loss 0.16504550173296842\n",
      "Epoch: 390, loss 0.3469583024067775\n",
      "Epoch: 390, loss 0.3434695713642821\n",
      "Epoch: 390, loss 0.34156490874956735\n",
      "Epoch: 390, loss 0.16506629888071378\n",
      "Epoch: 390, loss 0.1633299655171986\n",
      "Epoch: 390, loss 0.1641518982543315\n",
      "Epoch: 390, loss 0.17206352089638172\n",
      "Epoch: 390, loss 0.16440084507903505\n",
      "Epoch: 400, loss 0.34742132942562504\n",
      "Epoch: 400, loss 0.343939067256788\n",
      "Epoch: 400, loss 0.3420475622009165\n",
      "Epoch: 400, loss 0.16444127181776053\n",
      "Epoch: 400, loss 0.1627227515618575\n",
      "Epoch: 400, loss 0.16353171856284315\n",
      "Epoch: 400, loss 0.17132454622527216\n",
      "Epoch: 400, loss 0.1637704255045514\n",
      "Epoch: 410, loss 0.34787838856445513\n",
      "Epoch: 410, loss 0.3444023634683013\n",
      "Epoch: 410, loss 0.34252369757571816\n",
      "Epoch: 410, loss 0.1638297928467246\n",
      "Epoch: 410, loss 0.1621285859715658\n",
      "Epoch: 410, loss 0.16292502430465086\n",
      "Epoch: 410, loss 0.1706024750560361\n",
      "Epoch: 410, loss 0.16315393027708622\n",
      "Epoch: 420, loss 0.3483294871419836\n",
      "Epoch: 420, loss 0.34485947704361664\n",
      "Epoch: 420, loss 0.34299334362444944\n",
      "Epoch: 420, loss 0.16323157931047433\n",
      "Epoch: 420, loss 0.16154720422533775\n",
      "Epoch: 420, loss 0.16233153179345167\n",
      "Epoch: 420, loss 0.16989690259039936\n",
      "Epoch: 420, loss 0.16255105227540106\n",
      "Epoch: 430, loss 0.3487746370180611\n",
      "Epoch: 430, loss 0.3453104290407919\n",
      "Epoch: 430, loss 0.3434565325552609\n",
      "Epoch: 430, loss 0.1626463524983413\n",
      "Epoch: 430, loss 0.16097834491069102\n",
      "Epoch: 430, loss 0.16175096148551887\n",
      "Epoch: 430, loss 0.16920743283840017\n",
      "Epoch: 430, loss 0.16196148997720075\n",
      "Epoch: 440, loss 0.34921385432127133\n",
      "Epoch: 440, loss 0.3457552442885241\n",
      "Epoch: 440, loss 0.3439132998209327\n",
      "Epoch: 440, loss 0.16207383774901146\n",
      "Epoch: 440, loss 0.16042174987175195\n",
      "Epoch: 440, loss 0.16118303806354528\n",
      "Epoch: 440, loss 0.16853367854966067\n",
      "Epoch: 440, loss 0.16138494744156878\n",
      "Epoch: 450, loss 0.34964715918652167\n",
      "Epoch: 450, loss 0.3461939511519072\n",
      "Epoch: 450, loss 0.3443636839126405\n",
      "Epoch: 450, loss 0.16151376453887414\n",
      "Epoch: 450, loss 0.15987716434017724\n",
      "Epoch: 450, loss 0.16062749050769173\n",
      "Epoch: 450, loss 0.167875261130673\n",
      "Epoch: 450, loss 0.16082113428626849\n",
      "Epoch: 460, loss 0.35007457550258614\n",
      "Epoch: 460, loss 0.34662658130660234\n",
      "Epoch: 460, loss 0.3448077261606278\n",
      "Epoch: 460, loss 0.16096586655677167\n",
      "Epoch: 460, loss 0.15934433704998693\n",
      "Epoch: 460, loss 0.16008405215461935\n",
      "Epoch: 460, loss 0.16723181055008207\n",
      "Epoch: 460, loss 0.16026976566007925\n",
      "Epoch: 470, loss 0.3504961306694833\n",
      "Epoch: 470, loss 0.34705316952137366\n",
      "Epoch: 470, loss 0.34524547054181043\n",
      "Epoch: 470, loss 0.16042988176608064\n",
      "Epoch: 470, loss 0.158823020337383\n",
      "Epoch: 470, loss 0.15955246074528978\n",
      "Epoch: 470, loss 0.16660296523375737\n",
      "Epoch: 470, loss 0.15973056221039703\n",
      "Epoch: 480, loss 0.35091185536558844\n",
      "Epoch: 480, loss 0.3474737534489635\n",
      "Epoch: 480, loss 0.3456769634943503\n",
      "Epoch: 480, loss 0.15990555245498642\n",
      "Epoch: 480, loss 0.15831297022655294\n",
      "Epoch: 480, loss 0.1590324584622589\n",
      "Epoch: 480, loss 0.16598837195117905\n",
      "Epoch: 480, loss 0.15920325004630834\n",
      "Epoch: 490, loss 0.3513217833243134\n",
      "Epoch: 490, loss 0.34788837342520146\n",
      "Epoch: 490, loss 0.34610225373916037\n",
      "Epoch: 490, loss 0.15939262527579434\n",
      "Epoch: 490, loss 0.1578139465024334\n",
      "Epoch: 490, loss 0.158523791957191\n",
      "Epoch: 490, loss 0.16538768569453632\n",
      "Epoch: 490, loss 0.1586875606973932\n",
      "Epoch: 500, loss 0.35172595112019767\n",
      "Epoch: 500, loss 0.34829707227626794\n",
      "Epoch: 500, loss 0.3465213921083307\n",
      "Epoch: 500, loss 0.15889085127406333\n",
      "Epoch: 500, loss 0.15732571277134202\n",
      "Epoch: 500, loss 0.1580262123692643\n",
      "Epoch: 500, loss 0.1648005695517396\n",
      "Epoch: 500, loss 0.15818323106849325\n",
      "Epoch: 510, loss 0.35212439796422584\n",
      "Epoch: 510, loss 0.34869989513398203\n",
      "Epoch: 510, loss 0.3469344313804\n",
      "Epoch: 510, loss 0.1583999859083137\n",
      "Epoch: 510, loss 0.1568480365103483\n",
      "Epoch: 510, loss 0.15753947533512563\n",
      "Epoch: 510, loss 0.16422669457440991\n",
      "Epoch: 510, loss 0.1576900033907034\n",
      "Epoch: 520, loss 0.3525171655081518\n",
      "Epoch: 520, loss 0.349096889258961\n",
      "Epoch: 520, loss 0.34734142612239\n",
      "Epoch: 520, loss 0.15791978906103613\n",
      "Epoch: 520, loss 0.15638068910622074\n",
      "Epoch: 520, loss 0.15706334099102778\n",
      "Epoch: 520, loss 0.16366573964181064\n",
      "Epoch: 520, loss 0.1572076251688541\n",
      "Epoch: 530, loss 0.3529042976576441\n",
      "Epoch: 530, loss 0.3494881038715274\n",
      "Epoch: 530, loss 0.34774243253853293\n",
      "Epoch: 530, loss 0.1574500250416552\n",
      "Epoch: 530, loss 0.15592344588470985\n",
      "Epoch: 530, loss 0.156597573967726\n",
      "Epoch: 530, loss 0.16311739132152225\n",
      "Epoch: 530, loss 0.15673584912572114\n",
      "Epoch: 540, loss 0.3532858403940019\n",
      "Epoch: 540, loss 0.3498735899901667\n",
      "Epoch: 540, loss 0.34813750832555135\n",
      "Epoch: 540, loss 0.1569904625821053\n",
      "Epoch: 540, loss 0.15547608613092198\n",
      "Epoch: 540, loss 0.1561419433787148\n",
      "Epoch: 540, loss 0.1625813437276234\n",
      "Epoch: 540, loss 0.15627443314323874\n",
      "Epoch: 550, loss 0.35366184160422875\n",
      "Epoch: 550, loss 0.35025340027738083\n",
      "Epoch: 550, loss 0.3485267125343918\n",
      "Epoch: 550, loss 0.15654087482561344\n",
      "Epoch: 550, loss 0.15503839310147316\n",
      "Epoch: 550, loss 0.15569622280233453\n",
      "Epoch: 550, loss 0.16205729837701172\n",
      "Epoch: 550, loss 0.15582314020095744\n",
      "Epoch: 560, loss 0.3540323509191977\n",
      "Epoch: 560, loss 0.35062758889272294\n",
      "Epoch: 560, loss 0.3489101054382495\n",
      "Epoch: 560, loss 0.15610103930926555\n",
      "Epoch: 560, loss 0.1546101540290869\n",
      "Epoch: 560, loss 0.15526019025826618\n",
      "Epoch: 560, loss 0.16154496404444368\n",
      "Epoch: 560, loss 0.15538173831200508\n",
      "Epoch: 570, loss 0.3543974195596957\n",
      "Epoch: 570, loss 0.35099621135285\n",
      "Epoch: 570, loss 0.3492877484067684\n",
      "Epoch: 570, loss 0.15567073794088304\n",
      "Epoch: 570, loss 0.15419116012024334\n",
      "Epoch: 570, loss 0.15483362817888233\n",
      "Epoch: 570, loss 0.16104405661678955\n",
      "Epoch: 570, loss 0.15495000045677773\n",
      "Epoch: 580, loss 0.3547571001900791\n",
      "Epoch: 580, loss 0.3513593243983774\n",
      "Epoch: 580, loss 0.34965970378625055\n",
      "Epoch: 580, loss 0.15524975697071544\n",
      "Epoch: 580, loss 0.1537812065464655\n",
      "Epoch: 580, loss 0.15441632337591585\n",
      "Epoch: 580, loss 0.16055429894694914\n",
      "Epoch: 580, loss 0.15452770451460496\n",
      "Epoch: 590, loss 0.3551114467792868\n",
      "Epoch: 590, loss 0.3517169858673225\n",
      "Epoch: 590, loss 0.35002603478570526\n",
      "Epoch: 590, loss 0.15483788695843653\n",
      "Epoch: 590, loss 0.15338009242980222\n",
      "Epoch: 590, loss 0.15400806700288594\n",
      "Epoch: 590, loss 0.16007542070782615\n",
      "Epoch: 590, loss 0.15411463319362106\n",
      "Epoch: 600, loss 0.35546051446897897\n",
      "Epoch: 600, loss 0.35206925457495186\n",
      "Epoch: 600, loss 0.35038680536859457\n",
      "Epoch: 600, loss 0.15443492273586773\n",
      "Epoch: 600, loss 0.1529876208229959\n",
      "Epoch: 600, loss 0.15360865451366468\n",
      "Epoch: 600, loss 0.15960715824669508\n",
      "Epoch: 600, loss 0.15371057395904358\n",
      "Epoch: 610, loss 0.35580435944853095\n",
      "Epoch: 610, loss 0.35241619019980197\n",
      "Epoch: 610, loss 0.35074208015008657\n",
      "Epoch: 610, loss 0.15404066336586367\n",
      "Epoch: 610, loss 0.15260359868483914\n",
      "Epoch: 610, loss 0.1532178856175842\n",
      "Epoch: 610, loss 0.15914925444026898\n",
      "Epoch: 610, loss 0.15331531896008654\n",
      "Epoch: 620, loss 0.35614303883664694\n",
      "Epoch: 620, loss 0.3527578531756768\n",
      "Epoch: 620, loss 0.35109192429965935\n",
      "Epoch: 620, loss 0.1536549120977382\n",
      "Epoch: 620, loss 0.15222783685115435\n",
      "Epoch: 620, loss 0.15283556423142758\n",
      "Epoch: 620, loss 0.15870145855072318\n",
      "Epoch: 620, loss 0.15292866495569216\n",
      "Epoch: 630, loss 0.35647661056933955\n",
      "Epoch: 630, loss 0.3530943045894051\n",
      "Epoch: 630, loss 0.3514364034488714\n",
      "Epoch: 630, loss 0.15327747631960326\n",
      "Epoch: 630, loss 0.15186015000182623\n",
      "Epoch: 630, loss 0.15246149842864598\n",
      "Epoch: 630, loss 0.15826352608291347\n",
      "Epoch: 630, loss 0.15255041323928226\n",
      "Epoch: 640, loss 0.35680513329403774\n",
      "Epoch: 640, loss 0.3534256060841571\n",
      "Epoch: 640, loss 0.3517755836041338\n",
      "Epoch: 640, loss 0.1529081675079543\n",
      "Epoch: 640, loss 0.15150035662427408\n",
      "Epoch: 640, loss 0.15209550038610875\n",
      "Epoch: 640, loss 0.1578352186429845\n",
      "Epoch: 640, loss 0.1521803695626988\n",
      "Epoch: 650, loss 0.3571286662695659\n",
      "Epoch: 650, loss 0.3537518197680917\n",
      "Epoch: 650, loss 0.35210953106429177\n",
      "Epoch: 650, loss 0.15254680117483116\n",
      "Epoch: 650, loss 0.15114827897373884\n",
      "Epoch: 650, loss 0.15173738632869\n",
      "Epoch: 650, loss 0.15741630379854832\n",
      "Epoch: 650, loss 0.15181834405951822\n",
      "Epoch: 660, loss 0.3574472692717884\n",
      "Epoch: 660, loss 0.3540730081281663\n",
      "Epoch: 660, loss 0.3524383123428696\n",
      "Epoch: 660, loss 0.1521931968128322\n",
      "Epoch: 660, loss 0.15080374303071278\n",
      "Epoch: 660, loss 0.15138697647194535\n",
      "Epoch: 660, loss 0.15700655494057097\n",
      "Epoch: 660, loss 0.15146415116787754\n",
      "Epoch: 670, loss 0.3577610025046577\n",
      "Epoch: 670, loss 0.354389233948871\n",
      "Epoch: 670, loss 0.3527619940947771\n",
      "Epoch: 670, loss 0.15184717783827523\n",
      "Epoch: 670, loss 0.1504665784558447\n",
      "Epoch: 670, loss 0.15104409496315413\n",
      "Epoch: 670, loss 0.1566057511471104\n",
      "Epoch: 670, loss 0.1511176095529837\n",
      "Epoch: 680, loss 0.35806992651645286\n",
      "Epoch: 680, loss 0.35470056023570484\n",
      "Epoch: 680, loss 0.3530806430473206\n",
      "Epoch: 680, loss 0.15150857153275146\n",
      "Epoch: 680, loss 0.1501366185426091\n",
      "Epoch: 680, loss 0.15070856982095263\n",
      "Epoch: 680, loss 0.15621367704900818\n",
      "Epoch: 680, loss 0.1507785420294379\n",
      "Epoch: 690, loss 0.35837410212098675\n",
      "Epoch: 690, loss 0.3550070501431998\n",
      "Epoch: 690, loss 0.3533943259353466\n",
      "Epoch: 690, loss 0.15117720898331047\n",
      "Epoch: 690, loss 0.14981370016801515\n",
      "Epoch: 690, loss 0.15038023287377913\n",
      "Epoch: 690, loss 0.15583012269763058\n",
      "Epoch: 690, loss 0.1504467754835051\n",
      "Epoch: 700, loss 0.3586735903235633\n",
      "Epoch: 700, loss 0.3553087669072955\n",
      "Epoch: 700, loss 0.35370310944034766\n",
      "Epoch: 700, loss 0.1508529250214992\n",
      "Epoch: 700, loss 0.14949766374161216\n",
      "Epoch: 700, loss 0.1500589196973392\n",
      "Epoch: 700, loss 0.15545488343473954\n",
      "Epoch: 700, loss 0.15012214079545633\n",
      "Epoch: 710, loss 0.35896845225147556\n",
      "Epoch: 710, loss 0.35560577378187985\n",
      "Epoch: 710, loss 0.354007060133371\n",
      "Epoch: 710, loss 0.15053555816145608\n",
      "Epoch: 710, loss 0.14918835315302723\n",
      "Epoch: 710, loss 0.14974446955127696\n",
      "Epoch: 710, loss 0.1550877597645527\n",
      "Epoch: 710, loss 0.1498044727620948\n",
      "Epoch: 720, loss 0.35925874908884325\n",
      "Epoch: 720, loss 0.35589813397932135\n",
      "Epoch: 720, loss 0.3543062444215697\n",
      "Epoch: 720, loss 0.15022495053724447\n",
      "Epoch: 720, loss 0.14888561571824915\n",
      "Epoch: 720, loss 0.149436725315224\n",
      "Epoch: 720, loss 0.15472855722804826\n",
      "Epoch: 720, loss 0.1494936100195675\n",
      "Epoch: 730, loss 0.35954454201558617\n",
      "Epoch: 730, loss 0.35618591061480037\n",
      "Epoch: 730, loss 0.3546007284982326\n",
      "Epoch: 730, loss 0.14992094783960802\n",
      "Epoch: 730, loss 0.1485893021248715\n",
      "Epoch: 730, loss 0.14913553342439678\n",
      "Epoch: 730, loss 0.15437708627955998\n",
      "Epoch: 730, loss 0.14918939496656997\n",
      "Epoch: 740, loss 0.35982589215034705\n",
      "Epoch: 740, loss 0.3564691666542823\n",
      "Epoch: 740, loss 0.3548905782961459\n",
      "Epoch: 740, loss 0.14962339925230003\n",
      "Epoch: 740, loss 0.14829926637647037\n",
      "Epoch: 740, loss 0.14884074380488246\n",
      "Epoch: 740, loss 0.15403316216569102\n",
      "Epoch: 740, loss 0.14889167368802306\n",
      "Epoch: 750, loss 0.3601028604971738\n",
      "Epoch: 750, loss 0.3567479648659544\n",
      "Epoch: 750, loss 0.35517585944413443\n",
      "Epoch: 750, loss 0.149332157388134\n",
      "Epoch: 750, loss 0.14801536573629653\n",
      "Epoch: 750, loss 0.1485522098087535\n",
      "Epoch: 750, loss 0.1536966048065655\n",
      "Epoch: 750, loss 0.14860029587930956\n",
      "Epoch: 760, loss 0.3603755078957819\n",
      "Epoch: 760, loss 0.35702236777496965\n",
      "Epoch: 760, loss 0.35545663722663634\n",
      "Epoch: 760, loss 0.1490470782248962\n",
      "Epoch: 760, loss 0.1477374606704378\n",
      "Epoch: 760, loss 0.14826978814913863\n",
      "Epoch: 760, loss 0.15336723867944677\n",
      "Epoch: 760, loss 0.14831511477114695\n",
      "Epoch: 770, loss 0.36064389497523053\n",
      "Epoch: 770, loss 0.35729243762134055\n",
      "Epoch: 770, loss 0.35573297654617264\n",
      "Epoch: 770, loss 0.14876802104123532\n",
      "Epoch: 770, loss 0.14746541479059483\n",
      "Epoch: 770, loss 0.14799333883535964\n",
      "Epoch: 770, loss 0.15304489270471544\n",
      "Epoch: 770, loss 0.1480359870551579\n",
      "Epoch: 780, loss 0.36090808211083997\n",
      "Epoch: 780, loss 0.35755823632083594\n",
      "Epoch: 780, loss 0.35600494188857834\n",
      "Epoch: 780, loss 0.14849484835264473\n",
      "Epoch: 780, loss 0.14719909479660603\n",
      "Epoch: 780, loss 0.1477227251082426\n",
      "Epoch: 780, loss 0.1527294001342176\n",
      "Epoch: 780, loss 0.1477627728102053\n",
      "Epoch: 790, loss 0.3611681293841782\n",
      "Epoch: 790, loss 0.35781982542871166\n",
      "Epoch: 790, loss 0.35627259729084243\n",
      "Epoch: 790, loss 0.1482274258476497\n",
      "Epoch: 790, loss 0.1469383704188519\n",
      "Epoch: 790, loss 0.1474578133757067\n",
      "Epoch: 790, loss 0.15242059844198935\n",
      "Epoch: 790, loss 0.1474953354295545\n",
      "Epoch: 800, loss 0.3614240965459947\n",
      "Epoch: 800, loss 0.35807726610617574\n",
      "Epoch: 800, loss 0.35653600631146487\n",
      "Epoch: 800, loss 0.14796562232427277\n",
      "Epoch: 800, loss 0.14668311436063045\n",
      "Epoch: 800, loss 0.147198473148698\n",
      "Epoch: 800, loss 0.15211832921732532\n",
      "Epoch: 800, loss 0.1472335415488924\n",
      "Epoch: 810, loss 0.36167604298191014\n",
      "Epoch: 810, loss 0.35833061908940567\n",
      "Epoch: 810, loss 0.35679523200316887\n",
      "Epoch: 810, loss 0.14770930962688306\n",
      "Epoch: 810, loss 0.14643320224062845\n",
      "Epoch: 810, loss 0.14694457697757035\n",
      "Epoch: 810, loss 0.15182243806020523\n",
      "Epoch: 810, loss 0.14697726097527167\n",
      "Epoch: 820, loss 0.36192402768075405\n",
      "Epoch: 820, loss 0.3585799446610217\n",
      "Epoch: 820, loss 0.35705033688787413\n",
      "Epoch: 820, loss 0.14745836258349485\n",
      "Epoch: 820, loss 0.14618851253556722\n",
      "Epoch: 820, loss 0.14669600038896985\n",
      "Epoch: 820, loss 0.15153277447904784\n",
      "Epoch: 820, loss 0.14672636661700555\n",
      "Epoch: 830, loss 0.3621681092053921\n",
      "Epoch: 830, loss 0.3588253026238711\n",
      "Epoch: 830, loss 0.35730138293380354\n",
      "Epoch: 830, loss 0.14721265894358856\n",
      "Epoch: 830, loss 0.14594892652311509\n",
      "Epoch: 830, loss 0.14645262182329488\n",
      "Epoch: 830, loss 0.1512491917907765\n",
      "Epoch: 830, loss 0.14648073441455325\n",
      "Epoch: 840, loss 0.3624083456659256\n",
      "Epoch: 840, loss 0.3590667522770137\n",
      "Epoch: 840, loss 0.3575484315346247\n",
      "Epoch: 840, loss 0.1469720793165095\n",
      "Epoch: 840, loss 0.14571432822513153\n",
      "Epoch: 840, loss 0.14621432257277978\n",
      "Epoch: 840, loss 0.15097154702316837\n",
      "Epoch: 840, loss 0.1462402432724192\n",
      "Epoch: 850, loss 0.36264479469512223\n",
      "Epoch: 850, loss 0.35930435239378183\n",
      "Epoch: 850, loss 0.3577915434905011\n",
      "Epoch: 850, loss 0.14673650711051517\n",
      "Epoch: 850, loss 0.1454846043513313\n",
      "Epoch: 850, loss 0.14598098672026977\n",
      "Epoch: 850, loss 0.1506997008194748\n",
      "Epoch: 850, loss 0.146004774992107\n",
      "Epoch: 860, loss 0.3628775134259712\n",
      "Epoch: 860, loss 0.3595381612018138\n",
      "Epoch: 860, loss 0.3580307789909697\n",
      "Epoch: 860, loss 0.14650582847250448\n",
      "Epoch: 860, loss 0.14525964424341084\n",
      "Epoch: 860, loss 0.14575250107871746\n",
      "Epoch: 860, loss 0.15043351734527266\n",
      "Epoch: 860, loss 0.14577421420613484\n",
      "Epoch: 870, loss 0.36310655847123785\n",
      "Epoch: 870, loss 0.35976823636494376\n",
      "Epoch: 870, loss 0.35826619759953304\n",
      "Epoch: 870, loss 0.14627993222848412\n",
      "Epoch: 870, loss 0.1450393398197073\n",
      "Epoch: 870, loss 0.14552875513145214\n",
      "Epoch: 870, loss 0.15017286419752282\n",
      "Epoch: 870, loss 0.1455484483131414\n",
      "Epoch: 880, loss 0.363331985904918\n",
      "Epoch: 880, loss 0.3599946349668634\n",
      "Epoch: 880, loss 0.35849785823988617\n",
      "Epoch: 880, loss 0.14605870982480135\n",
      "Epoch: 880, loss 0.14482358552042804\n",
      "Epoch: 880, loss 0.14530964097324706\n",
      "Epoch: 880, loss 0.14991761231580142\n",
      "Epoch: 880, loss 0.1453273674140882\n",
      "Epoch: 890, loss 0.36355385124546546\n",
      "Epoch: 890, loss 0.3602174134964272\n",
      "Epoch: 890, loss 0.3587258191836624\n",
      "Epoch: 890, loss 0.1458420552701931\n",
      "Epoch: 890, loss 0.14461227825351158\n",
      "Epoch: 890, loss 0.14509505325223382\n",
      "Epoch: 890, loss 0.14966763589568097\n",
      "Epoch: 890, loss 0.14511086424958683\n",
      "Epoch: 900, loss 0.3637722094407205\n",
      "Epoch: 900, loss 0.3604366278345449\n",
      "Epoch: 900, loss 0.35895013803964704\n",
      "Epoch: 900, loss 0.14562986507866\n",
      "Epoch: 900, loss 0.1444053173411397\n",
      "Epoch: 900, loss 0.1448848891126678\n",
      "Epoch: 900, loss 0.14942281230420798\n",
      "Epoch: 900, loss 0.14489883413833854\n",
      "Epoch: 910, loss 0.36398711485441704\n",
      "Epoch: 910, loss 0.3606523332425404\n",
      "Epoch: 910, loss 0.35917087174434187\n",
      "Epoch: 910, loss 0.14542203821320795\n",
      "Epoch: 910, loss 0.14420260446694985\n",
      "Epoch: 910, loss 0.14467904813858598\n",
      "Epoch: 910, loss 0.1491830219974633\n",
      "Epoch: 910, loss 0.14469117491671113\n",
      "Epoch: 920, loss 0.3641986212541973\n",
      "Epoch: 920, loss 0.3608645843519136\n",
      "Epoch: 920, loss 0.3593880765538296\n",
      "Epoch: 920, loss 0.14521847603047\n",
      "Epoch: 920, loss 0.1440040436239727\n",
      "Epoch: 920, loss 0.14447743229836704\n",
      "Epoch: 920, loss 0.14894814844015358\n",
      "Epoch: 920, loss 0.14448778687944686\n",
      "Epoch: 930, loss 0.36440678180102765\n",
      "Epoch: 930, loss 0.36107343515540696\n",
      "Epoch: 930, loss 0.35960180803683733\n",
      "Epoch: 930, loss 0.1450190822262294\n",
      "Epoch: 930, loss 0.14380954106332017\n",
      "Epoch: 930, loss 0.1442799458902138\n",
      "Epoch: 930, loss 0.148718078027205\n",
      "Epoch: 930, loss 0.14428857272150666\n",
      "Epoch: 940, loss 0.3646116490399468\n",
      "Epoch: 940, loss 0.36127893899931207\n",
      "Epoch: 940, loss 0.3598121210689478\n",
      "Epoch: 940, loss 0.14482376278186151\n",
      "Epoch: 940, loss 0.14361900524365268\n",
      "Epoch: 940, loss 0.14408649548857133\n",
      "Epoch: 940, loss 0.14849270000732162\n",
      "Epoch: 940, loss 0.14409343748105463\n",
      "Epoch: 950, loss 0.3648132748920634\n",
      "Epoch: 950, loss 0.3614811485769374\n",
      "Epoch: 950, loss 0.36001906982788107\n",
      "Epoch: 950, loss 0.144632425911697\n",
      "Epoch: 950, loss 0.1434323467814326\n",
      "Epoch: 950, loss 0.1438969898914841\n",
      "Epoch: 950, loss 0.14827190640846374\n",
      "Epoch: 950, loss 0.14390228848356693\n",
      "Epoch: 960, loss 0.36501171064772064\n",
      "Epoch: 960, loss 0.3616801159231632\n",
      "Epoch: 960, loss 0.36022270778977605\n",
      "Epoch: 960, loss 0.14444498201132816\n",
      "Epoch: 960, loss 0.14324947840199478\n",
      "Epoch: 960, loss 0.14371134006891131\n",
      "Epoch: 960, loss 0.1480555919652186\n",
      "Epoch: 960, loss 0.1437150352870798\n",
      "Epoch: 970, loss 0.3652070069607675\n",
      "Epoch: 970, loss 0.3618758924100244\n",
      "Epoch: 970, loss 0.36042308772642173\n",
      "Epoch: 970, loss 0.14426134360685272\n",
      "Epoch: 970, loss 0.14307031489143304\n",
      "Epoch: 970, loss 0.1435294591119925\n",
      "Epoch: 970, loss 0.1478436540480148\n",
      "Epoch: 970, loss 0.14353158962855297\n",
      "Epoch: 980, loss 0.365399213843851\n",
      "Epoch: 980, loss 0.3620685287432439\n",
      "Epoch: 980, loss 0.3606202617033597\n",
      "Epoch: 980, loss 0.14408142530507323\n",
      "Epoch: 980, loss 0.14289477304932824\n",
      "Epoch: 980, loss 0.1433512621832818\n",
      "Epoch: 980, loss 0.1476359925941536\n",
      "Epoch: 980, loss 0.14335186537135924\n",
      "Epoch: 990, loss 0.3655883806646898\n",
      "Epoch: 990, loss 0.3622580749596771\n",
      "Epoch: 990, loss 0.36081428107882674\n",
      "Epoch: 990, loss 0.1439051437446382\n",
      "Epoch: 990, loss 0.1427227716423085\n",
      "Epoch: 990, loss 0.14317666646793428\n",
      "Epoch: 990, loss 0.1474325100406053\n",
      "Epoch: 990, loss 0.14317577845387308\n"
     ]
    }
   ],
   "source": [
    "def numerical_derivative(f: Callable, x: np.ndarray) -> np.ndarray:\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        temp = x[idx]\n",
    "        x[idx] = float(temp) + h\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = temp - h\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2 * h)\n",
    "        \n",
    "        x[idx] = temp\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "\n",
    "def train_numerical_derivative(lr: float) -> None:\n",
    "    for epoch in range(1000):\n",
    "        for x_batch, t_batch in zip(train_x_data, train_t_data_onehot):\n",
    "            y_data = model_numer(x_batch)\n",
    "            loss = mean_square_error(y_data, t_batch)\n",
    "\n",
    "            f = lambda W2, b2: sigmoid(x_batch @ W2 + b2)  # f(W2, b2)(x) = sigmoid(W2x + b2)\n",
    "            h = lambda W2, b2, W3, b3: sigmoid(f(W2, b2) @ W3 + b3)  # y = h(W2, b2, W3, b3)(x) = g(W3, b3)(f(W2, b2)(x)) = sigmoid(W3(sigmoid(W3x + b2)) + b3)\n",
    "            \n",
    "            E_w2 = lambda W2: mean_square_error(h(W2, model_numer.b2, model_numer.W3, model_numer.b3), t_batch)\n",
    "            E_b2 = lambda b2: mean_square_error(h(model_numer.W2, b2, model_numer.W3, model_numer.b3), t_batch)\n",
    "            E_w3 = lambda W3: mean_square_error(h(model_numer.W2, model_numer.b2, W3, model_numer.b3), t_batch)\n",
    "            E_b3 = lambda b3: mean_square_error(h(model_numer.W2, model_numer.b2, model_numer.W3, b3), t_batch)\n",
    "            \n",
    "            model_numer.W2 -= lr * numerical_derivative(E_w2, model_numer.W2)\n",
    "            model_numer.b2 -= lr * numerical_derivative(E_b2, model_numer.b2)\n",
    "            model_numer.W3 -= lr * numerical_derivative(E_w3, model_numer.W3)\n",
    "            model_numer.b3 -= lr * numerical_derivative(E_b3, model_numer.b3)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch: {epoch}, loss {loss}')\n",
    "\n",
    "\n",
    "model_numer = NeuralNetwork()\n",
    "train_numerical_derivative(lr=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 추론 (evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43552819 0.54511349]] [[0]]\n",
      "[[0.43774026 0.64535815]] [[0]]\n"
     ]
    }
   ],
   "source": [
    "def test(model):\n",
    "    y_data = model(test_x_data)\n",
    "    print(y_data, test_t_data)\n",
    "    \n",
    "    \n",
    "test(model_back)\n",
    "test(model_numer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2185028b62590b62afdaea33c23835374a0efabc80ef4ce750ba82ee2e8657e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
