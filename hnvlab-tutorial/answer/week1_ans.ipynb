{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented and written by Yeoreum Lee in AI HnV Lab @ Sahmyook University in 2023\n",
    "__author__ = 'leeyeoreum02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,) (5,)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([1, 2, 3, 4, 5]).reshape(5, 1)\n",
    "t_data = np.array([1, 2, 3, 4, 5]).reshape(5, 1)\n",
    "\n",
    "print(x_data.shape, t_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 나누기(split)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 x_data와 t_data를 train : test = 0.8 : 0.2의 비율로 나누는 코드를 구현하시오. (구글링 금지)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) (4,) (1,) (1,)\n"
     ]
    }
   ],
   "source": [
    "def split_data(x_data: np.ndarray, t_data: np.ndarray, split_rate: float) -> Tuple[np.ndarray]:\n",
    "    test_x_data = x_data[:int(split_rate * len(x_data))]\n",
    "    test_t_data = t_data[:int(split_rate * len(t_data))]\n",
    "    train_x_data = x_data[int(split_rate * len(x_data)):]\n",
    "    train_t_data = t_data[int(split_rate * len(t_data)):]\n",
    "    \n",
    "    return train_x_data, train_t_data, test_x_data, test_t_data\n",
    "\n",
    "\n",
    "train_x_data, train_t_data, test_x_data, test_t_data = split_data(x_data, t_data, split_rate=0.2)\n",
    "print(train_x_data.shape, train_t_data.shape, test_x_data.shape, test_t_data.shape,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 선형 회귀(linear regression) 모델\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 선형 회귀(linear regression) 모델을 구현하시오. (구글링 금지)\n",
    "\n",
    "$$\\boldsymbol{y} = f(W, b) =  W\\boldsymbol{x} + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, n_input: int, n_output: int) -> None:\n",
    "        self.W = np.random.rand(n_input, n_output)\n",
    "        self.b = np.random.rand(n_output)\n",
    "        \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        y = x @ self.W + self.b\n",
    "        return y\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self.forward(x)\n",
    "    \n",
    "    \n",
    "model = LinearRegression(n_input=1, n_output=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 오차 함수 (error function, loss function)\n",
    "\n",
    "주어진 수식만을 이용하여 MSE(mean square error) 함수를 구현하시오. (구글링, 메인 교재 참고, 서브 강의 참고 금지)\n",
    "- N은 데이터 개수 (행 개수)\n",
    "- $y$는 정답(label) $\\hat{y}$은 예측값(prediction)\n",
    "\n",
    "$$MSE = \\frac{1} {N}\\sum_{i=1} ^N (\\boldsymbol{y_{i}} - \\boldsymbol{\\hat{y_{i}}})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y_data: np.ndarray, t_data: np.ndarray) -> np.ndarray:\n",
    "    return np.sum((t_data - y_data) ** 2) / len(y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 수치 미분 (numerical derivative)\n",
    "\n",
    "주어진 수식만을 이용하여 수치 미분(numerical derivative) 함수를 구현하시오. (구글링, 메인 교재 참고, 서브 강의 참고 금지)\n",
    "\n",
    "$$\\frac{df(\\boldsymbol{x})} {d\\boldsymbol{x}} = \\lim_{h \\to 0} \\frac{f(\\boldsymbol{x} + h) - f(\\boldsymbol{x} - h)} {2h}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f: Callable, x: np.ndarray) -> np.ndarray:\n",
    "    h = 1e-4\n",
    "    grad = (f(x + h) - f(x - h)) / (2 * h)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2185028b62590b62afdaea33c23835374a0efabc80ef4ce750ba82ee2e8657e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
