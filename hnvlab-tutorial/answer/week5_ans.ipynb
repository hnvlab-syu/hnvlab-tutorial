{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented and written by Yeoreum Lee in AI HnV Lab @ Sahmyook University in 2023\n",
    "__author__ = 'leeyeoreum02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2) (9, 1)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[2, 4], [4, 11], [6, 6], [8, 5], [10, 7], [12, 16], [14, 8], [16, 3], [18, 7]])\n",
    "t_data = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1]).reshape(9, 1)\n",
    "\n",
    "print(x_data.shape, t_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 나누기(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2) (8, 1) (1, 2) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "def split_data(x_data: np.ndarray, t_data: np.ndarray, split_rate: float) -> Tuple[np.ndarray]:\n",
    "    test_x_data = x_data[:int(split_rate * len(x_data))]\n",
    "    test_t_data = t_data[:int(split_rate * len(t_data))]\n",
    "    train_x_data = x_data[int(split_rate * len(x_data)):]\n",
    "    train_t_data = t_data[int(split_rate * len(t_data)):]\n",
    "    \n",
    "    return train_x_data, train_t_data, test_x_data, test_t_data\n",
    "\n",
    "train_x_data, train_t_data, test_x_data, test_t_data = split_data(x_data, t_data, split_rate=0.2)\n",
    "print(train_x_data.shape, train_t_data.shape, test_x_data.shape, test_t_data.shape,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 활성 함수(activation function)\n",
    "\n",
    "$$sigmoid(\\boldsymbol{x}) = \\frac {1} {1 + e^{-\\boldsymbol{x}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 원핫 인코딩(One-hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99 0.01]\n",
      " [0.99 0.01]\n",
      " [0.99 0.01]]\n",
      "(8, 2) (1, 2)\n"
     ]
    }
   ],
   "source": [
    "def onehot_encoding(train_t_data: np.ndarray, test_t_data: np.ndarray, num_classes: int = 2) -> Tuple[np.ndarray]:\n",
    "    train_t_data_onehot = np.zeros((train_t_data.shape[0], num_classes), dtype=np.float32) + 0.01  # one-hot encoding (vectorization) + smoothing\n",
    "    for i in range(len(train_t_data_onehot)):\n",
    "        train_t_data_onehot[i, train_t_data[i]] = 0.99  # smoothing\n",
    "\n",
    "    test_t_data_onehot = np.zeros((test_t_data.shape[0], num_classes), dtype=np.float32) + 0.01  # one-hot encoding (vectorization) + smoothing\n",
    "    for i in range(len(test_t_data_onehot)):\n",
    "        test_t_data_onehot[i, test_t_data[i]] = 0.99  # smoothing\n",
    "    \n",
    "    return train_t_data_onehot, test_t_data_onehot\n",
    "\n",
    "\n",
    "train_t_data_onehot, test_t_data_onehot = onehot_encoding(train_t_data, test_t_data)\n",
    "print(train_t_data_onehot[:3])\n",
    "print(train_t_data_onehot.shape, test_t_data_onehot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 신경망(neural network) 모델\n",
    "\n",
    "$$f(W^{(2)}, b^{(2)})(\\boldsymbol{x}) = sigmoid(W^{(2)}\\boldsymbol{x} + b^{(2)})$$\n",
    "$$g(W^{(3)}, b^{(3)})(\\boldsymbol{x}) = \\sigma(W^{(3)}\\boldsymbol{x} + b^{(3)})$$\n",
    "$$\n",
    "\\begin{matrix}\n",
    "y &=& h(W^{(2)}, b^{(2)}, W^{(3)}, b^{(3)})(\\boldsymbol{x}) \\\\\n",
    "  &=& (g(W^{(3)}, b^{(3)}) \\circ f(W^{(2)}, b^{(2)}))(\\boldsymbol{x}) \\\\\n",
    "  &=& g(W^{(3)}, b^{(3)})(f(W^{(2)}, b^{(2)})(\\boldsymbol{x})) \\\\\n",
    "  &=& \\sigma(W^{(3)}sigmoid(W^{(2)}\\boldsymbol{x} + b^{(2)}) + b^{(3)})\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self) -> None:\n",
    "        self.W2 = np.random.randn(2, 2)\n",
    "        self.b2 = np.random.randn(2)\n",
    "        self.W3 = np.random.randn(2, 2)\n",
    "        self.b3 = np.random.randn(2)\n",
    "        \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        a1 = x\n",
    "        z2 = a1 @ self.W2 + self.b2\n",
    "        self.a2 = sigmoid(z2)\n",
    "        z3 = self.a2 @ self.W3 + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "        return y\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self.forward(x)\n",
    "    \n",
    "    \n",
    "model_back = NeuralNetwork()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 오차 함수 (error function, loss function)\n",
    "\n",
    "- N은 데이터 개수 (행 개수)\n",
    "- $y$는 정답(label) $\\hat{y}$은 예측값(prediction)\n",
    "\n",
    "$$MSE = \\frac{1} {N}\\sum_{i=1} ^N (\\boldsymbol{y_{i}} - \\boldsymbol{\\hat{y_{i}}})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y_data: np.ndarray, t_data: np.ndarray) -> np.ndarray:\n",
    "    return np.sum((t_data - y_data) ** 2) / len(y_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 학습 (train)\n",
    "\n",
    "메인 교재와 서브 강의만을 이용하여 다음 순서를 가지는 학습 코드를 구현하시오. (구글링 금지)\n",
    "\n",
    "0. 배치 사이즈는 1임\n",
    "1. 모델 순전파 (forward)\n",
    "2. 오차 계산 (loss)\n",
    "3. 모델 파라미터(가중치 + 편향) 별 오차 함수의 오차역전파 계산 (backpropagation)\n",
    "4. 가중치(weight), 편향(bias) 갱신 (경사 하강법, gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss 0.24669196467070953\n",
      "Epoch: 0, loss 0.24661587123455866\n",
      "Epoch: 0, loss 0.24639624186021925\n",
      "Epoch: 0, loss 0.24919712851187012\n",
      "Epoch: 0, loss 0.24914594350570568\n",
      "Epoch: 0, loss 0.2491227647827212\n",
      "Epoch: 0, loss 0.2614515117695525\n",
      "Epoch: 0, loss 0.24909209969775217\n",
      "Epoch: 10, loss 0.24718703141430642\n",
      "Epoch: 10, loss 0.24711087123555142\n",
      "Epoch: 10, loss 0.24689123990197223\n",
      "Epoch: 10, loss 0.24855256431047879\n",
      "Epoch: 10, loss 0.2485015817293723\n",
      "Epoch: 10, loss 0.24847839946228456\n",
      "Epoch: 10, loss 0.26071810774659715\n",
      "Epoch: 10, loss 0.24844755023733045\n",
      "Epoch: 20, loss 0.24768139258215432\n",
      "Epoch: 20, loss 0.24760516614804323\n",
      "Epoch: 20, loss 0.24738553407963412\n",
      "Epoch: 20, loss 0.24791117622940295\n",
      "Epoch: 20, loss 0.24786039451874892\n",
      "Epoch: 20, loss 0.24783720963105962\n",
      "Epoch: 20, loss 0.2599888875432118\n",
      "Epoch: 20, loss 0.24780618097711177\n",
      "Epoch: 30, loss 0.24817503260244486\n",
      "Epoch: 30, loss 0.24809874040454302\n",
      "Epoch: 30, loss 0.2478791088324449\n",
      "Epoch: 30, loss 0.24727296414853583\n",
      "Epoch: 30, loss 0.24722238177434516\n",
      "Epoch: 30, loss 0.24719919516947036\n",
      "Epoch: 30, loss 0.2592638361260088\n",
      "Epoch: 30, loss 0.24716799169861858\n",
      "Epoch: 40, loss 0.24866793606804782\n",
      "Epoch: 40, loss 0.2485915786020721\n",
      "Epoch: 40, loss 0.24837194876364202\n",
      "Epoch: 40, loss 0.2466379276019638\n",
      "Epoch: 40, loss 0.24658754305033762\n",
      "Epoch: 40, loss 0.24656435561195897\n",
      "Epoch: 40, loss 0.25854293839450193\n",
      "Epoch: 40, loss 0.24653298183956218\n",
      "Epoch: 50, loss 0.24916008773845383\n",
      "Epoch: 50, loss 0.2490836655041082\n",
      "Epoch: 50, loss 0.24886403864241363\n",
      "Epoch: 50, loss 0.24600606578304385\n",
      "Epoch: 50, loss 0.24595587755966336\n",
      "Epoch: 50, loss 0.2459326901520741\n",
      "Epoch: 50, loss 0.25782617917996975\n",
      "Epoch: 50, loss 0.24590115049887362\n",
      "Epoch: 60, loss 0.24965147254162656\n",
      "Epoch: 60, loss 0.2495749860424403\n",
      "Epoch: 60, loss 0.24935536340576323\n",
      "Epoch: 60, loss 0.24537737754951133\n",
      "Epoch: 60, loss 0.24532738417914413\n",
      "Epoch: 60, loss 0.2453041976475872\n",
      "Epoch: 60, loss 0.2571135432444976\n",
      "Epoch: 60, loss 0.2452724964417653\n",
      "Epoch: 70, loss 0.25014207557576584\n",
      "Epoch: 70, loss 0.25006552531893256\n",
      "Epoch: 70, loss 0.24984590816028335\n",
      "Epoch: 70, loss 0.24475186142861363\n",
      "Epoch: 70, loss 0.2447020614546357\n",
      "Epoch: 70, loss 0.24467887662563628\n",
      "Epoch: 70, loss 0.25640501528018933\n",
      "Epoch: 70, loss 0.2446470181048222\n",
      "Epoch: 80, loss 0.25063188211098136\n",
      "Epoch: 80, loss 0.25055526860720073\n",
      "Epoch: 80, loss 0.25033565818384157\n",
      "Epoch: 80, loss 0.2441295156222671\n",
      "Epoch: 80, loss 0.2440799076061997\n",
      "Epoch: 80, loss 0.2440567252878913\n",
      "Epoch: 80, loss 0.255700579908546\n",
      "Epoch: 80, loss 0.24402471360111527\n",
      "Epoch: 90, loss 0.2511208775908784\n",
      "Epoch: 90, loss 0.25104420135419897\n",
      "Epoch: 90, loss 0.25082459892717635\n",
      "Epoch: 90, loss 0.24351033801223465\n",
      "Epoch: 90, loss 0.24346092053329632\n",
      "Epoch: 90, loss 0.24343774151574082\n",
      "Epoch: 90, loss 0.2550002216800025\n",
      "Epoch: 90, loss 0.2434055807253387\n",
      "Epoch: 100, loss 0.2516090476340556\n",
      "Epoch: 100, loss 0.25153230918172054\n",
      "Epoch: 100, loss 0.25131271601540806\n",
      "Epoch: 100, loss 0.24289432616531983\n",
      "Epoch: 100, loss 0.24284509781999214\n",
      "Epoch: 100, loss 0.2428219228754945\n",
      "Epoch: 100, loss 0.25430392507361765\n",
      "Epoch: 100, loss 0.2427896169589643\n",
      "Epoch: 110, loss 0.25209637803551627\n",
      "Epoch: 110, loss 0.2520195778878098\n",
      "Epoch: 110, loss 0.25179999524945995\n",
      "Epoch: 110, loss 0.24228147733857572\n",
      "Epoch: 110, loss 0.24223243674018316\n",
      "Epoch: 110, loss 0.24220926662359976\n",
      "Epoch: 110, loss 0.2536116744969111\n",
      "Epoch: 110, loss 0.24217681947541136\n",
      "Epoch: 120, loss 0.2525828547679934\n",
      "Epoch: 120, loss 0.25250599344809055\n",
      "Epoch: 120, loss 0.2522864226073962\n",
      "Epoch: 120, loss 0.24167178848452386\n",
      "Epoch: 120, loss 0.24162293426282735\n",
      "Epoch: 120, loss 0.24159976971186914\n",
      "Epoch: 120, loss 0.25292345428584057\n",
      "Epoch: 120, loss 0.2415671851452294\n",
      "Epoch: 130, loss 0.25306846398319044\n",
      "Epoch: 130, loss 0.2529915420170075\n",
      "Epoch: 130, loss 0.2527719842456728\n",
      "Epoch: 130, loss 0.24106525625638325\n",
      "Epoch: 130, loss 0.24101658705718557\n",
      "Epoch: 130, loss 0.24099342879271654\n",
      "Epoch: 130, loss 0.25223924870491565\n",
      "Epoch: 130, loss 0.24096071054128987\n",
      "Epoch: 140, loss 0.25355319201293663\n",
      "Epoch: 140, loss 0.25347620992898456\n",
      "Epoch: 140, loss 0.25325666650030565\n",
      "Epoch: 140, loss 0.2404618770133026\n",
      "Epoch: 140, loss 0.24041339149806762\n",
      "Epoch: 140, loss 0.2403902402243968\n",
      "Epoch: 140, loss 0.2515590419474396\n",
      "Epoch: 140, loss 0.24035739194398464\n",
      "Epoch: 150, loss 0.25403702537026074\n",
      "Epoch: 150, loss 0.25395998369950007\n",
      "Epoch: 150, loss 0.25374045588795396\n",
      "Epoch: 150, loss 0.23986164682559735\n",
      "Epoch: 150, loss 0.23981334367108087\n",
      "Epoch: 150, loss 0.23979020007625038\n",
      "Epoch: 150, loss 0.2508828181358764\n",
      "Epoch: 150, loss 0.23975722534642813\n",
      "Epoch: 160, loss 0.25451995075038086\n",
      "Epoch: 160, loss 0.2544428500260788\n",
      "Epoch: 160, loss 0.2542233391069234\n",
      "Epoch: 160, loss 0.23926456147998604\n",
      "Epoch: 160, loss 0.23921643937787812\n",
      "Epoch: 160, loss 0.23919330413394532\n",
      "Epoch: 160, loss 0.2502105613223349\n",
      "Epoch: 160, loss 0.2391602064596612\n",
      "Epoch: 170, loss 0.2550019550316153\n",
      "Epoch: 170, loss 0.2549247957892048\n",
      "Epoch: 170, loss 0.2547053030380866\n",
      "Epoch: 170, loss 0.2386706164848231\n",
      "Epoch: 170, loss 0.23862267414140256\n",
      "Epoch: 170, loss 0.23859954790471855\n",
      "Epoch: 170, loss 0.24954225548916703\n",
      "Epoch: 170, loss 0.2385663307178525\n",
      "Epoch: 180, loss 0.2554830252762117\n",
      "Epoch: 180, loss 0.2554058080531524\n",
      "Epoch: 180, loss 0.25518633474572383\n",
      "Epoch: 180, loss 0.23807980707532866\n",
      "Epoch: 180, loss 0.23803204321112778\n",
      "Epoch: 180, loss 0.23800892662261014\n",
      "Epoch: 180, loss 0.24887788454967252\n",
      "Epoch: 180, loss 0.23797559328349602\n",
      "Epoch: 190, loss 0.25596314873109755\n",
      "Epoch: 190, loss 0.2558858740667395\n",
      "Epoch: 190, loss 0.25566642147828617\n",
      "Epoch: 190, loss 0.23749212821880883\n",
      "Epoch: 190, loss 0.23744454156828945\n",
      "Epoch: 190, loss 0.23742143525369092\n",
      "Epoch: 190, loss 0.24821743234890786\n",
      "Epoch: 190, loss 0.23738798905260244\n",
      "Epoch: 200, loss 0.25644231282855423\n",
      "Epoch: 200, loss 0.25636498126400264\n",
      "Epoch: 200, loss 0.2561455506690786\n",
      "Epoch: 200, loss 0.23690757461986706\n",
      "Epoch: 200, loss 0.2368601639311067\n",
      "Epoch: 200, loss 0.23683706850127922\n",
      "Epoch: 200, loss 0.24756088266459075\n",
      "Epoch: 200, loss 0.23680351265988087\n",
      "Epoch: 210, loss 0.2569205051868132\n",
      "Epoch: 210, loss 0.2568431172647961\n",
      "Epoch: 210, loss 0.25662370993686834\n",
      "Epoch: 210, loss 0.23632614072560287\n",
      "Epoch: 210, loss 0.23627890475999092\n",
      "Epoch: 210, loss 0.2362558208111455\n",
      "Epoch: 210, loss 0.24690821920809822\n",
      "Epoch: 210, loss 0.23622215848390876\n",
      "Epoch: 220, loss 0.25739771361057695\n",
      "Epoch: 220, loss 0.25732026987531453\n",
      "Epoch: 220, loss 0.2571008870864169\n",
      "Epoch: 220, loss 0.23574782073079611\n",
      "Epoch: 220, loss 0.2357007582627397\n",
      "Epoch: 220, loss 0.2356776863767019\n",
      "Epoch: 220, loss 0.2462594256255526\n",
      "Epoch: 220, loss 0.235643920652289\n",
      "Epoch: 230, loss 0.25787392609146687\n",
      "Epoch: 230, loss 0.2577964270885431\n",
      "Epoch: 230, loss 0.2575770701089385\n",
      "Epoch: 230, loss 0.23517260858307407\n",
      "Epoch: 230, loss 0.23512571839971372\n",
      "Epoch: 230, loss 0.23510265914417472\n",
      "Epoch: 230, loss 0.24561448549898982\n",
      "Epoch: 230, loss 0.23506879304679024\n",
      "Epoch: 240, loss 0.2583491308083973\n",
      "Epoch: 240, loss 0.25827157708463344\n",
      "Epoch: 240, loss 0.25805224718248504\n",
      "Epoch: 240, loss 0.23460049798805993\n",
      "Epoch: 240, loss 0.23455377888899387\n",
      "Epoch: 240, loss 0.23453073281775821\n",
      "Epoch: 240, loss 0.24497338234760618\n",
      "Epoch: 240, loss 0.23449676930846852\n",
      "Epoch: 250, loss 0.2588233161278787\n",
      "Epoch: 250, loss 0.2587457082312089\n",
      "Epoch: 250, loss 0.25852640667225985\n",
      "Epoch: 250, loss 0.23403148241450022\n",
      "Epoch: 250, loss 0.2339849332115177\n",
      "Epoch: 250, loss 0.233961900864746\n",
      "Epoch: 250, loss 0.2443360996290797\n",
      "Epoch: 250, loss 0.23392784284277018\n",
      "Epoch: 260, loss 0.25929647060424954\n",
      "Epoch: 260, loss 0.25921880908359923\n",
      "Epoch: 260, loss 0.25899953713086077\n",
      "Epoch: 260, loss 0.2334655550993694\n",
      "Epoch: 260, loss 0.23341917461619233\n",
      "Epoch: 260, loss 0.23339615652064116\n",
      "Epoch: 260, loss 0.2437026207409605\n",
      "Epoch: 260, loss 0.23336200682461045\n",
      "Epoch: 270, loss 0.259768582979841\n",
      "Epoch: 270, loss 0.2596908683850059\n",
      "Epoch: 270, loss 0.25947162729845485\n",
      "Epoch: 270, loss 0.2329027090529484\n",
      "Epoch: 270, loss 0.23285649612498197\n",
      "Epoch: 270, loss 0.23283349279423912\n",
      "Epoch: 270, loss 0.24307292902212602\n",
      "Epoch: 270, loss 0.23279925420342934\n",
      "Epoch: 280, loss 0.2602396421850724\n",
      "Epoch: 280, loss 0.26016187506660116\n",
      "Epoch: 280, loss 0.2599426661028844\n",
      "Epoch: 280, loss 0.2323429370638781\n",
      "Epoch: 280, loss 0.23229689053796831\n",
      "Epoch: 280, loss 0.2322739024726846\n",
      "Epoch: 280, loss 0.24244700775429878\n",
      "Epoch: 280, loss 0.23223957770822046\n",
      "Epoch: 290, loss 0.2607096373384813\n",
      "Epoch: 290, loss 0.2606318182475594\n",
      "Epoch: 290, loss 0.26041264265970787\n",
      "Epoch: 290, loss 0.2317862317041823\n",
      "Epoch: 290, loss 0.23174035043838223\n",
      "Epoch: 290, loss 0.23171737812649973\n",
      "Epoch: 290, loss 0.24182484016362\n",
      "Epoch: 290, loss 0.23168296985253134\n",
      "Epoch: 300, loss 0.2611785577466885\n",
      "Epoch: 300, loss 0.26110068723502466\n",
      "Epoch: 300, loss 0.26088154627217425\n",
      "Epoch: 300, loss 0.23123258533426216\n",
      "Epoch: 300, loss 0.2311868681976052\n",
      "Epoch: 300, loss 0.23116391211458193\n",
      "Epoch: 300, loss 0.24120640942227736\n",
      "Epoch: 300, loss 0.23112942293943578\n",
      "Epoch: 310, loss 0.2616463929043\n",
      "Epoch: 310, loss 0.26156847152401363\n",
      "Epoch: 310, loss 0.26134936643113593\n",
      "Epoch: 310, loss 0.23068199010785695\n",
      "Epoch: 310, loss 0.23063643598013706\n",
      "Epoch: 310, loss 0.2306134965891678\n",
      "Epoch: 310, loss 0.2405916986501815\n",
      "Epoch: 310, loss 0.2305789290664727\n",
      "Epoch: 320, loss 0.26211313249374546\n",
      "Epoch: 320, loss 0.262035160797258\n",
      "Epoch: 320, loss 0.2618160928148975\n",
      "Epoch: 320, loss 0.23013443797697197\n",
      "Epoch: 320, loss 0.23008904574853178\n",
      "Epoch: 320, loss 0.23006612350076583\n",
      "Epoch: 320, loss 0.23998069091668933\n",
      "Epoch: 320, loss 0.23003148013055263\n",
      "Epoch: 330, loss 0.26257876638505806\n",
      "Epoch: 330, loss 0.26250074492498504\n",
      "Epoch: 330, loss 0.26228171528900435\n",
      "Epoch: 330, loss 0.22958992069677184\n",
      "Epoch: 330, loss 0.22954468926829652\n",
      "Epoch: 330, loss 0.22952178460305184\n",
      "Epoch: 330, loss 0.23937336924236863\n",
      "Epoch: 330, loss 0.22948706783283004\n",
      "Epoch: 340, loss 0.2630432846355931\n",
      "Epoch: 340, loss 0.2629652139646385\n",
      "Epoch: 340, loss 0.2627462239059725\n",
      "Epoch: 340, loss 0.2290484298304354\n",
      "Epoch: 340, loss 0.2290033581127539\n",
      "Epoch: 340, loss 0.2289804714577282\n",
      "Epoch: 340, loss 0.23876971660080237\n",
      "Epoch: 340, loss 0.22894568368353874\n",
      "Epoch: 350, loss 0.26350667748969026\n",
      "Epoch: 350, loss 0.26342855816054295\n",
      "Epoch: 350, loss 0.2632096089049591\n",
      "Epoch: 350, loss 0.22850995675397473\n",
      "Epoch: 350, loss 0.22846504366786669\n",
      "Epoch: 350, loss 0.2284421754393448\n",
      "Epoch: 350, loss 0.23816971592042788\n",
      "Epoch: 350, loss 0.22840731900679018\n",
      "Epoch: 360, loss 0.26396893537827765\n",
      "Epoch: 360, loss 0.2638907679435105\n",
      "Epoch: 360, loss 0.26367186071137805\n",
      "Epoch: 360, loss 0.22797449266101294\n",
      "Epoch: 360, loss 0.22792973713702258\n",
      "Epoch: 360, loss 0.22790688774008105\n",
      "Epoch: 360, loss 0.2375733500864083\n",
      "Epoch: 360, loss 0.22787196494533288\n",
      "Epoch: 370, loss 0.26443004891842303\n",
      "Epoch: 370, loss 0.2643518339303932\n",
      "Epoch: 370, loss 0.26413296993645846\n",
      "Epoch: 370, loss 0.22744202856752244\n",
      "Epoch: 370, loss 0.22739742954577716\n",
      "Epoch: 370, loss 0.22737459937448576\n",
      "Epoch: 370, loss 0.23698060194253404\n",
      "Epoch: 370, loss 0.22733961246527043\n",
      "Epoch: 380, loss 0.2648900089128291\n",
      "Epoch: 380, loss 0.26481174692358056\n",
      "Epoch: 380, loss 0.26459292737675133\n",
      "Epoch: 380, loss 0.2269125553165205\n",
      "Epoch: 380, loss 0.2268681117465568\n",
      "Epoch: 380, loss 0.226845301184176\n",
      "Epoch: 380, loss 0.23639145429314906\n",
      "Epoch: 380, loss 0.22681025236074048\n",
      "Epoch: 390, loss 0.26534880634927827\n",
      "Epoch: 390, loss 0.2652704979104469\n",
      "Epoch: 390, loss 0.2650517240135822\n",
      "Epoch: 390, loss 0.22638606358272262\n",
      "Epoch: 390, loss 0.22634177442331577\n",
      "Epoch: 390, loss 0.2263189838424928\n",
      "Epoch: 390, loss 0.23580588990510193\n",
      "Epoch: 390, loss 0.2262838752585482\n",
      "Epoch: 400, loss 0.2658064324000254\n",
      "Epoch: 400, loss 0.26572807806274557\n",
      "Epoch: 400, loss 0.2655093510124534\n",
      "Epoch: 400, loss 0.22586254387715096\n",
      "Epoch: 400, loss 0.2258184080961514\n",
      "Epoch: 400, loss 0.22579563785911183\n",
      "Epoch: 400, loss 0.23522389150971537\n",
      "Epoch: 400, loss 0.22576047162275797\n",
      "Epoch: 410, loss 0.26626287842114194\n",
      "Epoch: 410, loss 0.266184478735955\n",
      "Epoch: 410, loss 0.2659657997223977\n",
      "Epoch: 410, loss 0.22534198655169796\n",
      "Epoch: 410, loss 0.22529800312587234\n",
      "Epoch: 410, loss 0.22527525358460945\n",
      "Epoch: 410, loss 0.23464544180477567\n",
      "Epoch: 410, loss 0.22524003175923965\n",
      "Epoch: 420, loss 0.2667181359518114\n",
      "Epoch: 420, loss 0.26663969146857686\n",
      "Epoch: 420, loss 0.26642106167528223\n",
      "Epoch: 420, loss 0.22482438180364372\n",
      "Epoch: 420, loss 0.2247805497185208\n",
      "Epoch: 420, loss 0.22475782121498206\n",
      "Epoch: 420, loss 0.23407052345653595\n",
      "Epoch: 420, loss 0.22472254582016882\n",
      "Epoch: 430, loss 0.2671721967135791\n",
      "Epoch: 430, loss 0.2670937079813868\n",
      "Epoch: 430, loss 0.2668751285850667\n",
      "Epoch: 430, loss 0.22430971968012592\n",
      "Epoch: 430, loss 0.22426603792984778\n",
      "Epoch: 430, loss 0.22424333079611827\n",
      "Epoch: 430, loss 0.23349911910173166\n",
      "Epoch: 430, loss 0.22420800380848058\n",
      "Epoch: 440, loss 0.2676250526095557\n",
      "Epoch: 440, loss 0.2675465201766407\n",
      "Epoch: 440, loss 0.2673279923470162\n",
      "Epoch: 440, loss 0.22379799008256251\n",
      "Epoch: 440, loss 0.22375445766974003\n",
      "Epoch: 440, loss 0.223731772228223\n",
      "Epoch: 440, loss 0.23293121134960754\n",
      "Epoch: 440, loss 0.22369639558227553\n",
      "Epoch: 450, loss 0.2680766957235771\n",
      "Epoch: 450, loss 0.2679981201372363\n",
      "Epoch: 450, loss 0.26777964503686924\n",
      "Epoch: 450, loss 0.22328918277102527\n",
      "Epoch: 450, loss 0.223245798706598\n",
      "Epoch: 450, loss 0.22322313527019283\n",
      "Epoch: 450, loss 0.23236678278395145\n",
      "Epoch: 450, loss 0.2231877108591775\n",
      "Epoch: 460, loss 0.2685271183193225\n",
      "Epoch: 460, loss 0.26844850012583327\n",
      "Epoch: 460, loss 0.26823007890996436\n",
      "Epoch: 460, loss 0.22278328736856312\n",
      "Epoch: 460, loss 0.22274005067166405\n",
      "Epoch: 460, loss 0.2227174095439416\n",
      "Epoch: 460, loss 0.23180581596513453\n",
      "Epoch: 460, loss 0.2226819392206415\n",
      "Epoch: 470, loss 0.26897631283939144\n",
      "Epoch: 470, loss 0.2688976525839316\n",
      "Epoch: 470, loss 0.2686792864003251\n",
      "Epoch: 470, loss 0.2222802933654763\n",
      "Epoch: 470, loss 0.22223720306330036\n",
      "Epoch: 470, loss 0.2222145845386756\n",
      "Epoch: 470, loss 0.23124829343215414\n",
      "Epoch: 470, loss 0.22217907011621268\n",
      "Epoch: 480, loss 0.26942427190433943\n",
      "Epoch: 480, loss 0.2693455701309101\n",
      "Epoch: 480, loss 0.2691272601197043\n",
      "Epoch: 480, loss 0.22178019012353917\n",
      "Epoch: 480, loss 0.2217372452512157\n",
      "Epoch: 480, loss 0.22171464961511744\n",
      "Epoch: 480, loss 0.23069419770467892\n",
      "Epoch: 480, loss 0.2216790928677341\n",
      "Epoch: 490, loss 0.26987098831167755\n",
      "Epoch: 490, loss 0.2697922455630269\n",
      "Epoch: 490, loss 0.2695739928565909\n",
      "Epoch: 490, loss 0.22128296688017113\n",
      "Epoch: 490, loss 0.22124016648064113\n",
      "Epoch: 490, loss 0.22121759400967933\n",
      "Epoch: 490, loss 0.23014351128509286\n",
      "Epoch: 490, loss 0.22118199667350286\n",
      "Epoch: 500, loss 0.2703164550348331\n",
      "Epoch: 500, loss 0.270237671852383\n",
      "Epoch: 500, loss 0.2700194775751797\n",
      "Epoch: 500, loss 0.22078861275255596\n",
      "Epoch: 500, loss 0.22074595587645202\n",
      "Epoch: 500, loss 0.2207234068385826\n",
      "Epoch: 500, loss 0.22959621666053753\n",
      "Epoch: 500, loss 0.22068777061237527\n",
      "Epoch: 510, loss 0.27076066522207615\n",
      "Epoch: 510, loss 0.2706818421458496\n",
      "Epoch: 510, loss 0.2704637074143041\n",
      "Epoch: 510, loss 0.22029711674170865\n",
      "Epoch: 510, loss 0.22025460244723905\n",
      "Epoch: 510, loss 0.22023207710192624\n",
      "Epoch: 510, loss 0.22905229630494944\n",
      "Epoch: 510, loss 0.2201964036478196\n",
      "Epoch: 520, loss 0.2712036121954101\n",
      "Epoch: 520, loss 0.2711247497639612\n",
      "Epoch: 520, loss 0.27090667568633575\n",
      "Epoch: 520, loss 0.21980846773648854\n",
      "Epoch: 520, loss 0.219766095089325\n",
      "Epoch: 520, loss 0.21974359368770086\n",
      "Epoch: 520, loss 0.2285117326810921\n",
      "Epoch: 520, loss 0.21970788463191496\n",
      "Epoch: 530, loss 0.27164528944943045\n",
      "Epoch: 530, loss 0.27156638819977597\n",
      "Epoch: 530, loss 0.2713483758760495\n",
      "Epoch: 530, loss 0.21932265451755958\n",
      "Epoch: 530, loss 0.2192804225907281\n",
      "Epoch: 530, loss 0.2192579453757501\n",
      "Epoch: 530, loss 0.22797450824258003\n",
      "Epoch: 530, loss 0.21922220230929884\n",
      "Epoch: 540, loss 0.272085690650151\n",
      "Epoch: 540, loss 0.27200675111770356\n",
      "Epoch: 540, loss 0.271788801639458\n",
      "Epoch: 540, loss 0.21883966576129688\n",
      "Epoch: 540, loss 0.2187975736350723\n",
      "Epoch: 540, loss 0.21877512084167805\n",
      "Epoch: 540, loss 0.22744060543589453\n",
      "Epoch: 540, loss 0.21873934532105935\n",
      "Epoch: 550, loss 0.27252480963379955\n",
      "Epoch: 550, loss 0.27244583235230324\n",
      "Epoch: 550, loss 0.27222794680261436\n",
      "Epoch: 550, loss 0.21835949004363847\n",
      "Epoch: 550, loss 0.21831753680544158\n",
      "Epoch: 550, loss 0.21829510866070131\n",
      "Epoch: 550, loss 0.22691000670238765\n",
      "Epoch: 550, loss 0.2182593022085749\n",
      "Epoch: 560, loss 0.2729626404055852\n",
      "Epoch: 560, loss 0.27288362590705173\n",
      "Epoch: 560, loss 0.27266580536038554\n",
      "Epoch: 560, loss 0.217882115843883\n",
      "Epoch: 560, loss 0.2178403005881815\n",
      "Epoch: 560, loss 0.21781789731144824\n",
      "Epoch: 560, loss 0.22638269448027526\n",
      "Epoch: 560, loss 0.21778206141729842\n",
      "Epoch: 570, loss 0.2733991771384357\n",
      "Epoch: 570, loss 0.27332012595308386\n",
      "Epoch: 570, loss 0.2731023714751988\n",
      "Epoch: 570, loss 0.21740753154843312\n",
      "Epoch: 570, loss 0.21736585337664482\n",
      "Epoch: 570, loss 0.21734347517970232\n",
      "Epoch: 570, loss 0.22585865120661613\n",
      "Epoch: 570, loss 0.21730761130048826\n",
      "Epoch: 580, loss 0.27383441417171017\n",
      "Epoch: 580, loss 0.27375532682790565\n",
      "Epoch: 580, loss 0.2735376394757589\n",
      "Epoch: 580, loss 0.21693572545448342\n",
      "Epoch: 580, loss 0.2168941834748826\n",
      "Epoch: 580, loss 0.21687183056209072\n",
      "Epoch: 580, loss 0.22533785931927675\n",
      "Epoch: 580, loss 0.2168359401228838\n",
      "Epoch: 590, loss 0.2742683460098848\n",
      "Epoch: 590, loss 0.27418922303408233\n",
      "Epoch: 590, loss 0.27397160385574204\n",
      "Epoch: 590, loss 0.2164666857736534\n",
      "Epoch: 590, loss 0.21642527910127976\n",
      "Epoch: 590, loss 0.21640295166971818\n",
      "Epoch: 590, loss 0.22482030125888017\n",
      "Epoch: 590, loss 0.2163670360643264\n",
      "Epoch: 600, loss 0.2747009673212144\n",
      "Epoch: 600, loss 0.27462180923790147\n",
      "Epoch: 600, loss 0.2744042592724636\n",
      "Epoch: 600, loss 0.2160004006355657\n",
      "Epoch: 600, loss 0.21595912839213624\n",
      "Epoch: 600, loss 0.21593682663174502\n",
      "Epoch: 600, loss 0.22430595947073764\n",
      "Epoch: 600, loss 0.21590088722332546\n",
      "Epoch: 610, loss 0.27513227293637066\n",
      "Epoch: 610, loss 0.27505308026801306\n",
      "Epoch: 610, loss 0.2748356005455228\n",
      "Epoch: 610, loss 0.2155368580913684\n",
      "Epoch: 610, loss 0.2154957194051917\n",
      "Epoch: 610, loss 0.21547344349891046\n",
      "Epoch: 610, loss 0.22379481640676332\n",
      "Epoch: 610, loss 0.21543748162056936\n",
      "Epoch: 620, loss 0.2755622578470586\n",
      "Epoch: 620, loss 0.2754830311140472\n",
      "Epoch: 620, loss 0.27526562265542537\n",
      "Epoch: 620, loss 0.21507604611720266\n",
      "Epoch: 620, loss 0.21503504012309546\n",
      "Epoch: 620, loss 0.21501279024700015\n",
      "Epoch: 620, loss 0.22328685452736802\n",
      "Epoch: 620, loss 0.2149768072023812\n",
      "Epoch: 630, loss 0.2759909172046115\n",
      "Epoch: 630, loss 0.27591165692521097\n",
      "Epoch: 630, loss 0.27569432074218503\n",
      "Epoch: 630, loss 0.21461795261761463\n",
      "Epoch: 630, loss 0.2145770784568214\n",
      "Epoch: 630, loss 0.21455485478025837\n",
      "Epoch: 630, loss 0.22278205630333497\n",
      "Epoch: 630, loss 0.21451885184411965\n",
      "Epoch: 640, loss 0.2764182463185662\n",
      "Epoch: 640, loss 0.2763389530088656\n",
      "Epoch: 640, loss 0.27612169010390464\n",
      "Epoch: 640, loss 0.2141625654289125\n",
      "Epoch: 640, loss 0.21412182224902598\n",
      "Epoch: 640, loss 0.21409962493474533\n",
      "Epoch: 640, loss 0.22228040421767356\n",
      "Epoch: 640, loss 0.2140636033535244\n",
      "Epoch: 650, loss 0.27684424065522\n",
      "Epoch: 650, loss 0.2767649148290836\n",
      "Epoch: 650, loss 0.27654772619533896\n",
      "Epoch: 650, loss 0.21370987232246708\n",
      "Epoch: 650, loss 0.21366925927735275\n",
      "Epoch: 650, loss 0.2136470884816379\n",
      "Epoch: 650, loss 0.22178188076745128\n",
      "Epoch: 650, loss 0.21361104947400678\n",
      "Epoch: 660, loss 0.2772688958361691\n",
      "Epoch: 660, loss 0.27718953800519086\n",
      "Epoch: 660, loss 0.27697242462643945\n",
      "Epoch: 660, loss 0.21325986100795893\n",
      "Epoch: 660, loss 0.2132193772576802\n",
      "Epoch: 660, loss 0.21319723313047662\n",
      "Epoch: 660, loss 0.22128646846560357\n",
      "Epoch: 660, loss 0.21316117788788527\n",
      "Epoch: 670, loss 0.27769220763683067\n",
      "Epoch: 670, loss 0.2776128183102883\n",
      "Epoch: 670, loss 0.2773957811608814\n",
      "Epoch: 670, loss 0.212812519136569\n",
      "Epoch: 670, loss 0.21277216384731515\n",
      "Epoch: 670, loss 0.21275004653235685\n",
      "Epoch: 670, loss 0.22079414984272053\n",
      "Epoch: 670, loss 0.21271397621956553\n",
      "Epoch: 680, loss 0.27811417198494953\n",
      "Epoch: 680, loss 0.27803475166976116\n",
      "Epoch: 680, loss 0.27781779171457666\n",
      "Epoch: 680, loss 0.21236783430411485\n",
      "Epoch: 680, loss 0.21232760664813102\n",
      "Epoch: 680, loss 0.2123055162830642\n",
      "Epoch: 680, loss 0.22030490744880932\n",
      "Epoch: 680, loss 0.21226943203866705\n",
      "Epoch: 690, loss 0.27853478495908973\n",
      "Epoch: 690, loss 0.2784553341597719\n",
      "Epoch: 690, loss 0.27823845235417066\n",
      "Epoch: 690, loss 0.21192579405413217\n",
      "Epoch: 690, loss 0.21188569320965056\n",
      "Epoch: 690, loss 0.21186362992615645\n",
      "Epoch: 690, loss 0.21981872385503193\n",
      "Epoch: 690, loss 0.21182753286309375\n",
      "Epoch: 700, loss 0.2789540427871132\n",
      "Epoch: 700, loss 0.27887456200573985\n",
      "Epoch: 700, loss 0.278657759295526\n",
      "Epoch: 700, loss 0.2114863858809013\n",
      "Epoch: 700, loss 0.21144641103207495\n",
      "Epoch: 700, loss 0.21142437495599037\n",
      "Epoch: 700, loss 0.2193355816554183\n",
      "Epoch: 700, loss 0.21138826616205045\n",
      "Epoch: 710, loss 0.27937194184464476\n",
      "Epoch: 710, loss 0.2792924315808083\n",
      "Epoch: 710, loss 0.27907570890219346\n",
      "Epoch: 710, loss 0.21104959723241978\n",
      "Epoch: 710, loss 0.2110097475692578\n",
      "Epoch: 710, loss 0.210987738820693\n",
      "Epoch: 710, loss 0.21885546346855328\n",
      "Epoch: 710, loss 0.21095161935900583\n",
      "Epoch: 720, loss 0.2797884786535264\n",
      "Epoch: 720, loss 0.27970893940429975\n",
      "Epoch: 720, loss 0.27949229768387074\n",
      "Epoch: 720, loss 0.21061541551332022\n",
      "Epoch: 720, loss 0.2105756902316247\n",
      "Epoch: 720, loss 0.2105537089250805\n",
      "Epoch: 720, loss 0.2183783519392375\n",
      "Epoch: 720, loss 0.2105175798346008\n",
      "Epoch: 730, loss 0.28020364988026\n",
      "Epoch: 730, loss 0.28012408214016005\n",
      "Epoch: 730, loss 0.2799075222948509\n",
      "Epoch: 730, loss 0.21018382808773506\n",
      "Epoch: 730, loss 0.21014422638903954\n",
      "Epoch: 730, loss 0.2101222726335215\n",
      "Epoch: 730, loss 0.2179042297401219\n",
      "Epoch: 730, loss 0.21008613492950276\n",
      "Epoch: 740, loss 0.2806174523344409\n",
      "Epoch: 740, loss 0.2805378565953936\n",
      "Epoch: 740, loss 0.28032137953245967\n",
      "Epoch: 740, loss 0.20975482228210637\n",
      "Epoch: 740, loss 0.2097153433736164\n",
      "Epoch: 740, loss 0.20969341727274807\n",
      "Epoch: 740, loss 0.21743307957331517\n",
      "Epoch: 740, loss 0.20965727194720754\n",
      "Epoch: 750, loss 0.2810298829671815\n",
      "Epoch: 750, loss 0.2809502597184885\n",
      "Epoch: 750, loss 0.28073386633548547\n",
      "Epoch: 750, loss 0.20932838538794427\n",
      "Epoch: 750, loss 0.20928902848247857\n",
      "Epoch: 750, loss 0.20926713013461223\n",
      "Epoch: 750, loss 0.2169648841719629\n",
      "Epoch: 750, loss 0.2092309781567866\n",
      "Epoch: 760, loss 0.28144093886952826\n",
      "Epoch: 760, loss 0.2813612885978338\n",
      "Epoch: 760, loss 0.2811449797825994\n",
      "Epoch: 760, loss 0.20890450466453006\n",
      "Epoch: 760, loss 0.2088652689804643\n",
      "Epoch: 760, loss 0.20884339847879035\n",
      "Epoch: 760, loss 0.21649962630180064\n",
      "Epoch: 760, loss 0.20880724079558316\n",
      "Epoch: 770, loss 0.28185061727086974\n",
      "Epoch: 770, loss 0.28177094046013007\n",
      "Epoch: 770, loss 0.28155471709076907\n",
      "Epoch: 770, loss 0.2084831673415692\n",
      "Epoch: 770, loss 0.20844405210277972\n",
      "Epoch: 770, loss 0.20842220953543394\n",
      "Epoch: 770, loss 0.21603728876267747\n",
      "Epoch: 770, loss 0.20838604707185415\n",
      "Epoch: 780, loss 0.2822589155373393\n",
      "Epoch: 780, loss 0.28217921266879303\n",
      "Epoch: 780, loss 0.28196307561366546\n",
      "Epoch: 780, loss 0.20806436062178923\n",
      "Epoch: 780, loss 0.20802536505759978\n",
      "Epoch: 780, loss 0.20800355050776909\n",
      "Epoch: 780, loss 0.21557785439005203\n",
      "Epoch: 780, loss 0.20796738416736102\n",
      "Epoch: 790, loss 0.2826658311702119\n",
      "Epoch: 790, loss 0.28258610272235135\n",
      "Epoch: 790, loss 0.2823700528400638\n",
      "Epoch: 790, loss 0.20764807168348814\n",
      "Epoch: 790, loss 0.20760919502861658\n",
      "Epoch: 790, loss 0.20758740857464306\n",
      "Epoch: 790, loss 0.21512130605645954\n",
      "Epoch: 790, loss 0.20755123923990892\n",
      "Epoch: 800, loss 0.28307136180429615\n",
      "Epoch: 800, loss 0.2829916082528398\n",
      "Epoch: 800, loss 0.2827756463922399\n",
      "Epoch: 800, loss 0.2072342876830304\n",
      "Epoch: 800, loss 0.20719552917753742\n",
      "Epoch: 800, loss 0.20717377089302008\n",
      "Epoch: 800, loss 0.21466762667295108\n",
      "Epoch: 800, loss 0.2071375994258336\n",
      "Epoch: 810, loss 0.28347550520632203\n",
      "Epoch: 810, loss 0.28339572702418886\n",
      "Epoch: 810, loss 0.2831798540243626\n",
      "Epoch: 810, loss 0.20682299575729118\n",
      "Epoch: 810, loss 0.2067843546465299\n",
      "Epoch: 810, loss 0.20676262460042594\n",
      "Epoch: 810, loss 0.21421679919050277\n",
      "Epoch: 810, loss 0.20672645184243774\n",
      "Epoch: 820, loss 0.28387825927332555\n",
      "Epoch: 820, loss 0.28379845693061034\n",
      "Epoch: 820, loss 0.2835826736208815\n",
      "Epoch: 820, loss 0.20641418302605083\n",
      "Epoch: 820, loss 0.20637565856061746\n",
      "Epoch: 820, loss 0.20635395681734056\n",
      "Epoch: 820, loss 0.21376880660139677\n",
      "Epoch: 820, loss 0.20631778359037767\n",
      "Epoch: 830, loss 0.28427962203103074\n",
      "Epoch: 830, loss 0.2841997959949799\n",
      "Epoch: 830, loss 0.2839841031949139\n",
      "Epoch: 830, loss 0.20600783659433874\n",
      "Epoch: 830, loss 0.20596942803002496\n",
      "Epoch: 830, loss 0.20594775464954262\n",
      "Epoch: 830, loss 0.21332363194057302\n",
      "Epoch: 830, loss 0.20591158175599794\n",
      "Epoch: 840, loss 0.28467959163222983\n",
      "Epoch: 840, loss 0.2845997423672192\n",
      "Epoch: 840, loss 0.2843841408866282\n",
      "Epoch: 840, loss 0.20560394355472747\n",
      "Epoch: 840, loss 0.2055656501524733\n",
      "Epoch: 840, loss 0.2055440051904026\n",
      "Epoch: 840, loss 0.21288125828695184\n",
      "Epoch: 840, loss 0.20550783341361864\n",
      "Epoch: 850, loss 0.28507816635516164\n",
      "Epoch: 850, loss 0.2849982943226754\n",
      "Epoch: 850, loss 0.28478278496162607\n",
      "Epoch: 850, loss 0.20520249098957774\n",
      "Epoch: 850, loss 0.20516431201542518\n",
      "Epoch: 850, loss 0.20514269552312675\n",
      "Epoch: 850, loss 0.21244166876472753\n",
      "Epoch: 850, loss 0.2051065256277716\n",
      "Epoch: 860, loss 0.2854753446018908\n",
      "Epoch: 860, loss 0.2853954502605007\n",
      "Epoch: 860, loss 0.2851800338093255\n",
      "Epoch: 860, loss 0.20480346597323396\n",
      "Epoch: 860, loss 0.20476540069828278\n",
      "Epoch: 860, loss 0.20474381272295294\n",
      "Epoch: 860, loss 0.212004846544632\n",
      "Epoch: 860, loss 0.20470764545538886\n",
      "Epoch: 870, loss 0.28587112489668565\n",
      "Epoch: 870, loss 0.2857912087020321\n",
      "Epoch: 870, loss 0.285575885941342\n",
      "Epoch: 870, loss 0.204406855574172\n",
      "Epoch: 870, loss 0.2043689032745355\n",
      "Epoch: 870, loss 0.20434734385929731\n",
      "Epoch: 870, loss 0.2115707748451702\n",
      "Epoch: 870, loss 0.20431117994794237\n",
      "Epoch: 880, loss 0.2862655058843976\n",
      "Epoch: 880, loss 0.28618556828917185\n",
      "Epoch: 880, loss 0.28597033998987204\n",
      "Epoch: 880, loss 0.20401264685709936\n",
      "Epoch: 880, loss 0.20397480681386088\n",
      "Epoch: 880, loss 0.2039532759978539\n",
      "Epoch: 880, loss 0.21113943693382592\n",
      "Epoch: 880, loss 0.20391711615353691\n",
      "Epoch: 890, loss 0.28665848632884194\n",
      "Epoch: 890, loss 0.2865785277827685\n",
      "Epoch: 890, loss 0.28636339470607625\n",
      "Epoch: 890, loss 0.2036208268850068\n",
      "Epoch: 890, loss 0.20358309838417823\n",
      "Epoch: 890, loss 0.20356159620264552\n",
      "Epoch: 890, loss 0.2107108161282384\n",
      "Epoch: 890, loss 0.20352544111895443\n",
      "Epoch: 900, loss 0.2870500651111799\n",
      "Epoch: 900, loss 0.28697008606100116\n",
      "Epoch: 900, loss 0.28675504895846554\n",
      "Epoch: 900, loss 0.2032313827211748\n",
      "Epoch: 900, loss 0.20319376505365494\n",
      "Epoch: 900, loss 0.20317229153802968\n",
      "Epoch: 900, loss 0.21028489579734994\n",
      "Epoch: 900, loss 0.2031361418916528\n",
      "Epoch: 910, loss 0.2874402412283044\n",
      "Epoch: 910, loss 0.28736024211776506\n",
      "Epoch: 910, loss 0.2871453017312897\n",
      "Epoch: 910, loss 0.20284430143113213\n",
      "Epoch: 910, loss 0.20280679389266631\n",
      "Epoch: 910, loss 0.20278534907065693\n",
      "Epoch: 910, loss 0.20986165936252466\n",
      "Epoch: 910, loss 0.2027492055217177\n",
      "Epoch: 920, loss 0.28782901379122805\n",
      "Epoch: 920, loss 0.28774899506106144\n",
      "Epoch: 920, loss 0.28753415212292827\n",
      "Epoch: 920, loss 0.20245957008456963\n",
      "Epoch: 920, loss 0.20242217197571002\n",
      "Epoch: 920, loss 0.20240075587138326\n",
      "Epoch: 920, loss 0.20944109029863855\n",
      "Epoch: 920, loss 0.20236461906376962\n",
      "Epoch: 930, loss 0.2882163820234745\n",
      "Epoch: 930, loss 0.28813634411138955\n",
      "Epoch: 930, loss 0.28792159934428535\n",
      "Epoch: 930, loss 0.20207717575720865\n",
      "Epoch: 930, loss 0.20203988638327525\n",
      "Epoch: 930, loss 0.20201849901713811\n",
      "Epoch: 930, loss 0.20902317213514038\n",
      "Epoch: 930, loss 0.2019823695788243\n",
      "Epoch: 940, loss 0.2886023452594748\n",
      "Epoch: 940, loss 0.2885222886001443\n",
      "Epoch: 940, loss 0.28830764271718906\n",
      "Epoch: 940, loss 0.20169710553262452\n",
      "Epoch: 940, loss 0.2016599242036669\n",
      "Epoch: 940, loss 0.2016385655927474\n",
      "Epoch: 940, loss 0.2086078884570845\n",
      "Epoch: 940, loss 0.20160244413611045\n",
      "Epoch: 950, loss 0.2889869029429682\n",
      "Epoch: 950, loss 0.28890682796801676\n",
      "Epoch: 950, loss 0.28869228167279404\n",
      "Epoch: 950, loss 0.20131934650402583\n",
      "Epoch: 950, loss 0.2012822725347859\n",
      "Epoch: 950, loss 0.20126094269271189\n",
      "Epoch: 950, loss 0.20819522290613474\n",
      "Epoch: 950, loss 0.20122482981484216\n",
      "Epoch: 960, loss 0.28937005462540755\n",
      "Epoch: 960, loss 0.28928996176340216\n",
      "Epoch: 960, loss 0.28907551574999035\n",
      "Epoch: 960, loss 0.2009438857759908\n",
      "Epoch: 960, loss 0.20090691848586573\n",
      "Epoch: 960, loss 0.20088561742294275\n",
      "Epoch: 960, loss 0.20778515918154122\n",
      "Epoch: 960, loss 0.20084951370594817\n",
      "Epoch: 970, loss 0.2897517999643703\n",
      "Epoch: 970, loss 0.2896716896408108\n",
      "Epoch: 970, loss 0.2894573445938178\n",
      "Epoch: 970, loss 0.20057071046615976\n",
      "Epoch: 970, loss 0.200533849179166\n",
      "Epoch: 970, loss 0.20051257690245383\n",
      "Epoch: 970, loss 0.2073776810410876\n",
      "Epoch: 970, loss 0.20047648291375847\n",
      "Epoch: 980, loss 0.29013213872197674\n",
      "Epoch: 980, loss 0.29005201135928715\n",
      "Epoch: 980, loss 0.2898377679538853\n",
      "Epoch: 980, loss 0.20019980770688575\n",
      "Epoch: 980, loss 0.20016305175162344\n",
      "Epoch: 980, loss 0.20014180826501088\n",
      "Epoch: 980, loss 0.2069727723020115\n",
      "Epoch: 980, loss 0.20010572455764833\n",
      "Epoch: 990, loss 0.2905110707633129\n",
      "Epoch: 990, loss 0.2904309267808341\n",
      "Epoch: 990, loss 0.2902167856827974\n",
      "Epoch: 990, loss 0.1998311646468432\n",
      "Epoch: 990, loss 0.19979451335646115\n",
      "Epoch: 990, loss 0.19977329866074\n",
      "Epoch: 990, loss 0.20657041684189748\n",
      "Epoch: 990, loss 0.1997372257736404\n"
     ]
    }
   ],
   "source": [
    "def train(lr: float) -> None:\n",
    "    for epoch in range(1000):\n",
    "        for x_batch, t_batch in zip(train_x_data, train_t_data_onehot):\n",
    "            y_data = model_back(x_batch)\n",
    "            loss = mean_square_error(y_data, t_batch)\n",
    "            \n",
    "            # backpropagation\n",
    "            round_E_round_b3 = np.array([\n",
    "                (y_data[0] - t_batch[0]) * y_data[0] * (1 - y_data[0]),\n",
    "                (y_data[1] - t_batch[1]) * y_data[1] * (1 - y_data[1])\n",
    "            ])\n",
    "            round_E_round_W3 = model_back.a2.T @ round_E_round_b3\n",
    "            model_back.W3 -= lr * round_E_round_W3\n",
    "            model_back.b3 -= lr * round_E_round_b3\n",
    "            \n",
    "            round_E_round_b2 = (round_E_round_b3 @ model_back.W3.T) * (model_back.a2 * (1 - model_back.a2))\n",
    "            round_E_round_W2 = x_batch.T @ round_E_round_b2\n",
    "            model_back.W2 -= lr * round_E_round_W2\n",
    "            model_back.b2 -= lr * round_E_round_b2\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch: {epoch}, loss {loss}')\n",
    "\n",
    "\n",
    "train(lr=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 학습 속도 비교\n",
    "\n",
    "오차역전파를 가중치 갱신에 사용한 문제 6과 수치미분을 가중치 갱신에 사용한 문제7 간의 속도를 비교해보시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss 0.39306979336512143\n",
      "Epoch: 0, loss 0.3940685117316766\n",
      "Epoch: 0, loss 0.3954982227784679\n",
      "Epoch: 0, loss 0.26364038326313743\n",
      "Epoch: 0, loss 0.275435802263037\n",
      "Epoch: 0, loss 0.2636609821101887\n",
      "Epoch: 0, loss 0.170691377620301\n",
      "Epoch: 0, loss 0.245818137880464\n",
      "Epoch: 10, loss 0.3931562262701146\n",
      "Epoch: 10, loss 0.3943897130850803\n",
      "Epoch: 10, loss 0.3962744628391879\n",
      "Epoch: 10, loss 0.25945132632770646\n",
      "Epoch: 10, loss 0.27390749833203176\n",
      "Epoch: 10, loss 0.25841468284264396\n",
      "Epoch: 10, loss 0.15250179266295014\n",
      "Epoch: 10, loss 0.2336493786212255\n",
      "Epoch: 20, loss 0.3932472548656145\n",
      "Epoch: 20, loss 0.39479468567527004\n",
      "Epoch: 20, loss 0.39732829640916556\n",
      "Epoch: 20, loss 0.25430719844708094\n",
      "Epoch: 20, loss 0.2723683734701248\n",
      "Epoch: 20, loss 0.2514759981935887\n",
      "Epoch: 20, loss 0.13391822918108137\n",
      "Epoch: 20, loss 0.21704565531962802\n",
      "Epoch: 30, loss 0.39334116832901644\n",
      "Epoch: 30, loss 0.3953122909101074\n",
      "Epoch: 30, loss 0.3987750823863953\n",
      "Epoch: 30, loss 0.24787521408333218\n",
      "Epoch: 30, loss 0.2708072977666099\n",
      "Epoch: 30, loss 0.24210192209209236\n",
      "Epoch: 30, loss 0.11663089964131948\n",
      "Epoch: 30, loss 0.19524570386836299\n",
      "Epoch: 40, loss 0.3934354139958639\n",
      "Epoch: 40, loss 0.39597655868193116\n",
      "Epoch: 40, loss 0.40075285021215556\n",
      "Epoch: 40, loss 0.23982106741689066\n",
      "Epoch: 40, loss 0.2692024419462949\n",
      "Epoch: 40, loss 0.22950833873504334\n",
      "Epoch: 40, loss 0.10219772583620379\n",
      "Epoch: 40, loss 0.16913420881888613\n",
      "Epoch: 50, loss 0.3935260973166651\n",
      "Epoch: 50, loss 0.39681447312316015\n",
      "Epoch: 50, loss 0.4033702091474108\n",
      "Epoch: 50, loss 0.23001453995577378\n",
      "Epoch: 50, loss 0.2675213460198963\n",
      "Epoch: 50, loss 0.21340326434758933\n",
      "Epoch: 50, loss 0.09139854808494402\n",
      "Epoch: 50, loss 0.14234198755061167\n",
      "Epoch: 60, loss 0.3936085850913646\n",
      "Epoch: 60, loss 0.3978321757351141\n",
      "Epoch: 60, loss 0.4066375746338492\n",
      "Epoch: 60, loss 0.21871895855091816\n",
      "Epoch: 60, loss 0.2657254743705616\n",
      "Epoch: 60, loss 0.19459633108935392\n",
      "Epoch: 60, loss 0.08397835451118939\n",
      "Epoch: 60, loss 0.1195095481494878\n",
      "Epoch: 70, loss 0.39367919649514305\n",
      "Epoch: 70, loss 0.39901783157866727\n",
      "Epoch: 70, loss 0.410465218120612\n",
      "Epoch: 70, loss 0.2064903367500485\n",
      "Epoch: 70, loss 0.2637730039495442\n",
      "Epoch: 70, loss 0.17482661514550565\n",
      "Epoch: 70, loss 0.0790676026585129\n",
      "Epoch: 70, loss 0.10280738627641456\n",
      "Epoch: 80, loss 0.39373573728656985\n",
      "Epoch: 80, loss 0.40035037676324453\n",
      "Epoch: 80, loss 0.4147064400089986\n",
      "Epoch: 80, loss 0.193959495269737\n",
      "Epoch: 80, loss 0.261622819735849\n",
      "Epoch: 80, loss 0.15596240101102304\n",
      "Epoch: 80, loss 0.0758031338213615\n",
      "Epoch: 80, loss 0.09159650218372377\n",
      "Epoch: 90, loss 0.39377686481457114\n",
      "Epoch: 90, loss 0.4017996046532166\n",
      "Epoch: 90, loss 0.41918251530641537\n",
      "Epoch: 90, loss 0.18172329371383258\n",
      "Epoch: 90, loss 0.2592454871096345\n",
      "Epoch: 90, loss 0.13936578519769596\n",
      "Epoch: 90, loss 0.07357893930654083\n",
      "Epoch: 90, loss 0.0842927999449621\n",
      "Epoch: 100, loss 0.3938017959058979\n",
      "Epoch: 100, loss 0.40332799159290483\n",
      "Epoch: 100, loss 0.4237104956272821\n",
      "Epoch: 100, loss 0.1702592682628221\n",
      "Epoch: 100, loss 0.25663133915796943\n",
      "Epoch: 100, loss 0.1256343684388445\n",
      "Epoch: 100, loss 0.07201574391013843\n",
      "Epoch: 100, loss 0.07951098142884086\n",
      "Epoch: 110, loss 0.39381045580247404\n",
      "Epoch: 110, loss 0.40489891467294437\n",
      "Epoch: 110, loss 0.42814045323489125\n",
      "Epoch: 110, loss 0.15985216389754098\n",
      "Epoch: 110, loss 0.25378712662653913\n",
      "Epoch: 110, loss 0.11470540937892992\n",
      "Epoch: 110, loss 0.07088078716567359\n",
      "Epoch: 110, loss 0.07630369154451906\n",
      "Epoch: 120, loss 0.3938035473775136\n",
      "Epoch: 120, loss 0.40648420679671043\n",
      "Epoch: 120, loss 0.4323762474451408\n",
      "Epoch: 120, loss 0.15059321358940772\n",
      "Epoch: 120, loss 0.2507257761458716\n",
      "Epoch: 120, loss 0.1061600271366987\n",
      "Epoch: 120, loss 0.07003032770606174\n",
      "Epoch: 120, loss 0.07408016684443426\n",
      "Epoch: 130, loss 0.3937824138965147\n",
      "Epoch: 130, loss 0.4080667934958584\n",
      "Epoch: 130, loss 0.4363727673502873\n",
      "Epoch: 130, loss 0.14243775962809554\n",
      "Epoch: 130, loss 0.24745703092068302\n",
      "Epoch: 130, loss 0.09949206486471392\n",
      "Epoch: 130, loss 0.06937453565144566\n",
      "Epoch: 130, loss 0.07248349935792299\n",
      "Epoch: 140, loss 0.39374883234083424\n",
      "Epoch: 140, loss 0.40963963374186196\n",
      "Epoch: 140, loss 0.4401216486788788\n",
      "Epoch: 140, loss 0.1352710902769207\n",
      "Epoch: 140, loss 0.24398200147571486\n",
      "Epoch: 140, loss 0.09424822051879014\n",
      "Epoch: 140, loss 0.0688563303478223\n",
      "Epoch: 140, loss 0.07129818604487917\n",
      "Epoch: 150, loss 0.3937048495769273\n",
      "Epoch: 150, loss 0.4112033808930242\n",
      "Epoch: 150, loss 0.4436366078050812\n",
      "Epoch: 150, loss 0.12895551739389902\n",
      "Epoch: 150, loss 0.24029092975555802\n",
      "Epoch: 150, loss 0.09006995391656242\n",
      "Epoch: 150, loss 0.06843865527697983\n",
      "Epoch: 150, loss 0.07039196969578537\n",
      "Epoch: 160, loss 0.39365269166507094\n",
      "Epoch: 160, loss 0.41276415503662667\n",
      "Epoch: 160, loss 0.44694265517929693\n",
      "Epoch: 160, loss 0.12335644084836742\n",
      "Epoch: 160, loss 0.2363626932108263\n",
      "Epoch: 160, loss 0.08668929022595655\n",
      "Epoch: 160, loss 0.06809686115262731\n",
      "Epoch: 160, loss 0.0696816738364103\n",
      "Epoch: 170, loss 0.39359473533944755\n",
      "Epoch: 170, loss 0.414331847560911\n",
      "Epoch: 170, loss 0.4500692944642364\n",
      "Epoch: 170, loss 0.11835398043100237\n",
      "Epoch: 170, loss 0.2321650686955568\n",
      "Epoch: 170, loss 0.08391068631638898\n",
      "Epoch: 170, loss 0.06781414013309837\n",
      "Epoch: 170, loss 0.06911354545730401\n",
      "Epoch: 180, loss 0.3935335216376456\n",
      "Epoch: 180, loss 0.41591891796048225\n",
      "Epoch: 180, loss 0.45304655040855535\n",
      "Epoch: 180, loss 0.1138466717579501\n",
      "Epoch: 180, loss 0.22765539878761115\n",
      "Epoch: 180, loss 0.08159251359965002\n",
      "Epoch: 180, loss 0.06757876303405325\n",
      "Epoch: 180, loss 0.06865190659345957\n",
      "Epoch: 190, loss 0.39347179304095836\n",
      "Epoch: 190, loss 0.41753948994308776\n",
      "Epoch: 190, loss 0.45590266582143535\n",
      "Epoch: 190, loss 0.10975147341739051\n",
      "Epoch: 190, loss 0.22278179714051116\n",
      "Epoch: 190, loss 0.07963217185727997\n",
      "Epoch: 190, loss 0.06738238222105422\n",
      "Epoch: 190, loss 0.06827250013785612\n",
      "Epoch: 200, loss 0.3934125361628158\n",
      "Epoch: 200, loss 0.41920851432075273\n",
      "Epoch: 200, loss 0.4586626102855097\n",
      "Epoch: 200, loss 0.10600241678953716\n",
      "Epoch: 200, loss 0.21748544983946835\n",
      "Epoch: 200, loss 0.07795516123950073\n",
      "Epoch: 200, loss 0.06721897078943787\n",
      "Epoch: 200, loss 0.06795850520364148\n",
      "Epoch: 210, loss 0.39335900792743544\n",
      "Epoch: 210, loss 0.42094075058565944\n",
      "Epoch: 210, loss 0.46134682695568807\n",
      "Epoch: 210, loss 0.1025490270810813\n",
      "Epoch: 210, loss 0.211704985032964\n",
      "Epoch: 210, loss 0.07650736564906603\n",
      "Epoch: 210, loss 0.06708414767418994\n",
      "Epoch: 210, loss 0.06769809489272824\n",
      "Epoch: 220, loss 0.39331471310670035\n",
      "Epoch: 220, loss 0.42274930900185126\n",
      "Epoch: 220, loss 0.46396986447412814\n",
      "Epoch: 220, loss 0.09935495349424159\n",
      "Epoch: 220, loss 0.20538425445486078\n",
      "Epoch: 220, loss 0.07524966840083339\n",
      "Epoch: 220, loss 0.06697474014534587\n",
      "Epoch: 220, loss 0.06748290065584245\n",
      "Epoch: 230, loss 0.393283286295669\n",
      "Epoch: 230, loss 0.4246435207329601\n",
      "Epoch: 230, loss 0.46653874914585075\n",
      "Epoch: 230, loss 0.09639682875529383\n",
      "Epoch: 230, loss 0.19848494034227096\n",
      "Epoch: 230, loss 0.0741541488345403\n",
      "Epoch: 230, loss 0.0668884918047653\n",
      "Epoch: 230, loss 0.06730701412005083\n",
      "Epoch: 240, loss 0.39326821873669904\n",
      "Epoch: 240, loss 0.4266260409563089\n",
      "Epoch: 240, loss 0.46905122182548253\n",
      "Epoch: 240, loss 0.09366308062798709\n",
      "Epoch: 240, loss 0.1910045772681162\n",
      "Epoch: 240, loss 0.07320126502286022\n",
      "Epoch: 240, loss 0.06682385453152372\n",
      "Epoch: 240, loss 0.06716630226699308\n",
      "Epoch: 250, loss 0.39327237725086106\n",
      "Epoch: 250, loss 0.4286894428149777\n",
      "Epoch: 250, loss 0.4714943375853149\n",
      "Epoch: 250, loss 0.09115220060333987\n",
      "Epoch: 250, loss 0.18299802482692426\n",
      "Epoch: 250, loss 0.07237756507960806\n",
      "Epoch: 250, loss 0.06677981858255055\n",
      "Epoch: 250, loss 0.06705789315552425\n",
      "Epoch: 260, loss 0.39329731716632915\n",
      "Epoch: 260, loss 0.4308131682499155\n",
      "Epoch: 260, loss 0.4738443253976926\n",
      "Epoch: 260, loss 0.08886992706962232\n",
      "Epoch: 260, loss 0.1745958559387173\n",
      "Epoch: 260, loss 0.07167361483010677\n",
      "Epoch: 260, loss 0.06675574574765605\n",
      "Epoch: 260, loss 0.06697974238725467\n",
      "Epoch: 270, loss 0.3933425132130117\n",
      "Epoch: 270, loss 0.4329623466047793\n",
      "Epoch: 270, loss 0.4760687329840724\n",
      "Epoch: 270, loss 0.08682510279556413\n",
      "Epoch: 270, loss 0.1660085218602803\n",
      "Epoch: 270, loss 0.07108202574190704\n",
      "Epoch: 270, loss 0.06675118542966521\n",
      "Epoch: 270, loss 0.06693023786247987\n",
      "Epoch: 280, loss 0.3934047854826219\n",
      "Epoch: 280, loss 0.4350900658423804\n",
      "Epoch: 280, loss 0.4781313132994848\n",
      "Epoch: 280, loss 0.0850246967992844\n",
      "Epoch: 280, loss 0.1575057411294138\n",
      "Epoch: 280, loss 0.07059570662439163\n",
      "Epoch: 280, loss 0.06676567853606039\n",
      "Epoch: 280, loss 0.06690784996541985\n",
      "Epoch: 290, loss 0.39347825747905524\n",
      "Epoch: 290, loss 0.4371435496716608\n",
      "Epoch: 290, loss 0.47999876525879726\n",
      "Epoch: 290, loss 0.08346931180368618\n",
      "Epoch: 290, loss 0.14937097202382504\n",
      "Epoch: 290, loss 0.07020663575034626\n",
      "Epoch: 290, loss 0.06679858290253132\n",
      "Epoch: 290, loss 0.06691087299125967\n",
      "Epoch: 300, loss 0.393555019264326\n",
      "Epoch: 300, loss 0.4390726257921948\n",
      "Epoch: 300, loss 0.48164710428696317\n",
      "Epoch: 300, loss 0.08215071826398133\n",
      "Epoch: 300, loss 0.14184680696315885\n",
      "Epoch: 300, loss 0.06990540528560191\n",
      "Epoch: 300, loss 0.066848966666874\n",
      "Epoch: 300, loss 0.06693730576628426\n",
      "Epoch: 310, loss 0.3936263256184436\n",
      "Epoch: 310, loss 0.4408373881942248\n",
      "Epoch: 310, loss 0.4830653306706462\n",
      "Epoch: 310, loss 0.0810521466299077\n",
      "Epoch: 310, loss 0.13509477994768262\n",
      "Epoch: 310, loss 0.06968151794014275\n",
      "Epoch: 310, loss 0.06691559694669505\n",
      "Epoch: 310, loss 0.06698487812086085\n",
      "Epoch: 320, loss 0.3936838913803243\n",
      "Epoch: 320, loss 0.4424124379904705\n",
      "Epoch: 320, loss 0.48425547156704785\n",
      "Epoch: 320, loss 0.08015076136996097\n",
      "Epoch: 320, loss 0.12918388433832953\n",
      "Epoch: 320, loss 0.06952412514302043\n",
      "Epoch: 320, loss 0.06699701160992506\n",
      "Epoch: 320, loss 0.0670511764619043\n",
      "Epoch: 330, loss 0.3937208622338258\n",
      "Epoch: 330, loss 0.4437870905896498\n",
      "Epoch: 330, loss 0.48522984213564657\n",
      "Epoch: 330, loss 0.0794209502679131\n",
      "Epoch: 330, loss 0.12410476226548078\n",
      "Epoch: 330, loss 0.06942281069002647\n",
      "Epoch: 330, loss 0.06709163242124638\n",
      "Epoch: 330, loss 0.06713379780268253\n",
      "Epoch: 340, loss 0.3937322779155368\n",
      "Epoch: 340, loss 0.44496274502301214\n",
      "Epoch: 340, loss 0.48600720572008915\n",
      "Epoch: 340, loss 0.07883720461404642\n",
      "Epoch: 340, loss 0.11979604391486588\n",
      "Epoch: 340, loss 0.06936815518162426\n",
      "Epoch: 340, loss 0.06719787608845892\n",
      "Epoch: 340, loss 0.06723047712149942\n",
      "Epoch: 350, loss 0.393715088068675\n",
      "Epoch: 350, loss 0.4459491651453472\n",
      "Epoch: 350, loss 0.48660923084409946\n",
      "Epoch: 350, loss 0.07837601733691404\n",
      "Epoch: 350, loss 0.11617018634587545\n",
      "Epoch: 350, loss 0.06935200991384996\n",
      "Epoch: 350, loss 0.06731423749048884\n",
      "Epoch: 350, loss 0.06733916541853585\n",
      "Epoch: 360, loss 0.3936678938861072\n",
      "Epoch: 360, loss 0.44676097545845167\n",
      "Epoch: 360, loss 0.4870579040265174\n",
      "Epoch: 360, loss 0.07801680382241073\n",
      "Epoch: 360, loss 0.11313249985479484\n",
      "Epoch: 360, loss 0.06936753577578475\n",
      "Epoch: 360, loss 0.06743933900381013\n",
      "Epoch: 360, loss 0.06745806137257801\n",
      "Epoch: 370, loss 0.3935905819208803\n",
      "Epoch: 370, loss 0.4474149657109884\n",
      "Epoch: 370, loss 0.4873739591756422\n",
      "Epoch: 370, loss 0.0777421190598716\n",
      "Epoch: 370, loss 0.11059252648838164\n",
      "Epoch: 370, loss 0.069409100670416\n",
      "Epoch: 370, loss 0.06757195153316478\n",
      "Epoch: 370, loss 0.0675856104148363\n",
      "Epoch: 380, loss 0.3934839591027334\n",
      "Epoch: 380, loss 0.44792828494120207\n",
      "Epoch: 380, loss 0.48757610180365407\n",
      "Epoch: 380, loss 0.07753747122162277\n",
      "Epoch: 380, loss 0.10846950962230992\n",
      "Epoch: 380, loss 0.0694721147070214\n",
      "Epoch: 380, loss 0.06771099641758516\n",
      "Epoch: 380, loss 0.06772048548607859\n",
      "Epoch: 390, loss 0.3933494414384894\n",
      "Epoch: 390, loss 0.44831736634639885\n",
      "Epoch: 390, loss 0.4876807542325181\n",
      "Epoch: 390, loss 0.07739095504749179\n",
      "Epoch: 390, loss 0.10669413420804942\n",
      "Epoch: 390, loss 0.06955285352407886\n",
      "Epoch: 390, loss 0.06785553642155873\n",
      "Epoch: 390, loss 0.06786155997256224\n",
      "Epoch: 400, loss 0.3931888114491812\n",
      "Epoch: 400, loss 0.44859736903937053\n",
      "Epoch: 400, loss 0.4877020985734827\n",
      "Epoch: 400, loss 0.07729283973850486\n",
      "Epoch: 400, loss 0.10520825527663188\n",
      "Epoch: 400, loss 0.069648295459425\n",
      "Epoch: 400, loss 0.06800476163451678\n",
      "Epoch: 400, loss 0.06800787918377371\n",
      "Epoch: 410, loss 0.39300404026250274\n",
      "Epoch: 410, loss 0.44878195081307365\n",
      "Epoch: 410, loss 0.48765226639051584\n",
      "Epoch: 410, loss 0.07723517975727379\n",
      "Epoch: 410, loss 0.10396371895240679\n",
      "Epoch: 410, loss 0.06975598246199144\n",
      "Epoch: 410, loss 0.06815797385596245\n",
      "Epoch: 410, loss 0.06815863364930902\n",
      "Epoch: 420, loss 0.39279716302428425\n",
      "Epoch: 420, loss 0.44888323630370985\n",
      "Epoch: 420, loss 0.48754158421117116\n",
      "Epoch: 420, loss 0.07721147635393028\n",
      "Epoch: 420, loss 0.10292089747283362\n",
      "Epoch: 420, loss 0.06987390616152603\n",
      "Epoch: 420, loss 0.06831457141538215\n",
      "Epoch: 420, loss 0.06831313559391114\n",
      "Epoch: 430, loss 0.3925701952126501\n",
      "Epoch: 430, loss 0.44891189090126055\n",
      "Epoch: 430, loss 0.48737882540167243\n",
      "Epoch: 430, loss 0.07721639603037667\n",
      "Epoch: 430, loss 0.10204724872222297\n",
      "Epoch: 430, loss 0.07000041670760607\n",
      "Epoch: 430, loss 0.06847403534665622\n",
      "Epoch: 430, loss 0.0684707988996723\n",
      "Epoch: 440, loss 0.3923250789468742\n",
      "Epoch: 440, loss 0.4488772450025082\n",
      "Epoch: 440, loss 0.4871714443330448\n",
      "Epoch: 440, loss 0.07724554214721602\n",
      "Epoch: 440, loss 0.10131603276994298\n",
      "Epoch: 440, loss 0.07013415072811613\n",
      "Epoch: 440, loss 0.06863591724482385\n",
      "Epoch: 440, loss 0.06863112235728261\n",
      "Epoch: 450, loss 0.39206365061828347\n",
      "Epoch: 450, loss 0.4487874362317975\n",
      "Epoch: 450, loss 0.4869257831920043\n",
      "Epoch: 450, loss 0.077295272165837\n",
      "Epoch: 450, loss 0.10070522494779484\n",
      "Epoch: 450, loss 0.07027397471070045\n",
      "Epoch: 450, loss 0.06879982882103419\n",
      "Epoch: 450, loss 0.06879367580564927\n",
      "Epoch: 460, loss 0.3917876233156106\n",
      "Epoch: 460, loss 0.44864955179862437\n",
      "Epoch: 460, loss 0.4866472494060337\n",
      "Epoch: 460, loss 0.07736255239175446\n",
      "Epoch: 460, loss 0.10019662099433836\n",
      "Epoch: 460, loss 0.07041894055312792\n",
      "Epoch: 460, loss 0.06896543302425497\n",
      "Epoch: 460, loss 0.06895808871285651\n",
      "Epoch: 470, loss 0.3914985792921038\n",
      "Epoch: 470, loss 0.4484697619404432\n",
      "Epoch: 470, loss 0.4863404653233855\n",
      "Epoch: 470, loss 0.07744484278877789\n",
      "Epoch: 470, loss 0.09977511190737562\n",
      "Epoch: 470, loss 0.0705682506032971\n",
      "Epoch: 470, loss 0.06913243654196208\n",
      "Epoch: 470, loss 0.06912404077719948\n",
      "Epoch: 480, loss 0.391197969087865\n",
      "Epoch: 480, loss 0.4482534404959854\n",
      "Epoch: 480, loss 0.48600939329770243\n",
      "Epoch: 480, loss 0.07754000558180069\n",
      "Epoch: 480, loss 0.0994281012529854\n",
      "Epoch: 480, loss 0.07072123006047573\n",
      "Epoch: 480, loss 0.0693005834826654\n",
      "Epoch: 480, loss 0.0692912541805353\n",
      "Epoch: 490, loss 0.39088711493085104\n",
      "Epoch: 490, loss 0.4480052714918964\n",
      "Epoch: 490, loss 0.48565743971578873\n",
      "Epoch: 490, loss 0.07764623254994896\n",
      "Epoch: 490, loss 0.09914503869811206\n",
      "Epoch: 490, loss 0.07087730508001747\n",
      "Epoch: 490, loss 0.06946965005593113\n",
      "Epoch: 490, loss 0.0694594871856147\n",
      "Epoch: 500, loss 0.39056721676878153\n",
      "Epoch: 500, loss 0.447729342118237\n",
      "Epoch: 500, loss 0.48528754135845303\n",
      "Epoch: 500, loss 0.07776198696643778\n",
      "Epoch: 500, loss 0.09891704684422473\n",
      "Epoch: 500, loss 0.0710359853038369\n",
      "Epoch: 500, loss 0.069639440087197\n",
      "Epoch: 500, loss 0.06962852882465549\n",
      "Epoch: 510, loss 0.39023935980230295\n",
      "Epoch: 510, loss 0.44742922318266254\n",
      "Epoch: 510, loss 0.48490223711134706\n",
      "Epoch: 510, loss 0.07788595701859\n",
      "Epoch: 510, loss 0.09873662229984045\n",
      "Epoch: 510, loss 0.0711968498364786\n",
      "Epoch: 510, loss 0.06980978122827913\n",
      "Epoch: 510, loss 0.06979819447455834\n",
      "Epoch: 520, loss 0.3899045227544981\n",
      "Epoch: 520, loss 0.4471080384100961\n",
      "Epoch: 520, loss 0.48450372760551297\n",
      "Epoch: 520, loss 0.07801701824469945\n",
      "Epoch: 520, loss 0.0985973955731928\n",
      "Epoch: 520, loss 0.07135953591571817\n",
      "Epoch: 520, loss 0.06998052174685776\n",
      "Epoch: 520, loss 0.0699683221542132\n",
      "Epoch: 530, loss 0.3895635863668493\n",
      "Epoch: 530, loss 0.4467685239962831\n",
      "Epoch: 530, loss 0.48409392494296066\n",
      "Epoch: 530, loss 0.07815420307653717\n",
      "Epoch: 530, loss 0.0984939375103939\n",
      "Epoch: 530, loss 0.07152372970139861\n",
      "Epoch: 530, loss 0.07015152779804512\n",
      "Epoch: 530, loss 0.0701387694118899\n",
      "Epoch: 540, loss 0.3892173417891509\n",
      "Epoch: 540, loss 0.4464130797464053\n",
      "Epoch: 540, loss 0.4836744942834032\n",
      "Epoch: 540, loss 0.07829667600477291\n",
      "Epoch: 540, loss 0.098421602594393\n",
      "Epoch: 540, loss 0.07168915873900103\n",
      "Epoch: 540, loss 0.07032268109805836\n",
      "Epoch: 540, loss 0.07030941069681323\n",
      "Epoch: 550, loss 0.3888664986535606\n",
      "Epoch: 550, loss 0.4460438129999464\n",
      "Epoch: 550, loss 0.4832468887441451\n",
      "Epoch: 550, loss 0.07844371321508903\n",
      "Epoch: 550, loss 0.0983764014982644\n",
      "Epoch: 550, loss 0.07185558575527659\n",
      "Epoch: 550, loss 0.07049387693415932\n",
      "Epoch: 550, loss 0.07048013512982551\n",
      "Epoch: 560, loss 0.38851169270739977\n",
      "Epoch: 560, loss 0.4456625763966339\n",
      "Epoch: 560, loss 0.48281237879521255\n",
      "Epoch: 560, loss 0.07859468579698359\n",
      "Epoch: 560, loss 0.09835489692822816\n",
      "Epoch: 560, loss 0.07202280351989612\n",
      "Epoch: 560, loss 0.07066502245668004\n",
      "Epoch: 560, loss 0.07065084460455354\n",
      "Epoch: 570, loss 0.38815349293691864\n",
      "Epoch: 570, loss 0.4452710003942949\n",
      "Epoch: 570, loss 0.4823720771104033\n",
      "Epoch: 570, loss 0.07874904582284663\n",
      "Epoch: 570, loss 0.09835411807802824\n",
      "Epoch: 570, loss 0.07219063056549421\n",
      "Epoch: 570, loss 0.07083603520849599\n",
      "Epoch: 570, loss 0.07082145216360328\n",
      "Epoch: 580, loss 0.3877924081530634\n",
      "Epoch: 580, loss 0.4448705213168931\n",
      "Epoch: 580, loss 0.48192695965501176\n",
      "Epoch: 580, loss 0.07890631474553736\n",
      "Epoch: 580, loss 0.09837149001899043\n",
      "Epoch: 580, loss 0.07235890760318672\n",
      "Epoch: 580, loss 0.07100684185510836\n",
      "Epoch: 580, loss 0.07099188060472514\n",
      "Epoch: 590, loss 0.387428893036147\n",
      "Epoch: 590, loss 0.44446240559373223\n",
      "Epoch: 590, loss 0.4814778836456709\n",
      "Epoch: 590, loss 0.07906607367900229\n",
      "Epoch: 590, loss 0.09840477513027354\n",
      "Epoch: 590, loss 0.07252749450496834\n",
      "Epoch: 590, loss 0.07117737708482419\n",
      "Epoch: 590, loss 0.07116206128017592\n",
      "Epoch: 600, loss 0.38706335365299993\n",
      "Epoch: 600, loss 0.4440477707490146\n",
      "Epoch: 600, loss 0.48102560290050356\n",
      "Epoch: 600, loss 0.07922795521662612\n",
      "Epoch: 600, loss 0.09845202428111512\n",
      "Epoch: 600, loss 0.0726962677509232\n",
      "Epoch: 600, loss 0.0713475826537028\n",
      "Epoch: 600, loss 0.07133193305913295\n",
      "Epoch: 610, loss 0.38669615247061084\n",
      "Epoch: 610, loss 0.4436276036141549\n",
      "Epoch: 610, loss 0.48057078100341977\n",
      "Epoch: 610, loss 0.07939163651208841\n",
      "Epoch: 610, loss 0.09851153594988608\n",
      "Epoch: 610, loss 0.07286511825974498\n",
      "Epoch: 610, loss 0.07151740655414202\n",
      "Epoch: 610, loss 0.07150144142831777\n",
      "Epoch: 620, loss 0.3863276128963114\n",
      "Epoch: 620, loss 0.44320277616175396\n",
      "Epoch: 620, loss 0.48011400263029813\n",
      "Epoch: 620, loss 0.07955683340226148\n",
      "Epoch: 620, loss 0.09858182183424462\n",
      "Epoch: 620, loss 0.07303394953712739\n",
      "Epoch: 620, loss 0.07168680228943802\n",
      "Epoch: 620, loss 0.07167053771027382\n",
      "Epoch: 630, loss 0.38595802337766855\n",
      "Epoch: 630, loss 0.4427740592983572\n",
      "Epoch: 630, loss 0.4796557833234357\n",
      "Epoch: 630, loss 0.07972329539460307\n",
      "Epoch: 630, loss 0.09866157779587477\n",
      "Epoch: 630, loss 0.07320267608915096\n",
      "Epoch: 630, loss 0.07185572823946446\n",
      "Epoch: 630, loss 0.0718391783821829\n",
      "Epoch: 640, loss 0.38558764109628774\n",
      "Epoch: 640, loss 0.44234213490121715\n",
      "Epoch: 640, loss 0.47919657795094417\n",
      "Epoch: 640, loss 0.07989080137536339\n",
      "Epoch: 640, loss 0.0987496592106327\n",
      "Epoch: 640, loss 0.07337122205773738\n",
      "Epoch: 640, loss 0.0720241471049565\n",
      "Epoch: 640, loss 0.07200732448092918\n",
      "Epoch: 650, loss 0.3852166952894952\n",
      "Epoch: 650, loss 0.44190760634092546\n",
      "Epoch: 650, loss 0.47873678804754716\n",
      "Epoch: 650, loss 0.08005915592168777\n",
      "Epoch: 650, loss 0.09884505997403042\n",
      "Epoch: 650, loss 0.07353952004308661\n",
      "Epoch: 650, loss 0.0721920254197922\n",
      "Epoch: 650, loss 0.07217494108239413\n",
      "Epoch: 660, loss 0.38484539023272285\n",
      "Epoch: 660, loss 0.4414710076953511\n",
      "Epoch: 660, loss 0.47827676820041276\n",
      "Epoch: 660, loss 0.0802281861220312\n",
      "Epoch: 660, loss 0.09894689455387393\n",
      "Epoch: 660, loss 0.07370751008429952\n",
      "Epoch: 660, loss 0.0723593331222677\n",
      "Epoch: 660, loss 0.07234199684486038\n",
      "Epoch: 670, loss 0.3844739079137552\n",
      "Epoch: 670, loss 0.4410328118298896\n",
      "Epoch: 670, loss 0.4778168316169309\n",
      "Epoch: 670, loss 0.080397738826314\n",
      "Epoch: 670, loss 0.0990543825945228\n",
      "Epoch: 670, loss 0.07387513877439812\n",
      "Epoch: 670, loss 0.07252604317767786\n",
      "Epoch: 670, loss 0.07250846360793901\n",
      "Epoch: 680, loss 0.38410241042805904\n",
      "Epoch: 680, loss 0.44059343749346846\n",
      "Epoch: 680, loss 0.47735725498943254\n",
      "Epoch: 680, loss 0.08056767826093311\n",
      "Epoch: 680, loss 0.09916683566719933\n",
      "Epoch: 680, loss 0.07404235849000529\n",
      "Epoch: 680, loss 0.07269213124562471\n",
      "Epoch: 680, loss 0.07267431603972174\n",
      "Epoch: 690, loss 0.38373104212228815\n",
      "Epoch: 690, loss 0.44015325555822316\n",
      "Epoch: 690, loss 0.47689828275378493\n",
      "Epoch: 690, loss 0.0807378839547814\n",
      "Epoch: 690, loss 0.09928364583282968\n",
      "Epoch: 690, loss 0.07420912671922456\n",
      "Epoch: 690, loss 0.07285757538640564\n",
      "Epoch: 690, loss 0.07283953132592627\n",
      "Epoch: 700, loss 0.38335993151092357\n",
      "Epoch: 700, loss 0.43971259451268874\n",
      "Epoch: 700, loss 0.47644013082395387\n",
      "Epoch: 700, loss 0.08090824893136744\n",
      "Epoch: 700, loss 0.099404275741891\n",
      "Epoch: 700, loss 0.07437540547391805\n",
      "Epoch: 700, loss 0.07302235580160865\n",
      "Epoch: 700, loss 0.07300408889568773\n",
      "Epoch: 710, loss 0.38298919298890644\n",
      "Epoch: 710, loss 0.43927174530301827\n",
      "Epoch: 710, loss 0.47598298987224397\n",
      "Epoch: 710, loss 0.08107867812943051\n",
      "Epoch: 710, loss 0.09952825004265223\n",
      "Epoch: 710, loss 0.07454116077477216\n",
      "Epoch: 710, loss 0.07318645460471176\n",
      "Epoch: 710, loss 0.07316797017940624\n",
      "Epoch: 720, loss 0.3826189283610849\n",
      "Epoch: 720, loss 0.43883096560379875\n",
      "Epoch: 720, loss 0.4755270282146986\n",
      "Epoch: 720, loss 0.08124908702039543\n",
      "Epoch: 720, loss 0.09965514790719486\n",
      "Epoch: 720, loss 0.07470636219931992\n",
      "Epoch: 720, loss 0.07334985561803478\n",
      "Epoch: 720, loss 0.07333115839467899\n",
      "Epoch: 730, loss 0.3822492282073897\n",
      "Epoch: 730, loss 0.4383904835890202\n",
      "Epoch: 730, loss 0.475072394352511\n",
      "Epoch: 730, loss 0.08141940039593568\n",
      "Epoch: 730, loss 0.09978459651569764\n",
      "Epoch: 730, loss 0.07487098248458524\n",
      "Epoch: 730, loss 0.07351254419287909\n",
      "Epoch: 730, loss 0.07349363835689068\n",
      "Epoch: 740, loss 0.38188017310084\n",
      "Epoch: 740, loss 0.43795050126436674\n",
      "Epoch: 740, loss 0.47461921921314254\n",
      "Epoch: 740, loss 0.08158955130295434\n",
      "Epoch: 740, loss 0.09991626536484488\n",
      "Epoch: 740, loss 0.07503499717723239\n",
      "Epoch: 740, loss 0.07367450705009372\n",
      "Epoch: 740, loss 0.07365539631148202\n",
      "Epoch: 750, loss 0.3815118346938504\n",
      "Epoch: 750, loss 0.43751119741400457\n",
      "Epoch: 750, loss 0.47416761812876235\n",
      "Epoch: 750, loss 0.08175948010665579\n",
      "Epoch: 750, loss 0.10004986128712909\n",
      "Epoch: 750, loss 0.07519838432513057\n",
      "Epoch: 750, loss 0.07383573213865313\n",
      "Epoch: 750, loss 0.07381641978530049\n",
      "Epoch: 760, loss 0.38114427668674694\n",
      "Epoch: 760, loss 0.43707273020815685\n",
      "Epoch: 760, loss 0.4737176925844865\n",
      "Epoch: 760, loss 0.08192913366519561\n",
      "Epoch: 760, loss 0.10018512408510435\n",
      "Epoch: 760, loss 0.07536112420511216\n",
      "Epoch: 760, loss 0.0739962085101463\n",
      "Epoch: 760, loss 0.07397669745477976\n",
      "Epoch: 770, loss 0.3807775556910165\n",
      "Epoch: 770, loss 0.4366352395118564\n",
      "Epoch: 770, loss 0.4732695317645514\n",
      "Epoch: 770, loss 0.08209846460173406\n",
      "Epoch: 770, loss 0.10032182269897649\n",
      "Epoch: 770, loss 0.0755231990824157\n",
      "Epoch: 770, loss 0.07415592620732442\n",
      "Epoch: 770, loss 0.07413621902896902\n",
      "Epoch: 780, loss 0.3804117219985449\n",
      "Epoch: 780, loss 0.43619884893020633\n",
      "Epoch: 780, loss 0.47282321392087\n",
      "Epoch: 780, loss 0.08226743066169223\n",
      "Epoch: 780, loss 0.10045975183784074\n",
      "Epoch: 780, loss 0.07568459299791755\n",
      "Epoch: 780, loss 0.07431487616508292\n",
      "Epoch: 780, loss 0.07429497514567776\n",
      "Epoch: 790, loss 0.38004682026692227\n",
      "Epoch: 790, loss 0.4357636676210593\n",
      "Epoch: 790, loss 0.4723788075852143\n",
      "Epoch: 790, loss 0.0824359941446858\n",
      "Epoch: 790, loss 0.10059872901489539\n",
      "Epoch: 790, loss 0.07584529157978219\n",
      "Epoch: 790, loss 0.07447305012245553\n",
      "Epoch: 790, loss 0.07445295727922427\n",
      "Epoch: 800, loss 0.3796828901298548\n",
      "Epoch: 800, loss 0.43532979190223586\n",
      "Epoch: 800, loss 0.4719363726435886\n",
      "Epoch: 800, loss 0.08260412140201134\n",
      "Epoch: 800, loss 0.10073859193533738\n",
      "Epoch: 800, loss 0.07600528187659261\n",
      "Epoch: 800, loss 0.07463044054435938\n",
      "Epoch: 800, loss 0.07461015765844783\n",
      "Epoch: 810, loss 0.37931996674078644\n",
      "Epoch: 810, loss 0.43489730667711557\n",
      "Epoch: 810, loss 0.47149596128899857\n",
      "Epoch: 810, loss 0.08277178239177296\n",
      "Epoch: 810, loss 0.10087919619272709\n",
      "Epoch: 810, loss 0.07616455220940851\n",
      "Epoch: 810, loss 0.07478704055198696\n",
      "Epoch: 810, loss 0.07476656919381394\n",
      "Epoch: 820, loss 0.37895808125695496\n",
      "Epoch: 820, loss 0.4344662866995381\n",
      "Epoch: 820, loss 0.47105761886682185\n",
      "Epoch: 820, loss 0.08293895028475708\n",
      "Epoch: 820, loss 0.10102041323562017\n",
      "Epoch: 820, loss 0.07632309204051863\n",
      "Epoch: 820, loss 0.0749428438608645\n",
      "Epoch: 820, loss 0.07492218541257586\n",
      "Epoch: 830, loss 0.37859726127036114\n",
      "Epoch: 830, loss 0.4340367976964674\n",
      "Epoch: 830, loss 0.4706213846252299\n",
      "Epoch: 830, loss 0.08310560111504306\n",
      "Epoch: 830, loss 0.1011621285713454\n",
      "Epoch: 830, loss 0.07648089185693353\n",
      "Epoch: 830, loss 0.07509784472571174\n",
      "Epoch: 830, loss 0.07507700040107763\n",
      "Epoch: 840, loss 0.37823753119143194\n",
      "Epoch: 840, loss 0.4336088973646691\n",
      "Epoch: 840, loss 0.47018729238160195\n",
      "Epoch: 840, loss 0.08327171347010165\n",
      "Epoch: 840, loss 0.10130424017817069\n",
      "Epoch: 840, loss 0.0766379430669103\n",
      "Epoch: 840, loss 0.07525203789134124\n",
      "Epoch: 840, loss 0.0752310087533952\n",
      "Epoch: 850, loss 0.37787891259053535\n",
      "Epoch: 850, loss 0.43318263625576714\n",
      "Epoch: 850, loss 0.4697553711145722\n",
      "Epoch: 850, loss 0.08343726821577\n",
      "Epoch: 850, loss 0.1014466571007895\n",
      "Epoch: 850, loss 0.07679423790800108\n",
      "Epoch: 850, loss 0.07540541854891768\n",
      "Epoch: 850, loss 0.07538420552559824\n",
      "Epoch: 860, loss 0.3775214245019614\n",
      "Epoch: 860, loss 0.43275805856233485\n",
      "Epoch: 860, loss 0.46932564549018074\n",
      "Epoch: 860, loss 0.08360224825207288\n",
      "Epoch: 860, loss 0.10158929820729347\n",
      "Epoch: 860, loss 0.07694976936530687\n",
      "Epoch: 860, loss 0.07555798229697774\n",
      "Epoch: 860, loss 0.0755365861950036\n",
      "Epoch: 870, loss 0.37716508369447366\n",
      "Epoch: 870, loss 0.4323352028162305\n",
      "Epoch: 870, loss 0.46889813632961463\n",
      "Epoch: 870, loss 0.08376663829633785\n",
      "Epoch: 870, loss 0.10173209108850331\n",
      "Epoch: 870, loss 0.07710453109876958\n",
      "Epoch: 870, loss 0.07570972510668066\n",
      "Epoch: 870, loss 0.07568814662386096\n",
      "Epoch: 880, loss 0.3768099049120943\n",
      "Epoch: 880, loss 0.43191410250906304\n",
      "Epoch: 880, loss 0.46847286102513674\n",
      "Epoch: 880, loss 0.08393042469048725\n",
      "Epoch: 880, loss 0.10187497108296847\n",
      "Epoch: 880, loss 0.07725851737847955\n",
      "Epoch: 880, loss 0.07586064329081704\n",
      "Epoch: 880, loss 0.07583888302697511\n",
      "Epoch: 890, loss 0.3764559010884004\n",
      "Epoch: 890, loss 0.431494786643583\n",
      "Epoch: 890, loss 0.46804983391005367\n",
      "Epoch: 890, loss 0.08409359522974572\n",
      "Epoch: 890, loss 0.10201788041290363\n",
      "Epoch: 890, loss 0.07741172302708643\n",
      "Epoch: 890, loss 0.07601073347615761\n",
      "Epoch: 890, loss 0.07598879194282566\n",
      "Epoch: 900, loss 0.3761030835372401\n",
      "Epoch: 900, loss 0.4310772802237549\n",
      "Epoch: 900, loss 0.4676290665878845\n",
      "Epoch: 900, loss 0.08425613901034171\n",
      "Epoch: 900, loss 0.10216076741821341\n",
      "Epoch: 900, loss 0.0775641433685155\n",
      "Epoch: 900, loss 0.07615999257876868\n",
      "Epoch: 900, loss 0.07613787020779196\n",
      "Epoch: 910, loss 0.3757514621224621\n",
      "Epoch: 910, loss 0.4306616046903702\n",
      "Epoch: 910, loss 0.4672105682252816\n",
      "Epoch: 910, loss 0.08441804629406002\n",
      "Epoch: 910, loss 0.10230358587726857\n",
      "Epoch: 910, loss 0.07771577418228097\n",
      "Epoch: 910, loss 0.07630841778196737\n",
      "Epoch: 910, loss 0.07628611493314097\n",
      "Epoch: 920, loss 0.37540104540896996\n",
      "Epoch: 920, loss 0.43024777830831484\n",
      "Epoch: 920, loss 0.4667943458127738\n",
      "Epoch: 920, loss 0.08457930838774862\n",
      "Epoch: 920, loss 0.10244629440444841\n",
      "Epoch: 920, loss 0.07786661166277041\n",
      "Epoch: 920, loss 0.07645600651662414\n",
      "Epoch: 920, loss 0.07643352348447069\n",
      "Epoch: 930, loss 0.37505184079716747\n",
      "Epoch: 930, loss 0.42983581651090996\n",
      "Epoch: 930, loss 0.4663804043969161\n",
      "Epoch: 930, loss 0.08473991753609489\n",
      "Epoch: 930, loss 0.10258885591563671\n",
      "Epoch: 930, loss 0.07801665238293665\n",
      "Epoch: 930, loss 0.07660275644354343\n",
      "Epoch: 930, loss 0.07658009346332807\n",
      "Epoch: 940, loss 0.3747038546426272\n",
      "Epoch: 940, loss 0.42942573220610436\n",
      "Epoch: 940, loss 0.465968747287024\n",
      "Epoch: 940, loss 0.08489986682619716\n",
      "Epoch: 940, loss 0.10273123715392057\n",
      "Epoch: 940, loss 0.07816589326191534\n",
      "Epoch: 940, loss 0.07674866543770403\n",
      "Epoch: 940, loss 0.0767258226907719\n",
      "Epoch: 950, loss 0.37435709236260395\n",
      "Epoch: 950, loss 0.42901753604877013\n",
      "Epoch: 950, loss 0.46555937623930427\n",
      "Epoch: 950, loss 0.08505915010261378\n",
      "Epoch: 950, loss 0.10287340826865668\n",
      "Epoch: 950, loss 0.078314331536127\n",
      "Epoch: 950, loss 0.07689373157414574\n",
      "Epoch: 950, loss 0.07687070919265696\n",
      "Epoch: 960, loss 0.37401155853087076\n",
      "Epoch: 960, loss 0.4286112366829187\n",
      "Epoch: 960, loss 0.4651522916209223\n",
      "Epoch: 960, loss 0.08521776189170965\n",
      "Epoch: 960, loss 0.1030153424417968\n",
      "Epoch: 960, loss 0.07846196473346903\n",
      "Epoch: 960, loss 0.07703795311531507\n",
      "Epoch: 960, loss 0.0770147511864453\n",
      "Epoch: 970, loss 0.37366725696214553\n",
      "Epoch: 970, loss 0.4282068409571388\n",
      "Epoch: 970, loss 0.46474749255619036\n",
      "Epoch: 970, loss 0.08537569733428639\n",
      "Epoch: 970, loss 0.10315701555617705\n",
      "Epoch: 970, loss 0.07860879065026627\n",
      "Epoch: 970, loss 0.0771813284997189\n",
      "Epoch: 970, loss 0.07715794706938398\n",
      "Epoch: 980, loss 0.37332419078727846\n",
      "Epoch: 980, loss 0.42780435411627815\n",
      "Epoch: 980, loss 0.46434497705687927\n",
      "Epoch: 980, loss 0.08553295212555972\n",
      "Epoch: 980, loss 0.10329840590097863\n",
      "Epoch: 980, loss 0.07875480733066392\n",
      "Epoch: 980, loss 0.07732385633173042\n",
      "Epoch: 980, loss 0.0773002954078881\n",
      "Epoch: 990, loss 0.3729823625202155\n",
      "Epoch: 990, loss 0.42740377997199813\n",
      "Epoch: 990, loss 0.46394474213840275\n",
      "Epoch: 990, loss 0.08568952246167748\n",
      "Epoch: 990, loss 0.10343949391019301\n",
      "Epoch: 990, loss 0.07890001304819688\n",
      "Epoch: 990, loss 0.07746553537242573\n",
      "Epoch: 990, loss 0.07744179492800177\n"
     ]
    }
   ],
   "source": [
    "def numerical_derivative(f: Callable, x: np.ndarray) -> np.ndarray:\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        temp = x[idx]\n",
    "        x[idx] = float(temp) + h\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = temp - h\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2 * h)\n",
    "        \n",
    "        x[idx] = temp\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "\n",
    "def train_numerical_derivative(lr: float) -> None:\n",
    "    for epoch in range(1000):\n",
    "        for x_batch, t_batch in zip(train_x_data, train_t_data_onehot):\n",
    "            y_data = model_numer(x_batch)\n",
    "            loss = mean_square_error(y_data, t_batch)\n",
    "\n",
    "            f = lambda W2, b2: sigmoid(x_batch @ W2 + b2)  # f(W2, b2)(x) = sigmoid(W2x + b2)\n",
    "            h = lambda W2, b2, W3, b3: sigmoid(f(W2, b2) @ W3 + b3)  # y = h(W2, b2, W3, b3)(x) = g(W3, b3)(f(W2, b2)(x)) = sigmoid(W3(sigmoid(W3x + b2)) + b3)\n",
    "            \n",
    "            E_w2 = lambda W2: mean_square_error(h(W2, model_numer.b2, model_numer.W3, model_numer.b3), t_batch)\n",
    "            E_b2 = lambda b2: mean_square_error(h(model_numer.W2, b2, model_numer.W3, model_numer.b3), t_batch)\n",
    "            E_w3 = lambda W3: mean_square_error(h(model_numer.W2, model_numer.b2, W3, model_numer.b3), t_batch)\n",
    "            E_b3 = lambda b3: mean_square_error(h(model_numer.W2, model_numer.b2, model_numer.W3, b3), t_batch)\n",
    "            \n",
    "            model_numer.W2 -= lr * numerical_derivative(E_w2, model_numer.W2)\n",
    "            model_numer.b2 -= lr * numerical_derivative(E_b2, model_numer.b2)\n",
    "            model_numer.W3 -= lr * numerical_derivative(E_w3, model_numer.W3)\n",
    "            model_numer.b3 -= lr * numerical_derivative(E_b3, model_numer.b3)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch: {epoch}, loss {loss}')\n",
    "\n",
    "\n",
    "model_numer = NeuralNetwork()\n",
    "train_numerical_derivative(lr=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 추론 (evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40060397 0.49256225]] [[0]]\n",
      "[[0.2129283  0.41174713]] [[0]]\n"
     ]
    }
   ],
   "source": [
    "def test(model):\n",
    "    y_data = model(test_x_data)\n",
    "    print(y_data, test_t_data)\n",
    "    \n",
    "    \n",
    "test(model_back)\n",
    "test(model_numer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2185028b62590b62afdaea33c23835374a0efabc80ef4ce750ba82ee2e8657e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
